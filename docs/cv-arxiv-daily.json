{"Talking Face": {"2401.04718": "|**2024-01-11**|**Jump Cut Smoothing for Talking Heads**|Xiaojuan Wang et.al.|[2401.04718](http://arxiv.org/abs/2401.04718)|null|\n", "2312.15197": "|**2023-12-23**|**TransFace: Unit-Based Audio-Visual Speech Synthesizer for Talking Head Translation**|Xize Cheng et.al.|[2312.15197](http://arxiv.org/abs/2312.15197)|null|\n", "2312.13578": "|**2023-12-21**|**DREAM-Talk: Diffusion-based Realistic Emotional Audio-driven Method for Single Image Talking Face Generation**|Chenxu Zhang et.al.|[2312.13578](http://arxiv.org/abs/2312.13578)|null|\n", "2312.10921": "|**2023-12-18**|**AE-NeRF: Audio Enhanced Neural Radiance Field for Few Shot Talking Head Synthesis**|Dongze Li et.al.|[2312.10921](http://arxiv.org/abs/2312.10921)|null|\n", "2312.11568": "|**2023-12-18**|**VectorTalker: SVG Talking Face Generation with Progressive Vectorisation**|Hao Hu et.al.|[2312.11568](http://arxiv.org/abs/2312.11568)|null|\n", "2312.10687": "|**2024-01-31**|**MM-TTS: Multi-modal Prompt based Style Transfer for Expressive Text-to-Speech Synthesis**|Wenhao Guan et.al.|[2312.10687](http://arxiv.org/abs/2312.10687)|null|\n", "2312.09767": "|**2023-12-15**|**DreamTalk: When Expressive Talking Head Generation Meets Diffusion Probabilistic Models**|Yifeng Ma et.al.|[2312.09767](http://arxiv.org/abs/2312.09767)|**[link](https://github.com/ali-vilab/dreamtalk)**|\n", "2312.07669": "|**2023-12-12**|**GMTalker: Gaussian Mixture based Emotional talking video Portraits**|Yibo Xia et.al.|[2312.07669](http://arxiv.org/abs/2312.07669)|null|\n", "2312.07385": "|**2023-12-12**|**GSmoothFace: Generalized Smooth Talking Face Generation via Fine Grained 3D Face Guidance**|Haiming Zhang et.al.|[2312.07385](http://arxiv.org/abs/2312.07385)|null|\n", "2312.06613": "|**2023-12-11**|**Neural Text to Articulate Talk: Deep Text to Audiovisual Speech Synthesis achieving both Auditory and Photo-realism**|Georgios Milis et.al.|[2312.06613](http://arxiv.org/abs/2312.06613)|**[link](https://github.com/g-milis/NEUTART)**|\n", "2312.06400": "|**2023-12-11**|**DiT-Head: High-Resolution Talking Head Synthesis using Diffusion Transformers**|Aaron Mir et.al.|[2312.06400](http://arxiv.org/abs/2312.06400)|null|\n", "2312.05572": "|**2023-12-09**|**R2-Talker: Realistic Real-Time Talking Head Synthesis with Hash Grid Landmarks Encoding and Progressive Multilayer Conditioning**|Zhiling Ye et.al.|[2312.05572](http://arxiv.org/abs/2312.05572)|null|\n", "2312.05430": "|**2023-12-09**|**FT2TF: First-Person Statement Text-To-Talking Face Generation**|Xingjian Diao et.al.|[2312.05430](http://arxiv.org/abs/2312.05430)|null|\n", "2312.03763": "|**2023-12-19**|**Gaussian3Diff: 3D Gaussian Diffusion for 3D Full Head Synthesis and Editing**|Yushi Lan et.al.|[2312.03763](http://arxiv.org/abs/2312.03763)|null|\n", "2312.02781": "|**2023-12-05**|**PMMTalk: Speech-Driven 3D Facial Animation from Complementary Pseudo Multi-modal Features**|Tianshun Han et.al.|[2312.02781](http://arxiv.org/abs/2312.02781)|null|\n", "2312.02703": "|**2023-12-05**|**MyPortrait: Morphable Prior-Guided Personalized Portrait Generation**|Bo Ding et.al.|[2312.02703](http://arxiv.org/abs/2312.02703)|null|\n", "2312.01841": "|**2023-12-07**|**VividTalk: One-Shot Audio-Driven Talking Head Generation Based on 3D Hybrid Prior**|Xusen Sun et.al.|[2312.01841](http://arxiv.org/abs/2312.01841)|null|\n", "2311.18729": "|**2023-11-30**|**Learning One-Shot 4D Head Avatar Synthesis using Synthetic Data**|Yu Deng et.al.|[2311.18729](http://arxiv.org/abs/2311.18729)|null|\n", "2311.17590": "|**2023-11-29**|**SyncTalk: The Devil is in the Synchronization for Talking Head Synthesis**|Ziqiao Peng et.al.|[2311.17590](http://arxiv.org/abs/2311.17590)|**[link](https://github.com/ZiqiaoPeng/SyncTalk)**|\n", "2311.17409": "|**2023-11-30**|**Talking Head(?) Anime from a Single Image 4: Improved Model and Its Distillation**|Pramook Khungurn et.al.|[2311.17409](http://arxiv.org/abs/2311.17409)|null|\n", "2311.17177": "|**2023-11-28**|**THInImg: Cross-modal Steganography for Presenting Talking Heads in Images**|Lin Zhao et.al.|[2311.17177](http://arxiv.org/abs/2311.17177)|null|\n", "2311.15230": "|**2024-03-14**|**GAIA: Zero-shot Talking Avatar Generation**|Tianyu He et.al.|[2311.15230](http://arxiv.org/abs/2311.15230)|null|\n", "2311.14730": "|**2023-11-20**|**MemoryCompanion: A Smart Healthcare Solution to Empower Efficient Alzheimer's Care Via Unleashing Generative AI**|Lifei Zheng et.al.|[2311.14730](http://arxiv.org/abs/2311.14730)|null|\n", "2311.08673": "|**2023-11-15**|**CP-EB: Talking Face Generation with Controllable Pose and Eye Blinking Embedding**|Jianzong Wang et.al.|[2311.08673](http://arxiv.org/abs/2311.08673)|null|\n", "2311.06772": "|**2023-11-12**|**ChatAnything: Facetime Chat with LLM-Enhanced Personas**|Yilin Zhao et.al.|[2311.06772](http://arxiv.org/abs/2311.06772)|null|\n", "2311.06307": "|**2023-11-08**|**Synthetic Speaking Children -- Why We Need Them and How to Make Them**|Muhammad Ali Farooq et.al.|[2311.06307](http://arxiv.org/abs/2311.06307)|null|\n", "2311.02549": "|**2023-11-05**|**3D-Aware Talking-Head Video Motion Transfer**|Haomiao Ni et.al.|[2311.02549](http://arxiv.org/abs/2311.02549)|null|\n", "2311.00994": "|**2023-11-02**|**LaughTalk: Expressive 3D Talking Head Generation with Laughter**|Kim Sung-Bin et.al.|[2311.00994](http://arxiv.org/abs/2311.00994)|null|\n", "2310.15112": "|**2023-10-23**|**The Self 2.0: How AI-Enhanced Self-Clones Transform Self-Perception and Improve Presentation Skills**|Qingxiao Zheng et.al.|[2310.15112](http://arxiv.org/abs/2310.15112)|null|\n", "2310.11295": "|**2023-10-17**|**CorrTalk: Correlation Between Hierarchical Speech and Facial Activity Variances for 3D Animation**|Zhaojie Chu et.al.|[2310.11295](http://arxiv.org/abs/2310.11295)|null|\n", "2310.05720": "|**2023-10-15**|**HyperLips: Hyper Control Lips with High Resolution Decoder for Talking Face Generation**|Yaosen Chen et.al.|[2310.05720](http://arxiv.org/abs/2310.05720)|**[link](https://github.com/semchan/HyperLips)**|\n", "2310.05304": "|**2023-10-08**|**GestSync: Determining who is speaking without a talking head**|Sindhu B Hegde et.al.|[2310.05304](http://arxiv.org/abs/2310.05304)|**[link](https://github.com/Sindhu-Hegde/gestsync)**|\n", "2310.05058": "|**2023-11-03**|**Learning Separable Hidden Unit Contributions for Speaker-Adaptive Lip-Reading**|Songtao Luo et.al.|[2310.05058](http://arxiv.org/abs/2310.05058)|**[link](https://github.com/jinchiniao/LSHUC)**|\n", "2310.02739": "|**2023-12-13**|**uTalk: Bridging the Gap Between Humans and AI**|Hussam Azzuni et.al.|[2310.02739](http://arxiv.org/abs/2310.02739)|null|\n", "2310.00434": "|**2023-09-30**|**DiffPoseTalk: Speech-Driven Stylistic 3D Facial Animation and Head Pose Generation via Diffusion Models**|Zhiyao Sun et.al.|[2310.00434](http://arxiv.org/abs/2310.00434)|null|\n", "2309.16148": "|**2023-09-28**|**OSM-Net: One-to-Many One-shot Talking Head Generation with Spontaneous Head Motions**|Jin Liu et.al.|[2309.16148](http://arxiv.org/abs/2309.16148)|null|\n", "2309.07752": "|**2023-09-14**|**DT-NeRF: Decomposed Triplane-Hash Neural Radiance Fields for High-Fidelity Talking Portrait Synthesis**|Yaoyu Su et.al.|[2309.07752](http://arxiv.org/abs/2309.07752)|null|\n", "2309.07509": "|**2023-09-14**|**DiffTalker: Co-driven audio-image diffusion for talking faces via intermediate landmarks**|Zipeng Qi et.al.|[2309.07509](http://arxiv.org/abs/2309.07509)|null|\n", "2309.07495": "|**2023-09-14**|**HDTR-Net: A Real-Time High-Definition Teeth Restoration Network for Arbitrary Talking Face Generation Methods**|Yongyuan Li et.al.|[2309.07495](http://arxiv.org/abs/2309.07495)|**[link](https://github.com/yylgoodlucky/hdtr)**|\n", "2309.06723": "|**2023-09-13**|**PIAVE: A Pose-Invariant Audio-Visual Speaker Extraction Network**|Qinghua Liu et.al.|[2309.06723](http://arxiv.org/abs/2309.06723)|null|\n", "2309.04946": "|**2023-10-12**|**Efficient Emotional Adaptation for Audio-Driven Talking-Head Generation**|Yuan Gan et.al.|[2309.04946](http://arxiv.org/abs/2309.04946)|**[link](https://github.com/yuangan/eat_code)**|\n", "2309.04814": "|**2023-09-09**|**Speech2Lip: High-fidelity Speech to Lip Generation by Learning from a Short Video**|Xiuzhe Wu et.al.|[2309.04814](http://arxiv.org/abs/2309.04814)|**[link](https://github.com/cvmi-lab/speech2lip)**|\n", "2309.01950": "|**2023-11-06**|**RADIO: Reference-Agnostic Dubbing Video Synthesis**|Dongyeun Lee et.al.|[2309.01950](http://arxiv.org/abs/2309.01950)|null|\n", "2308.16041": "|**2023-08-30**|**From Pixels to Portraits: A Comprehensive Survey of Talking Head Generation Techniques and Applications**|Shreyank N Gowda et.al.|[2308.16041](http://arxiv.org/abs/2308.16041)|null|\n", "2308.15224": "|**2023-08-29**|**Papeos: Augmenting Research Papers with Talk Videos**|Tae Soo Kim et.al.|[2308.15224](http://arxiv.org/abs/2308.15224)|null|\n", "2308.14256": "|**2023-12-14**|**FaceChain: A Playground for Human-centric Artificial Intelligence Generated Content**|Yang Liu et.al.|[2308.14256](http://arxiv.org/abs/2308.14256)|**[link](https://github.com/modelscope/facechain)**|\n", "2308.12866": "|**2023-08-24**|**ToonTalker: Cross-Domain Face Reenactment**|Yuan Gong et.al.|[2308.12866](http://arxiv.org/abs/2308.12866)|null|\n", "2308.09716": "|**2023-08-18**|**Diff2Lip: Audio Conditioned Diffusion Models for Lip-Synchronization**|Soumik Mukhopadhyay et.al.|[2308.09716](http://arxiv.org/abs/2308.09716)|**[link](https://github.com/soumik-kanad/diff2lip)**|\n", "2308.08849": "|**2023-08-17**|**A Survey on Deep Multi-modal Learning for Body Language Recognition and Generation**|Li Liu et.al.|[2308.08849](http://arxiv.org/abs/2308.08849)|**[link](https://github.com/wentaol86/awesome-body-language)**|\n", "2308.06457": "|**2023-08-12**|**Text-to-Video: a Two-stage Framework for Zero-shot Identity-agnostic Talking-head Generation**|Zhichao Wang et.al.|[2308.06457](http://arxiv.org/abs/2308.06457)|**[link](https://github.com/zhichaowang970201/text-to-video)**|\n", "2401.01207": "|**2024-04-07**|**Towards a Simultaneous and Granular Identity-Expression Control in Personalized Face Generation**|Renshuai Liu et.al.|[2401.01207](http://arxiv.org/abs/2401.01207)|null|\n", "2312.17205": "|**2024-04-11**|**EFHQ: Multi-purpose ExtremePose-Face-HQ dataset**|Trung Tuan Dao et.al.|[2312.17205](http://arxiv.org/abs/2312.17205)|null|\n", "2312.10422": "|**2023-12-19**|**Learning Dense Correspondence for NeRF-Based Face Reenactment**|Songlin Yang et.al.|[2312.10422](http://arxiv.org/abs/2312.10422)|null|\n", "2311.05521": "|**2023-11-28**|**BakedAvatar: Baking Neural Fields for Real-Time Head Avatar Synthesis**|Hao-Bin Duan et.al.|[2311.05521](http://arxiv.org/abs/2311.05521)|**[link](https://github.com/buaavrcg/BakedAvatar)**|\n", "2309.05095": "|**2023-09-10**|**MaskRenderer: 3D-Infused Multi-Mask Realistic Face Reenactment**|Tina Behrouzi et.al.|[2309.05095](http://arxiv.org/abs/2309.05095)|null|\n", "2308.04830": "|**2023-08-11**|**VAST: Vivify Your Talking Avatar via Zero-Shot Expressive Facial Style Transfer**|Liyang Chen et.al.|[2308.04830](http://arxiv.org/abs/2308.04830)|null|\n", "2308.00462": "|**2023-09-20**|**Context-Aware Talking-Head Video Editing**|Songlin Yang et.al.|[2308.00462](http://arxiv.org/abs/2308.00462)|null|\n", "2307.10797": "|**2023-07-20**|**HyperReenact: One-Shot Reenactment via Jointly Learning to Refine and Retarget Faces**|Stella Bounareli et.al.|[2307.10797](http://arxiv.org/abs/2307.10797)|**[link](https://github.com/stelabou/hyperreenact)**|\n", "2307.10008": "|**2023-07-19**|**MODA: Mapping-Once Audio-driven Portrait Animation with Dual Attentions**|Yunfei Liu et.al.|[2307.10008](http://arxiv.org/abs/2307.10008)|null|\n", "2307.09906": "|**2023-08-18**|**Implicit Identity Representation Conditioned Memory Compensation Network for Talking Head video Generation**|Fa-Ting Hong et.al.|[2307.09906](http://arxiv.org/abs/2307.09906)|**[link](https://github.com/harlanhong/iccv2023-mcnet)**|\n", "2307.09821": "|**2023-07-19**|**Hierarchical Semantic Perceptual Listener Head Video Generation: A High-performance Pipeline**|Zhigang Chang et.al.|[2307.09821](http://arxiv.org/abs/2307.09821)|null|\n", "2307.09480": "|**2023-07-18**|**FACTS: Facial Animation Creation using the Transfer of Styles**|Jack Saunders et.al.|[2307.09480](http://arxiv.org/abs/2307.09480)|null|\n", "2307.09368": "|**2023-12-11**|**Audio-driven Talking Face Generation by Overcoming Unintended Information Flow**|Dogucan Yaman et.al.|[2307.09368](http://arxiv.org/abs/2307.09368)|null|\n", "2307.09153": "|**2023-07-19**|**OPHAvatars: One-shot Photo-realistic Head Avatars**|Shaoxu Li et.al.|[2307.09153](http://arxiv.org/abs/2307.09153)|**[link](https://github.com/lsx0101/ophavatars)**|\n", "2307.05397": "|**2023-10-29**|**On the Vulnerability of DeepFake Detectors to Attacks Generated by Denoising Diffusion Models**|Marija Ivanovska et.al.|[2307.05397](http://arxiv.org/abs/2307.05397)|null|\n", "2307.04187": "|**2023-07-09**|**Predictive Coding For Animation-Based Video Compression**|Goluck Konuko et.al.|[2307.04187](http://arxiv.org/abs/2307.04187)|null|\n", "2307.03990": "|**2023-07-08**|**FTFDNet: Learning to Detect Talking Face Video Manipulation with Tri-Modality Interaction**|Ganglai Wang et.al.|[2307.03990](http://arxiv.org/abs/2307.03990)|null|\n", "2307.02090": "|**2023-07-05**|**Interactive Conversational Head Generation**|Mohan Zhou et.al.|[2307.02090](http://arxiv.org/abs/2307.02090)|null|\n", "2307.03270": "|**2023-07-04**|**A Comprehensive Multi-scale Approach for Speech and Dynamics Synchrony in Talking Head Generation**|Louis Airale et.al.|[2307.03270](http://arxiv.org/abs/2307.03270)|**[link](https://github.com/louisbearing/hmo-audio)**|\n", "2307.01233": "|**2023-07-03**|**RobustL2S: Speaker-Specific Lip-to-Speech Synthesis exploiting Self-Supervised Representations**|Neha Sahipjohn et.al.|[2307.01233](http://arxiv.org/abs/2307.01233)|null|\n", "2306.16003": "|**2024-01-18**|**Text-driven Talking Face Synthesis by Reprogramming Audio-driven Models**|Jeongsoo Choi et.al.|[2306.16003](http://arxiv.org/abs/2306.16003)|null|\n", "2306.11541": "|**2023-06-20**|**Audio-Driven 3D Facial Animation from In-the-Wild Videos**|Liying Lu et.al.|[2306.11541](http://arxiv.org/abs/2306.11541)|null|\n", "2306.10813": "|**2023-08-16**|**Instruct-NeuralTalker: Editing Audio-Driven Talking Radiance Fields with Instructions**|Yuqi Sun et.al.|[2306.10813](http://arxiv.org/abs/2306.10813)|null|\n", "2306.10799": "|**2023-08-30**|**SelfTalk: A Self-Supervised Commutative Training Diagram to Comprehend 3D Talking Faces**|Ziqiao Peng et.al.|[2306.10799](http://arxiv.org/abs/2306.10799)|**[link](https://github.com/psyai-net/SelfTalk_release)**|\n", "2306.08990": "|**2023-09-26**|**Emotional Speech-Driven Animation with Content-Emotion Disentanglement**|Radek Dan\u011b\u010dek et.al.|[2306.08990](http://arxiv.org/abs/2306.08990)|null|\n", "2306.07579": "|**2023-06-13**|**Parametric Implicit Face Representation for Audio-Driven Facial Reenactment**|Ricong Huang et.al.|[2306.07579](http://arxiv.org/abs/2306.07579)|null|\n", "2306.06885": "|**2023-06-12**|**NPVForensics: Jointing Non-critical Phonemes and Visemes for Deepfake Detection**|Yu Chen et.al.|[2306.06885](http://arxiv.org/abs/2306.06885)|null|\n", "2306.05356": "|**2023-06-08**|**ReliableSwap: Boosting General Face Swapping Via Reliable Supervision**|Ge Yuan et.al.|[2306.05356](http://arxiv.org/abs/2306.05356)|**[link](https://github.com/ygtxr1997/reliableswap)**|\n", "2306.03594": "|**2023-06-06**|**Emotional Talking Head Generation based on Memory-Sharing and Attention-Augmented Networks**|Jianrong Wang et.al.|[2306.03594](http://arxiv.org/abs/2306.03594)|null|\n", "2306.03504": "|**2023-08-02**|**Ada-TTA: Towards Adaptive High-Quality Text-to-Talking Avatar Synthesis**|Zhenhui Ye et.al.|[2306.03504](http://arxiv.org/abs/2306.03504)|null|\n", "2306.02903": "|**2023-06-05**|**Instruct-Video2Avatar: Video-to-Avatar Generation with Instructions**|Shaoxu Li et.al.|[2306.02903](http://arxiv.org/abs/2306.02903)|**[link](https://github.com/lsx0101/instruct-video2avatar)**|\n", "2306.01415": "|**2023-07-26**|**Learning Landmarks Motion from Speech for Speaker-Agnostic 3D Talking Heads Generation**|Federico Nocentini et.al.|[2306.01415](http://arxiv.org/abs/2306.01415)|**[link](https://github.com/fedenoce/s2l-s2d)**|\n", "2305.19556": "|**2024-04-01**|**Exploring Phonetic Context-Aware Lip-Sync For Talking Face Generation**|Se Jin Park et.al.|[2305.19556](http://arxiv.org/abs/2305.19556)|null|\n", "2305.13962": "|**2023-05-23**|**CPNet: Exploiting CLIP-based Attention Condenser and Probability Map Guidance for High-fidelity Talking Face Generation**|Jingning Xu et.al.|[2305.13962](http://arxiv.org/abs/2305.13962)|null|\n", "2305.13353": "|**2023-05-22**|**RenderMe-360: A Large Digital Asset Library and Benchmarks Towards High-fidelity Head Avatars**|Dongwei Pan et.al.|[2305.13353](http://arxiv.org/abs/2305.13353)|**[link](https://github.com/renderme-360/renderme-360)**|\n", "2305.10945": "|**2023-05-18**|**An Android Robot Head as Embodied Conversational Agent**|Marcel Heisler et.al.|[2305.10945](http://arxiv.org/abs/2305.10945)|null|\n", "2305.10456": "|**2023-05-17**|**LPMM: Intuitive Pose Control for Neural Talking-Head Model via Landmark-Parameter Morphable Model**|Kwangho Lee et.al.|[2305.10456](http://arxiv.org/abs/2305.10456)|null|\n", "2305.08293": "|**2023-05-15**|**Identity-Preserving Talking Face Generation with Landmark and Appearance Priors**|Weizhi Zhong et.al.|[2305.08293](http://arxiv.org/abs/2305.08293)|**[link](https://github.com/Weizhi-Zhong/IP_LAP)**|\n", "2305.06225": "|**2023-12-10**|**DaGAN++: Depth-Aware Generative Adversarial Network for Talking Head Video Generation**|Fa-Ting Hong et.al.|[2305.06225](http://arxiv.org/abs/2305.06225)|**[link](https://github.com/harlanhong/cvpr2022-dagan)**|\n", "2305.05445": "|**2023-05-09**|**StyleSync: High-Fidelity Generalized and Personalized Lip Sync in Style-based Generator**|Jiazhi Guan et.al.|[2305.05445](http://arxiv.org/abs/2305.05445)|null|\n", "2305.14359": "|**2023-05-09**|**Zero-shot personalized lip-to-speech synthesis with face image based voice control**|Zheng-Yan Sheng et.al.|[2305.14359](http://arxiv.org/abs/2305.14359)|null|\n", "2305.03713": "|**2023-09-12**|**Avatar Fingerprinting for Authorized Use of Synthetic Talking-Head Videos**|Ekta Prashnani et.al.|[2305.03713](http://arxiv.org/abs/2305.03713)|null|\n", "2305.02594": "|**2023-05-09**|**Multimodal-driven Talking Face Generation via a Unified Diffusion-based Generator**|Chao Xu et.al.|[2305.02594](http://arxiv.org/abs/2305.02594)|null|\n", "2305.02572": "|**2023-05-31**|**High-fidelity Generalized Emotional Talking Face Generation with Multi-modal Emotion Space Learning**|Chao Xu et.al.|[2305.02572](http://arxiv.org/abs/2305.02572)|null|\n", "2305.00942": "|**2023-05-01**|**StyleAvatar: Real-time Photo-realistic Portrait Avatar from a Single Video**|Lizhen Wang et.al.|[2305.00942](http://arxiv.org/abs/2305.00942)|**[link](https://github.com/lizhenwangt/styleavatar)**|\n", "2305.00787": "|**2023-05-01**|**GeneFace++: Generalized and Stable Real-Time Audio-Driven 3D Talking Face Generation**|Zhenhui Ye et.al.|[2305.00787](http://arxiv.org/abs/2305.00787)|null|\n", "2305.00521": "|**2024-02-12**|**StyleLipSync: Style-based Personalized Lip-sync Video Generation**|Taekyung Ki et.al.|[2305.00521](http://arxiv.org/abs/2305.00521)|null|\n", "2304.14471": "|**2023-04-27**|**Controllable One-Shot Face Video Synthesis With Semantic Aware Prior**|Kangning Liu et.al.|[2304.14471](http://arxiv.org/abs/2304.14471)|null|\n", "2304.12995": "|**2023-04-25**|**AudioGPT: Understanding and Generating Speech, Music, Sound, and Talking Head**|Rongjie Huang et.al.|[2304.12995](http://arxiv.org/abs/2304.12995)|**[link](https://github.com/aigc-audio/audiogpt)**|\n", "2304.11113": "|**2023-04-21**|**Implicit Neural Head Synthesis via Controllable Local Deformation Fields**|Chuhan Chen et.al.|[2304.11113](http://arxiv.org/abs/2304.11113)|null|\n", "2304.10168": "|**2023-11-02**|**High-Fidelity and Freely Controllable Talking Head Video Generation**|Yue Gao et.al.|[2304.10168](http://arxiv.org/abs/2304.10168)|null|\n", "2304.08945": "|**2023-04-18**|**Audio-Driven Talking Face Generation with Diverse yet Realistic Facial Animations**|Rongliang Wu et.al.|[2304.08945](http://arxiv.org/abs/2304.08945)|null|\n", "2304.05097": "|**2023-04-11**|**One-Shot High-Fidelity Talking-Head Synthesis with Deformable Neural Radiance Field**|Weichuang Li et.al.|[2304.05097](http://arxiv.org/abs/2304.05097)|null|\n", "2304.03275": "|**2023-09-18**|**That's What I Said: Fully-Controllable Talking Face Generation**|Youngjoon Jang et.al.|[2304.03275](http://arxiv.org/abs/2304.03275)|null|\n", "2304.03199": "|**2023-04-06**|**Face Animation with an Attribute-Guided Diffusion Model**|Bohan Zeng et.al.|[2304.03199](http://arxiv.org/abs/2304.03199)|**[link](https://github.com/zengbohan0217/fadm)**|\n", "2304.00471": "|**2023-04-28**|**A Unified Compression Framework for Efficient Speech-Driven Talking-Face Generation**|Bo-Kyeong Kim et.al.|[2304.00471](http://arxiv.org/abs/2304.00471)|null|\n", "2304.00334": "|**2023-04-01**|**TalkCLIP: Talking Head Generation with Text-Guided Expressive Speaking Styles**|Yifeng Ma et.al.|[2304.00334](http://arxiv.org/abs/2304.00334)|null|\n", "2303.17789": "|**2023-03-31**|**FONT: Flow-guided One-shot Talking Head Generation with Natural Head Motions**|Jin Liu et.al.|[2303.17789](http://arxiv.org/abs/2303.17789)|null|\n", "2303.17550": "|**2024-03-01**|**DAE-Talker: High Fidelity Speech-Driven Talking Face Generation with Diffusion Autoencoder**|Chenpeng Du et.al.|[2303.17550](http://arxiv.org/abs/2303.17550)|null|\n", "2303.17480": "|**2023-03-29**|**Seeing What You Said: Talking Face Generation Guided by a Lip Reading Expert**|Jiadong Wang et.al.|[2303.17480](http://arxiv.org/abs/2303.17480)|**[link](https://github.com/sxjdwang/talklip)**|\n", "2303.15539": "|**2023-03-27**|**OmniAvatar: Geometry-Guided Controllable 3D Head Synthesis**|Hongyi Xu et.al.|[2303.15539](http://arxiv.org/abs/2303.15539)|null|\n", "2303.14662": "|**2023-03-26**|**OTAvatar: One-shot Talking Face Avatar with Controllable Tri-plane Rendering**|Zhiyuan Ma et.al.|[2303.14662](http://arxiv.org/abs/2303.14662)|**[link](https://github.com/theericma/otavatar)**|\n", "2303.13071": "|**2023-03-23**|**PanoHead: Geometry-Aware 3D Full-Head Synthesis in 360$^{\\circ}$**|Sizhe An et.al.|[2303.13071](http://arxiv.org/abs/2303.13071)|null|\n", "2303.11548": "|**2023-03-26**|**Emotionally Enhanced Talking Face Generation**|Sahil Goyal et.al.|[2303.11548](http://arxiv.org/abs/2303.11548)|**[link](https://github.com/sahilg06/EmoGen)**|\n", "2303.11089": "|**2023-08-25**|**EmoTalk: Speech-Driven Emotional Disentanglement for 3D Face Animation**|Ziqiao Peng et.al.|[2303.11089](http://arxiv.org/abs/2303.11089)|**[link](https://github.com/psyai-net/EmoTalk_release)**|\n", "2303.09799": "|**2023-03-22**|**Style Transfer for 2D Talking Head Animation**|Trong-Thang Pham et.al.|[2303.09799](http://arxiv.org/abs/2303.09799)|**[link](https://github.com/aioz-ai/audiodrivenstyletransfer)**|\n", "2303.07697": "|**2023-03-14**|**DisCoHead: Audio-and-Video-Driven Talking Head Generation by Disentangled Control of Head Pose and Facial Expressions**|Geumbyeol Hwang et.al.|[2303.07697](http://arxiv.org/abs/2303.07697)|**[link](https://github.com/deepbrainai-research/koeba)**|\n", "2303.05322": "|**2023-03-09**|**Improving Few-Shot Learning for Talking Face System with TTS Data Augmentation**|Qi Chen et.al.|[2303.05322](http://arxiv.org/abs/2303.05322)|**[link](https://github.com/moon0316/t2a)**|\n", "2303.02659": "|**2023-03-05**|**Cyber Vaccine for Deepfake Immunity**|Ching-Chun Chang et.al.|[2303.02659](http://arxiv.org/abs/2303.02659)|null|\n", "2302.14337": "|**2023-05-19**|**UniFLG: Unified Facial Landmark Generator from Text or Speech**|Kentaro Mitsui et.al.|[2302.14337](http://arxiv.org/abs/2302.14337)|null|\n", "2303.08670": "|**2023-02-27**|**Deep Visual Forced Alignment: Learning to Align Transcription with Talking Face Video**|Minsu Kim et.al.|[2303.08670](http://arxiv.org/abs/2303.08670)|null|\n", "2302.13469": "|**2023-02-27**|**Memory-augmented Contrastive Learning for Talking Head Generation**|Jianrong Wang et.al.|[2302.13469](http://arxiv.org/abs/2302.13469)|**[link](https://github.com/yaxinzhao97/macl)**|\n", "2302.12532": "|**2023-02-24**|**Pose-Controllable 3D Facial Animation Synthesis using Hierarchical Audio-Vertex Attention**|Bin Liu et.al.|[2302.12532](http://arxiv.org/abs/2302.12532)|null|\n", "2302.08197": "|**2023-02-16**|**OPT: One-shot Pose-Controllable Talking Head Generation**|Jin Liu et.al.|[2302.08197](http://arxiv.org/abs/2302.08197)|null|\n", "2301.13430": "|**2023-01-31**|**GeneFace: Generalized and High-Fidelity Audio-Driven 3D Talking Face Synthesis**|Zhenhui Ye et.al.|[2301.13430](http://arxiv.org/abs/2301.13430)|null|\n", "2301.06281": "|**2023-03-01**|**DPE: Disentanglement of Pose and Expression for General Video Portrait Editing**|Youxin Pang et.al.|[2301.06281](http://arxiv.org/abs/2301.06281)|**[link](https://github.com/Carlyx/DPE)**|\n", "2301.03786": "|**2023-04-20**|**DiffTalk: Crafting Diffusion Models for Generalized Audio-Driven Portraits Animation**|Shuai Shen et.al.|[2301.03786](http://arxiv.org/abs/2301.03786)|**[link](https://github.com/sstzal/DiffTalk)**|\n", "2301.03396": "|**2023-07-29**|**Diffused Heads: Diffusion Models Beat GANs on Talking-Face Generation**|Micha\u0142 Stypu\u0142kowski et.al.|[2301.03396](http://arxiv.org/abs/2301.03396)|null|\n", "2301.02379": "|**2023-04-03**|**CodeTalker: Speech-Driven 3D Facial Animation with Discrete Motion Prior**|Jinbo Xing et.al.|[2301.02379](http://arxiv.org/abs/2301.02379)|**[link](https://github.com/Doubiiu/CodeTalker)**|\n", "2301.01081": "|**2023-06-10**|**StyleTalk: One-shot Talking Head Generation with Controllable Speaking Styles**|Yifeng Ma et.al.|[2301.01081](http://arxiv.org/abs/2301.01081)|**[link](https://github.com/fuxivirtualhuman/styletalk)**|\n", "2212.12137": "|**2022-12-23**|**Dubbing in Practice: A Large Scale Study of Human Localization With Insights for Automatic Dubbing**|William Brannon et.al.|[2212.12137](http://arxiv.org/abs/2212.12137)|null|\n", "2212.08062": "|**2023-03-27**|**MetaPortrait: Identity-Preserving Talking Head Generation with Fast Personalized Adaptation**|Bowen Zhang et.al.|[2212.08062](http://arxiv.org/abs/2212.08062)|**[link](https://github.com/Meta-Portrait/MetaPortrait)**|\n", "2212.05005": "|**2024-03-05**|**Memories are One-to-Many Mapping Alleviators in Talking Face Generation**|Anni Tang et.al.|[2212.05005](http://arxiv.org/abs/2212.05005)|null|\n", "2212.04970": "|**2022-12-09**|**Masked Lip-Sync Prediction by Audio-Visual Contextual Exploitation in Transformers**|Yasheng Sun et.al.|[2212.04970](http://arxiv.org/abs/2212.04970)|null|\n", "2212.04248": "|**2022-12-07**|**Talking Head Generation with Probabilistic Audio-to-Visual Diffusion Priors**|Zhentao Yu et.al.|[2212.04248](http://arxiv.org/abs/2212.04248)|null|\n", "2211.15064": "|**2023-03-04**|**High-fidelity Facial Avatar Reconstruction from Monocular Video with Generative Priors**|Yunpeng Bai et.al.|[2211.15064](http://arxiv.org/abs/2211.15064)|null|\n", "2211.14758": "|**2022-11-27**|**VideoReTalking: Audio-based Lip Synchronization for Talking Head Video Editing In the Wild**|Kun Cheng et.al.|[2211.14758](http://arxiv.org/abs/2211.14758)|null|\n", "2211.14506": "|**2022-11-26**|**Progressive Disentangled Representation Learning for Fine-Grained Controllable Talking Head Synthesis**|Duomin Wang et.al.|[2211.14506](http://arxiv.org/abs/2211.14506)|**[link](https://github.com/Dorniwang/PD-FGC-inference)**|\n", "2211.12194": "|**2023-03-13**|**SadTalker: Learning Realistic 3D Motion Coefficients for Stylized Audio-Driven Single Image Talking Face Animation**|Wenxuan Zhang et.al.|[2211.12194](http://arxiv.org/abs/2211.12194)|**[link](https://github.com/winfredy/sadtalker)**|\n", "2211.09809": "|**2022-12-07**|**SPACE: Speech-driven Portrait Animation with Controllable Expression**|Siddharth Gururani et.al.|[2211.09809](http://arxiv.org/abs/2211.09809)|null|\n", "2211.00987": "|**2023-04-17**|**Autoregressive GAN for Semantic Unconditional Head Motion Generation**|Louis Airale et.al.|[2211.00987](http://arxiv.org/abs/2211.00987)|**[link](https://github.com/louisbearing/unconditionalheadmotion)**|\n", "2211.00924": "|**2022-11-03**|**SyncTalkFace: Talking Face Generation with Precise Lip-Syncing via Audio-Lip Memory**|Se Jin Park et.al.|[2211.00924](http://arxiv.org/abs/2211.00924)|null|\n", "2210.07055": "|**2022-10-13**|**Sparse in Space and Time: Audio-visual Synchronisation with Trainable Selectors**|Vladimir Iashin et.al.|[2210.07055](http://arxiv.org/abs/2210.07055)|**[link](https://github.com/v-iashin/sparsesync)**|\n", "2210.06877": "|**2022-10-13**|**Pre-Avatar: An Automatic Presentation Generation Framework Leveraging Talking Avatar**|Aolan Sun et.al.|[2210.06877](http://arxiv.org/abs/2210.06877)|null|\n", "2210.06186": "|**2024-03-28**|**GOTCHA: Real-Time Video Deepfake Detection via Challenge-Response**|Govind Mittal et.al.|[2210.06186](http://arxiv.org/abs/2210.06186)|**[link](https://github.com/mittalgovind/GOTCHA-Deepfakes)**|\n", "2210.03692": "|**2022-10-07**|**Compressing Video Calls using Synthetic Talking Heads**|Madhav Agarwal et.al.|[2210.03692](http://arxiv.org/abs/2210.03692)|null|\n", "2210.03335": "|**2022-10-07**|**A Keypoint Based Enhancement Method for Audio Driven Free View Talking Head Synthesis**|Yichen Han et.al.|[2210.03335](http://arxiv.org/abs/2210.03335)|null|\n", "2210.02755": "|**2022-10-06**|**Audio-Visual Face Reenactment**|Madhav Agarwal et.al.|[2210.02755](http://arxiv.org/abs/2210.02755)|**[link](https://github.com/mdv3101/AVFR-Gan)**|\n", "2209.14698": "|**2022-09-29**|**Facial Landmark Predictions with Applications to Metaverse**|Qiao Han et.al.|[2209.14698](http://arxiv.org/abs/2209.14698)|**[link](https://github.com/sweatybridge/text-to-anime)**|\n", "2209.13375": "|**2022-09-27**|**StyleMask: Disentangling the Style Space of StyleGAN2 for Neural Face Reenactment**|Stella Bounareli et.al.|[2209.13375](http://arxiv.org/abs/2209.13375)|**[link](https://github.com/stelabou/stylemask)**|\n", "2209.10507": "|**2023-10-19**|**Gemino: Practical and Robust Neural Compression for Video Conferencing**|Vibhaalakshmi Sivaraman et.al.|[2209.10507](http://arxiv.org/abs/2209.10507)|null|\n", "2209.10340": "|**2022-09-21**|**FNeVR: Neural Volume Rendering for Face Animation**|Bohan Zeng et.al.|[2209.10340](http://arxiv.org/abs/2209.10340)|**[link](https://github.com/zengbohan0217/FNeVR)**|\n", "2209.08795": "|**2022-09-19**|**AutoLV: Automatic Lecture Video Generator**|Wenbin Wang et.al.|[2209.08795](http://arxiv.org/abs/2209.08795)|null|\n", "2209.08289": "|**2023-11-28**|**Continuously Controllable Facial Expression Editing in Talking Face Videos**|Zhiyao Sun et.al.|[2209.08289](http://arxiv.org/abs/2209.08289)|null|\n", "2209.04252": "|**2022-09-09**|**Talking Head from Speech Audio using a Pre-trained Image Generator**|Mohammed M. Alghamdi et.al.|[2209.04252](http://arxiv.org/abs/2209.04252)|null|\n", "2209.01320": "|**2023-03-24**|**Synthesizing Photorealistic Virtual Humans Through Cross-modal Disentanglement**|Siddarth Ravichandran et.al.|[2209.01320](http://arxiv.org/abs/2209.01320)|null|\n", "2208.13717": "|**2022-08-29**|**StableFace: Analyzing and Improving Motion Stability for Talking Face Generation**|Jun Ling et.al.|[2208.13717](http://arxiv.org/abs/2208.13717)|null|\n", "2208.10922": "|**2024-03-15**|**StyleTalker: One-shot Style-based Audio-driven Talking Head Video Generation**|Dongchan Min et.al.|[2208.10922](http://arxiv.org/abs/2208.10922)|null|\n", "2208.09796": "|**2022-10-04**|**Towards MOOCs for Lipreading: Using Synthetic Talking Heads to Train Humans in Lipreading at Scale**|Aditya Agarwal et.al.|[2208.09796](http://arxiv.org/abs/2208.09796)|null|\n", "2208.08562": "|**2022-09-07**|**Restructurable Activation Networks**|Kartikeya Bhardwaj et.al.|[2208.08562](http://arxiv.org/abs/2208.08562)|**[link](https://github.com/arm-software/ml-restructurable-activation-networks)**|\n", "2208.08118": "|**2022-08-17**|**Extreme-scale Talking-Face Video Upsampling with Audio-Visual Priors**|Sindhu B Hegde et.al.|[2208.08118](http://arxiv.org/abs/2208.08118)|**[link](https://github.com/Sindhu-Hegde/video-super-resolver)**|\n", "2208.02210": "|**2022-08-03**|**Free-HeadGAN: Neural Talking Head Synthesis with Explicit Gaze Control**|Michail Christos Doukas et.al.|[2208.02210](http://arxiv.org/abs/2208.02210)|null|\n", "2207.11770": "|**2022-07-24**|**Learning Dynamic Facial Radiance Fields for Few-Shot Talking Head Synthesis**|Shuai Shen et.al.|[2207.11770](http://arxiv.org/abs/2207.11770)|**[link](https://github.com/sstzal/DFRF)**|\n", "2207.11094": "|**2022-07-22**|**Visual Speech-Aware Perceptual 3D Facial Expression Reconstruction from Videos**|Panagiotis P. Filntisis et.al.|[2207.11094](http://arxiv.org/abs/2207.11094)|**[link](https://github.com/filby89/spectre)**|\n", "2207.03800": "|**2022-07-13**|**FastLTS: Non-Autoregressive End-to-End Unconstrained Lip-to-Speech Synthesis**|Yongqi Wang et.al.|[2207.03800](http://arxiv.org/abs/2207.03800)|**[link](https://github.com/cyanbx/FastLTS)**|\n", "2206.14658": "|**2022-06-29**|**Cut Inner Layers: A Structured Pruning Strategy for Efficient U-Net GANs**|Bo-Kyeong Kim et.al.|[2206.14658](http://arxiv.org/abs/2206.14658)|null|\n", "2206.12837": "|**2022-08-02**|**Perceptual Conversational Head Generation with Regularized Driver and Enhanced Renderer**|Ailin Huang et.al.|[2206.12837](http://arxiv.org/abs/2206.12837)|**[link](https://github.com/megvii-research/MM2022-ViCoPerceptualHeadGeneration)**|\n", "2206.07458": "|**2022-07-20**|**VisageSynTalk: Unseen Speaker Video-to-Speech Synthesis via Speech-Visage Feature Selection**|Joanna Hong et.al.|[2206.07458](http://arxiv.org/abs/2206.07458)|null|\n", "2205.15278": "|**2022-09-23**|**EAMM: One-Shot Emotional Talking Face via Audio-Based Emotion-Aware Motion Model**|Xinya Ji et.al.|[2205.15278](http://arxiv.org/abs/2205.15278)|null|\n", "2205.13368": "|**2022-05-26**|**One-Shot Face Reenactment on Megapixels**|Wonjun Kang et.al.|[2205.13368](http://arxiv.org/abs/2205.13368)|null|\n", "2205.12194": "|**2022-05-24**|**Merkel Podcast Corpus: A Multimodal Dataset Compiled from 16 Years of Angela Merkel's Weekly Video Podcasts**|Debjoy Saha et.al.|[2205.12194](http://arxiv.org/abs/2205.12194)|**[link](https://github.com/deeplsd/merkel-podcast-corpus)**|\n", "2205.06421": "|**2022-05-13**|**Talking Face Generation with Multilingual TTS**|Hyoung-Kyu Song et.al.|[2205.06421](http://arxiv.org/abs/2205.06421)|null|\n", "2205.01155": "|**2022-05-02**|**Emotion-Controllable Generalized Talking Face Generation**|Sanjana Sinha et.al.|[2205.01155](http://arxiv.org/abs/2205.01155)|null|\n", "2205.00916": "|**2022-05-02**|**A Novel Speech-Driven Lip-Sync Model with CNN and LSTM**|Xiaohong Li et.al.|[2205.00916](http://arxiv.org/abs/2205.00916)|null|\n", "2204.14057": "|**2022-05-27**|**Unsupervised Voice-Face Representation Learning by Cross-Modal Prototype Contrast**|Boqing Zhu et.al.|[2204.14057](http://arxiv.org/abs/2204.14057)|**[link](https://github.com/cocoxili/cmpc)**|\n", "2204.12756": "|**2022-04-27**|**Talking Head Generation Driven by Speech-Related Facial Action Units and Audio- Based on Multimodal Representation Fusion**|Sen Chen et.al.|[2204.12756](http://arxiv.org/abs/2204.12756)|null|\n", "2204.06180": "|**2022-04-13**|**Dynamic Neural Textures: Generating Talking-Face Videos with Continuously Controllable Expressions**|Zipeng Ye et.al.|[2204.06180](http://arxiv.org/abs/2204.06180)|null|\n", "2204.03083": "|**2023-05-18**|**Audio-Visual Person-of-Interest DeepFake Detection**|Davide Cozzolino et.al.|[2204.03083](http://arxiv.org/abs/2204.03083)|**[link](https://github.com/grip-unina/poi-forensics)**|\n", "2203.14512": "|**2023-02-14**|**Expressive Talking Head Video Encoding in StyleGAN2 Latent-Space**|Trevine Oorloff et.al.|[2203.14512](http://arxiv.org/abs/2203.14512)|**[link](https://github.com/trevineoorloff/Encode-in-Style)**|\n", "2203.14367": "|**2022-03-29**|**Thin-Plate Spline Motion Model for Image Animation**|Jian Zhao et.al.|[2203.14367](http://arxiv.org/abs/2203.14367)|**[link](https://github.com/yoyo-nb/thin-plate-spline-motion-model)**|\n", "2203.10117": "|**2022-11-10**|**On the role of Lip Articulation in Visual Speech Perception**|Zakaria Aldeneh et.al.|[2203.10117](http://arxiv.org/abs/2203.10117)|null|\n", "2203.07931": "|**2023-08-12**|**DialogueNeRF: Towards Realistic Avatar Face-to-Face Conversation Video Generation**|Yichao Yan et.al.|[2203.07931](http://arxiv.org/abs/2203.07931)|null|\n", "2203.06605": "|**2022-03-15**|**Depth-Aware Generative Adversarial Network for Talking Head Video Generation**|Fa-Ting Hong et.al.|[2203.06605](http://arxiv.org/abs/2203.06605)|**[link](https://github.com/harlanhong/cvpr2022-dagan)**|\n", "2203.05178": "|**2022-03-10**|**An Audio-Visual Attention Based Multimodal Network for Fake Talking Face Videos Detection**|Ganglai Wang et.al.|[2203.05178](http://arxiv.org/abs/2203.05178)|null|\n", "2203.04036": "|**2022-03-17**|**StyleHEAT: One-Shot High-Resolution Editable Talking Face Generation via Pre-trained StyleGAN**|Fei Yin et.al.|[2203.04036](http://arxiv.org/abs/2203.04036)|**[link](https://github.com/FeiiYin/StyleHEAT)**|\n", "2203.03984": "|**2022-03-08**|**Attention-Based Lip Audio-Visual Synthesis for Talking Face Generation in the Wild**|Ganglai Wang et.al.|[2203.03984](http://arxiv.org/abs/2203.03984)|null|\n", "2202.12972": "|**2022-02-25**|**FSGANv2: Improved Subject Agnostic Face Swapping and Reenactment**|Yuval Nirkin et.al.|[2202.12972](http://arxiv.org/abs/2202.12972)|null|\n", "2202.10758": "|**2022-02-22**|**Thinking the Fusion Strategy of Multi-reference Face Reenactment**|Takuya Yashima et.al.|[2202.10758](http://arxiv.org/abs/2202.10758)|null|\n", "2202.06198": "|**2023-01-23**|**Data standardization for robust lip sync**|Chun Wang et.al.|[2202.06198](http://arxiv.org/abs/2202.06198)|null|\n", "2202.00046": "|**2022-10-06**|**Finding Directions in GAN's Latent Space for Neural Face Reenactment**|Stella Bounareli et.al.|[2202.00046](http://arxiv.org/abs/2202.00046)|**[link](https://github.com/stelabou/stylegan_directions_face_reenactment)**|\n", "2201.08361": "|**2022-01-21**|**Stitch it in Time: GAN-Based Facial Editing of Real Videos**|Rotem Tzaban et.al.|[2201.08361](http://arxiv.org/abs/2201.08361)|**[link](https://github.com/rotemtzaban/STIT)**|\n", "2201.07131": "|**2022-10-21**|**Leveraging Real Talking Faces via Self-Supervision for Robust Forgery Detection**|Alexandros Haliassos et.al.|[2201.07131](http://arxiv.org/abs/2201.07131)|**[link](https://github.com/ahaliassos/RealForensics)**|\n", "2201.06260": "|**2022-01-17**|**Towards Realistic Visual Dubbing with Heterogeneous Sources**|Tianyi Xie et.al.|[2201.06260](http://arxiv.org/abs/2201.06260)|null|\n", "2201.05986": "|**2022-01-16**|**Audio-Driven Talking Face Video Generation with Dynamic Convolution Kernels**|Zipeng Ye et.al.|[2201.05986](http://arxiv.org/abs/2201.05986)|null|\n", "2201.00791": "|**2022-01-03**|**DFA-NeRF: Personalized Talking Head Generation via Disentangled Face Attributes Neural Rendering**|Shunyu Yao et.al.|[2201.00791](http://arxiv.org/abs/2201.00791)|null|\n", "2112.13548": "|**2022-07-20**|**Responsive Listening Head Generation: A Benchmark Dataset and Baseline**|Mohan Zhou et.al.|[2112.13548](http://arxiv.org/abs/2112.13548)|null|\n", "2112.10098": "|**2021-12-19**|**Initiative Defense against Facial Manipulation**|Qidong Huang et.al.|[2112.10098](http://arxiv.org/abs/2112.10098)|**[link](https://github.com/shikiw/initiative-defense-for-deepfake)**|\n", "2112.02749": "|**2021-12-06**|**One-shot Talking Face Generation from Single-speaker Audio-Visual Correlation Learning**|Suzhen Wang et.al.|[2112.02749](http://arxiv.org/abs/2112.02749)|null|\n", "2111.03472": "|**2021-11-02**|**BiosecurID: a multimodal biometric database**|Julian Fierrez et.al.|[2111.03472](http://arxiv.org/abs/2111.03472)|null|\n", "2111.00203": "|**2021-10-30**|**Imitating Arbitrary Talking Style for Realistic Audio-DrivenTalking Face Synthesis**|Haozhe Wu et.al.|[2111.00203](http://arxiv.org/abs/2111.00203)|**[link](https://github.com/wuhaozhe/style_avatar)**|\n", "2110.13571": "|**2021-10-26**|**Emotion recognition in talking-face videos using persistent entropy and neural networks**|Eduardo Paluzo-Hidalgo et.al.|[2110.13571](http://arxiv.org/abs/2110.13571)|**[link](https://github.com/cimagroup/audiovisual-emotionrecognitionusingtda)**|\n", "2110.13384": "|**2021-10-26**|**ViDA-MAN: Visual Dialog with Digital Humans**|Tong Shen et.al.|[2110.13384](http://arxiv.org/abs/2110.13384)|null|\n", "2110.09951": "|**2021-10-19**|**Talking Head Generation with Audio and Speech Related Facial Action Units**|Sen Chen et.al.|[2110.09951](http://arxiv.org/abs/2110.09951)|null|\n", "2110.08580": "|**2021-10-16**|**Intelligent Video Editing: Incorporating Modern Talking Face Generation Algorithms in a Video Editor**|Anchit Gupta et.al.|[2110.08580](http://arxiv.org/abs/2110.08580)|null|\n", "2110.04708": "|**2021-10-12**|**Fine-grained Identity Preserving Landmark Synthesis for Face Reenactment**|Haichao Zhang et.al.|[2110.04708](http://arxiv.org/abs/2110.04708)|null|\n", "2110.05241": "|**2021-10-07**|**Streaming Transformer Transducer Based Speech Recognition Using Non-Causal Convolution**|Yangyang Shi et.al.|[2110.05241](http://arxiv.org/abs/2110.05241)|null|\n", "2109.10595": "|**2021-09-24**|**Live Speech Portraits: Real-Time Photorealistic Talking-Head Animation**|Yuanxun Lu et.al.|[2109.10595](http://arxiv.org/abs/2109.10595)|null|\n", "2109.04991": "|**2021-09-17**|**Detection of GAN-synthesized street videos**|Omran Alamayreh et.al.|[2109.04991](http://arxiv.org/abs/2109.04991)|null|\n", "2109.02081": "|**2023-08-21**|**Deep Person Generation: A Survey from the Perspective of Face, Pose and Cloth Synthesis**|Tong Sha et.al.|[2109.02081](http://arxiv.org/abs/2109.02081)|null|\n", "2108.08020": "|**2021-11-29**|**Speech Drives Templates: Co-Speech Gesture Synthesis with Learned Templates**|Shenhan Qian et.al.|[2108.08020](http://arxiv.org/abs/2108.08020)|**[link](https://github.com/shenhanqian/speechdrivestemplates)**|\n", "2108.07938": "|**2021-08-18**|**FACIAL: Synthesizing Dynamic Talking Face with Implicit Attribute Learning**|Chenxu Zhang et.al.|[2108.07938](http://arxiv.org/abs/2108.07938)|**[link](https://github.com/zhangchenxu528/FACIAL)**|\n", "2108.05650": "|**2021-08-12**|**UniFaceGAN: A Unified Framework for Temporally Consistent Facial Video Editing**|Meng Cao et.al.|[2108.05650](http://arxiv.org/abs/2108.05650)|null|\n", "2108.05080": "|**2022-03-01**|**FakeAVCeleb: A Novel Audio-Video Multimodal Deepfake Dataset**|Hasam Khalid et.al.|[2108.05080](http://arxiv.org/abs/2108.05080)|**[link](https://github.com/dash-lab/fakeavceleb)**|\n", "2108.04325": "|**2021-08-11**|**AnyoneNet: Synchronized Speech and Talking Head Generation for Arbitrary Person**|Xinsheng Wang et.al.|[2108.04325](http://arxiv.org/abs/2108.04325)|null|\n", "2107.12346": "|**2021-07-27**|**Beyond Voice Identity Conversion: Manipulating Voice Attributes by Adversarial Learning of Structured Disentangled Representations**|Laurent Benaroya et.al.|[2107.12346](http://arxiv.org/abs/2107.12346)|null|\n", "2107.09293": "|**2021-07-20**|**Audio2Head: Audio-driven One-shot Talking-head Generation with Natural Head Motion**|Suzhen Wang et.al.|[2107.09293](http://arxiv.org/abs/2107.09293)|**[link](https://github.com/wangsuzhen/Audio2Head)**|\n", "2107.06831": "|**2021-12-20**|**Parallel and High-Fidelity Text-to-Lip Generation**|Jinglin Liu et.al.|[2107.06831](http://arxiv.org/abs/2107.06831)|**[link](https://github.com/Dianezzy/ParaLip)**|\n", "2107.04806": "|**2021-07-10**|**Speech2Video: Cross-Modal Distillation for Speech to Video Generation**|Shijing Si et.al.|[2107.04806](http://arxiv.org/abs/2107.04806)|null|\n", "2107.03109": "|**2021-07-07**|**Egocentric Videoconferencing**|Mohamed Elgharib et.al.|[2107.03109](http://arxiv.org/abs/2107.03109)|null|\n", "2107.05548": "|**2022-03-04**|**Multi-modality Deep Restoration of Extremely Compressed Face Videos**|Xi Zhang et.al.|[2107.05548](http://arxiv.org/abs/2107.05548)|null|\n", "2106.14014": "|**2022-04-03**|**Txt2Vid: Ultra-Low Bitrate Compression of Talking-Head Videos via Text**|Pulkit Tandon et.al.|[2106.14014](http://arxiv.org/abs/2106.14014)|**[link](https://github.com/tpulkit/txt2vid)**|\n", "2106.04185": "|**2021-06-08**|**LipSync3D: Data-Efficient Learning of Personalized 3D Talking Faces from Video using Pose and Lighting Normalization**|Avisek Lahiri et.al.|[2106.04185](http://arxiv.org/abs/2106.04185)|null|\n", "2104.14631": "|**2022-01-22**|**Text2Video: Text-driven Talking-head Video Synthesis with Personalized Phoneme-Pose Dictionary**|Sibo Zhang et.al.|[2104.14631](http://arxiv.org/abs/2104.14631)|null|\n", "2104.14557": "|**2021-04-29**|**Learned Spatial Representations for Few-shot Talking-Head Synthesis**|Moustafa Meshry et.al.|[2104.14557](http://arxiv.org/abs/2104.14557)|null|\n", "2104.12051": "|**2021-04-25**|**3D-TalkEmo: Learning to Synthesize 3D Emotional Talking Head**|Qianyun Wang et.al.|[2104.12051](http://arxiv.org/abs/2104.12051)|null|\n", "2104.11116": "|**2021-04-22**|**Pose-Controllable Talking Face Generation by Implicitly Modularized Audio-Visual Representation**|Hang Zhou et.al.|[2104.11116](http://arxiv.org/abs/2104.11116)|**[link](https://github.com/Hangz-nju-cuhk/Talking-Face_PC-AVS)**|\n", "2104.07995": "|**2021-05-07**|**Write-a-speaker: Text-based Emotional and Rhythmic Talking-head Generation**|Lincheng Li et.al.|[2104.07995](http://arxiv.org/abs/2104.07995)|**[link](https://github.com/FuxiVirtualHuman/Write-a-Speaker)**|\n", "2104.07452": "|**2021-05-20**|**Audio-Driven Emotional Video Portraits**|Xinya Ji et.al.|[2104.07452](http://arxiv.org/abs/2104.07452)|null|\n", "2104.03117": "|**2021-04-07**|**Single Source One Shot Reenactment using Weighted motion From Paired Feature Points**|Soumya Tripathy et.al.|[2104.03117](http://arxiv.org/abs/2104.03117)|null|\n", "2104.03061": "|**2021-04-07**|**Everything's Talkin': Pareidolia Face Reenactment**|Linsen Song et.al.|[2104.03061](http://arxiv.org/abs/2104.03061)|**[link](https://github.com/Linsen13/EverythingTalking)**|\n", "2104.02850": "|**2021-04-07**|**LI-Net: Large-Pose Identity-Preserving Face Reenactment Network**|Jin Liu et.al.|[2104.02850](http://arxiv.org/abs/2104.02850)|null|\n", "2103.11078": "|**2021-08-19**|**AD-NeRF: Audio Driven Neural Radiance Fields for Talking Head Synthesis**|Yudong Guo et.al.|[2103.11078](http://arxiv.org/abs/2103.11078)|**[link](https://github.com/YudongGuo/AD-NeRF)**|\n", "2103.10094": "|**2021-08-23**|**KoDF: A Large-scale Korean DeepFake Detection Dataset**|Patrick Kwon et.al.|[2103.10094](http://arxiv.org/abs/2103.10094)|null|\n", "2103.03663": "|**2021-03-05**|**Real-time RGBD-based Extended Body Pose Estimation**|Renat Bashirov et.al.|[2103.03663](http://arxiv.org/abs/2103.03663)|**[link](https://github.com/rmbashirov/rgbd-kinect-pose)**|\n", "2102.09737": "|**2021-02-19**|**One Shot Audio to Animated Video Generation**|Neeraj Kumar et.al.|[2102.09737](http://arxiv.org/abs/2102.09737)|null|\n", "2103.03927": "|**2021-02-18**|**AudioVisual Speech Synthesis: A brief literature review**|Efthymios Georgiou et.al.|[2103.03927](http://arxiv.org/abs/2103.03927)|null|\n", "2102.03984": "|**2021-04-26**|**One-shot Face Reenactment Using Appearance Adaptive Normalization**|Guangming Yao et.al.|[2102.03984](http://arxiv.org/abs/2102.03984)|null|\n", "2101.10808": "|**2022-04-25**|**Fast Facial Landmark Detection and Applications: A Survey**|Kostiantyn Khabarlak et.al.|[2101.10808](http://arxiv.org/abs/2101.10808)|null|\n", "2012.08261": "|**2021-08-23**|**HeadGAN: One-shot Neural Head Synthesis and Editing**|Michail Christos Doukas et.al.|[2012.08261](http://arxiv.org/abs/2012.08261)|null|\n", "2012.07842": "|**2020-12-14**|**Robust One Shot Audio to Video Generation**|Neeraj Kumar et.al.|[2012.07842](http://arxiv.org/abs/2012.07842)|null|\n", "2012.07304": "|**2020-12-14**|**Multi Modal Adaptive Normalization for Audio to Video Generation**|Neeraj Kumar et.al.|[2012.07304](http://arxiv.org/abs/2012.07304)|null|\n", "2011.15126": "|**2021-04-02**|**One-Shot Free-View Neural Talking-Head Synthesis for Video Conferencing**|Ting-Chun Wang et.al.|[2011.15126](http://arxiv.org/abs/2011.15126)|null|\n", "2011.14695": "|**2020-11-30**|**Adaptive Compact Attention For Few-shot Video-to-video Translation**|Risheng Huang et.al.|[2011.14695](http://arxiv.org/abs/2011.14695)|null|\n", "2011.10727": "|**2020-11-21**|**Stochastic Talking Face Generation Using Latent Distribution Matching**|Ravindra Yadav et.al.|[2011.10727](http://arxiv.org/abs/2011.10727)|**[link](https://github.com/ry85/Stochastic-Talking-Face-Generation-Using-Latent-Distribution-Matching)**|\n", "2011.10688": "|**2020-11-21**|**Iterative Text-based Editing of Talking-heads Using Neural Retargeting**|Xinwei Yao et.al.|[2011.10688](http://arxiv.org/abs/2011.10688)|null|\n", "2011.04439": "|**2020-11-09**|**FACEGAN: Facial Attribute Controllable rEenactment GAN**|Soumya Tripathy et.al.|[2011.04439](http://arxiv.org/abs/2011.04439)|null|\n", "2011.01114": "|**2020-11-02**|**Facial Keypoint Sequence Generation from Audio**|Prateek Manocha et.al.|[2011.01114](http://arxiv.org/abs/2011.01114)|null|\n", "2010.13017": "|**2020-10-25**|**APB2FaceV2: Real-Time Audio-Guided Multi-Face Reenactment**|Jiangning Zhang et.al.|[2010.13017](http://arxiv.org/abs/2010.13017)|**[link](https://github.com/zhangzjn/APB2FaceV2)**|\n", "2010.02315": "|**2020-10-05**|**SMILE: Semantically-guided Multi-attribute Image and Layout Editing**|Andr\u00e9s Romero et.al.|[2010.02315](http://arxiv.org/abs/2010.02315)|**[link](https://github.com/affromero/SMILE)**|\n", "2009.05784": "|**2020-09-12**|**DualLip: A System for Joint Lip Reading and Generation**|Weicong Chen et.al.|[2009.05784](http://arxiv.org/abs/2009.05784)|null|\n", "2009.01225": "|**2020-09-02**|**Seeing wake words: Audio-visual Keyword Spotting**|Liliane Momeni et.al.|[2009.01225](http://arxiv.org/abs/2009.01225)|null|\n", "2008.13040": "|**2020-08-29**|**\"It took me almost 30 minutes to practice this\". Performance and Production Practices in Dance Challenge Videos on TikTok**|Daniel Klug et.al.|[2008.13040](http://arxiv.org/abs/2008.13040)|null|\n", "2008.11985": "|**2021-03-03**|**Estimating Uniqueness of I-Vector Representation of Human Voice**|Erkam Sinan Tandogan et.al.|[2008.11985](http://arxiv.org/abs/2008.11985)|null|\n", "2008.10010": "|**2020-08-23**|**A Lip Sync Expert Is All You Need for Speech to Lip Generation In The Wild**|K R Prajwal et.al.|[2008.10010](http://arxiv.org/abs/2008.10010)|**[link](https://github.com/Rudrabha/Wav2Lip)**|\n", "2008.07783": "|**2020-09-18**|**Mesh Guided One-shot Face Reenactment using Graph Convolutional Networks**|Guangming Yao et.al.|[2008.07783](http://arxiv.org/abs/2008.07783)|null|\n", "2008.03592": "|**2021-07-21**|**Speech Driven Talking Face Generation from a Single Image and an Emotion Condition**|Sefik Emre Eskimez et.al.|[2008.03592](http://arxiv.org/abs/2008.03592)|**[link](https://github.com/eeskimez/emotalkingface)**|\n", "2008.02098": "|**2020-08-04**|**Speaker dependent acoustic-to-articulatory inversion using real-time MRI of the vocal tract**|Tam\u00e1s G\u00e1bor Csap\u00f3 et.al.|[2008.02098](http://arxiv.org/abs/2008.02098)|**[link](https://github.com/BME-SmartLab/speech2mri)**|\n", "2008.00620": "|**2021-08-30**|**Audiovisual Speech Synthesis using Tacotron2**|Ahmed Hussen Abdelaziz et.al.|[2008.00620](http://arxiv.org/abs/2008.00620)|null|\n", "2008.01652": "|**2020-08-02**|**Deep Multi-modality Soft-decoding of Very Low Bit-rate Face Videos**|Yanhui Guo et.al.|[2008.01652](http://arxiv.org/abs/2008.01652)|null|\n", "2007.08547": "|**2020-07-16**|**Talking-head Generation with Rhythmic Head Motion**|Lele Chen et.al.|[2007.08547](http://arxiv.org/abs/2007.08547)|**[link](https://github.com/lelechen63/Talking-head-Generation-with-Rhythmic-Head-Motion)**|\n", "2007.04134": "|**2020-07-08**|**Learning Speech Representations from Raw Audio by Joint Audiovisual Self-Supervision**|Abhinav Shukla et.al.|[2007.04134](http://arxiv.org/abs/2007.04134)|null|\n", "2006.11610": "|**2020-06-20**|**Speaker Independent and Multilingual/Mixlingual Speech-Driven Talking Head Generation Using Phonetic Posteriorgrams**|Huirong Huang et.al.|[2006.11610](http://arxiv.org/abs/2006.11610)|null|\n", "2005.14405": "|**2021-03-20**|**Not made for each other- Audio-Visual Dissonance-based Deepfake Detection and Localization**|Komal Chugh et.al.|[2005.14405](http://arxiv.org/abs/2005.14405)|**[link](https://github.com/abhinavdhall/deepfake)**|\n", "2005.13616": "|**2020-05-27**|**Modality Dropout for Improved Performance-driven Talking Faces**|Ahmed Hussen Abdelaziz et.al.|[2005.13616](http://arxiv.org/abs/2005.13616)|null|\n", "2005.12318": "|**2020-05-25**|**Identity-Preserving Realistic Talking Face Generation**|Sanjana Sinha et.al.|[2005.12318](http://arxiv.org/abs/2005.12318)|null|\n", "2005.10954": "|**2020-05-22**|**Head2Head: Video-based Neural Head Synthesis**|Mohammad Rami Koujan et.al.|[2005.10954](http://arxiv.org/abs/2005.10954)|null|\n", "2005.08606": "|**2021-03-19**|**End-to-End Lip Synchronisation Based on Pattern Classification**|You Jin Kim et.al.|[2005.08606](http://arxiv.org/abs/2005.08606)|null|\n", "2005.06402": "|**2020-05-13**|**FaR-GAN for One-Shot Face Reenactment**|Hanxiang Hao et.al.|[2005.06402](http://arxiv.org/abs/2005.06402)|null|\n", "2005.03201": "|**2020-05-07**|**What comprises a good talking-head video generation?: A Survey and Benchmark**|Lele Chen et.al.|[2005.03201](http://arxiv.org/abs/2005.03201)|**[link](https://github.com/lelechen63/talking-head-generation-survey)**|\n", "2004.14569": "|**2020-04-30**|**APB2Face: Audio-guided face reenactment with auxiliary pose and blink signals**|Jiangning Zhang et.al.|[2004.14569](http://arxiv.org/abs/2004.14569)|null|\n", "2004.12992": "|**2021-02-25**|**MakeItTalk: Speaker-Aware Talking-Head Animation**|Yang Zhou et.al.|[2004.12992](http://arxiv.org/abs/2004.12992)|null|\n", "2004.05478": "|**2020-05-11**|**Dancing to the Partisan Beat: A First Analysis of Political Communication on TikTok**|Juan Carlos Medina Serrano et.al.|[2004.05478](http://arxiv.org/abs/2004.05478)|**[link](https://github.com/JuanCarlosCSE/TikTok)**|\n", "2003.13840": "|**2020-03-30**|**ActGAN: Flexible and Efficient One-shot Face Reenactment**|Ivan Kosarevych et.al.|[2003.13840](http://arxiv.org/abs/2003.13840)|null|\n", "2003.12957": "|**2020-03-29**|**Realistic Face Reenactment via Self-Supervised Disentangling of Identity and Pose**|Xianfang Zeng et.al.|[2003.12957](http://arxiv.org/abs/2003.12957)|null|\n", "2003.02436": "|**2020-03-05**|**Talking-Heads Attention**|Noam Shazeer et.al.|[2003.02436](http://arxiv.org/abs/2003.02436)|**[link](https://github.com/zygmuntz/hyperband)**|\n", "2003.00418": "|**2020-03-01**|**Towards Automatic Face-to-Face Translation**|Prajwal K R et.al.|[2003.00418](http://arxiv.org/abs/2003.00418)|**[link](https://github.com/Rudrabha/LipGAN)**|\n", "2002.10137": "|**2020-03-05**|**Audio-driven Talking Face Video Generation with Learning-based Personalized Head Pose**|Ran Yi et.al.|[2002.10137](http://arxiv.org/abs/2002.10137)|**[link](https://github.com/yiranran/Audio-driven-TalkingFace-HeadPose)**|\n", "2002.08742": "|**2020-05-04**|**Disentangled Speech Embeddings using Cross-modal Self-supervision**|Arsha Nagrani et.al.|[2002.08742](http://arxiv.org/abs/2002.08742)|null|\n", "2002.08700": "|**2021-05-05**|**A Neural Lip-Sync Framework for Synthesizing Photorealistic Virtual News Anchors**|Ruobing Zheng et.al.|[2002.08700](http://arxiv.org/abs/2002.08700)|null|\n", "1912.05833": "|**2020-02-19**|**Speech-driven facial animation using polynomial fusion of features**|Triantafyllos Kefalas et.al.|[1912.05833](http://arxiv.org/abs/1912.05833)|null|\n", "1912.05566": "|**2020-07-29**|**Neural Voice Puppetry: Audio-driven Facial Reenactment**|Justus Thies et.al.|[1912.05566](http://arxiv.org/abs/1912.05566)|**[link](https://github.com/miu200521358/NeuralVoicePuppetryMMD)**|\n", "1911.09224": "|**2019-11-21**|**FLNet: Landmark Driven Fetching and Learning Network for Faithful Talking Facial Animation Synthesis**|Kuangxiao Gu et.al.|[1911.09224](http://arxiv.org/abs/1911.09224)|null|\n", "1911.08139": "|**2019-11-19**|**MarioNETte: Few-shot Face Reenactment Preserving Identity of Unseen Targets**|Sungjoo Ha et.al.|[1911.08139](http://arxiv.org/abs/1911.08139)|null|\n", "1910.12713": "|**2019-10-28**|**Few-shot Video-to-Video Synthesis**|Ting-Chun Wang et.al.|[1910.12713](http://arxiv.org/abs/1910.12713)|null|\n", "1910.08685": "|**2019-10-19**|**Real-Time Lip Sync for Live 2D Animation**|Deepali Aneja et.al.|[1910.08685](http://arxiv.org/abs/1910.08685)|**[link](https://github.com/deepalianeja/CharacterLipSync2D)**|\n", "1910.07514": "|**2019-10-16**|**Designing Style Matching Conversational Agents**|Deepali Aneja et.al.|[1910.07514](http://arxiv.org/abs/1910.07514)|null|\n", "1910.00726": "|**2019-10-02**|**Animating Face using Disentangled Audio Representations**|Gaurav Mittal et.al.|[1910.00726](http://arxiv.org/abs/1910.00726)|null|\n", "1909.08766": "|**2019-10-15**|**A High-Fidelity Open Embodied Avatar with Lip Syncing and Expression Capabilities**|Deepali Aneja et.al.|[1909.08766](http://arxiv.org/abs/1909.08766)|**[link](https://github.com/danmcduff/AvatarSim)**|\n", "1908.11039": "|**2019-08-29**|**3D Face Pose and Animation Tracking via Eigen-Decomposition based Bayesian Approach**|Ngoc-Trung Tran et.al.|[1908.11039](http://arxiv.org/abs/1908.11039)|null|\n", "1908.07226": "|**2019-08-20**|**Prosodic Phrase Alignment for Machine Dubbing**|Alp \u00d6ktem et.al.|[1908.07226](http://arxiv.org/abs/1908.07226)|**[link](https://github.com/alpoktem/MachineDub)**|\n", "1908.05932": "|**2019-08-16**|**FSGAN: Subject Agnostic Face Swapping and Reenactment**|Yuval Nirkin et.al.|[1908.05932](http://arxiv.org/abs/1908.05932)|**[link](https://github.com/YuvalNirkin/fsgan)**|\n", "1908.03251": "|**2019-08-05**|**One-shot Face Reenactment**|Yunxuan Zhang et.al.|[1908.03251](http://arxiv.org/abs/1908.03251)|**[link](https://github.com/bj80heyue/Learning_One_Shot_Face_Reenactment)**|\n", "1907.12918": "|**2019-10-09**|**EmoCo: Visual Analysis of Emotion Coherence in Presentation Videos**|Haipeng Zeng et.al.|[1907.12918](http://arxiv.org/abs/1907.12918)|null|\n", "1906.06337": "|**2019-06-14**|**Realistic Speech-Driven Facial Animation with GANs**|Konstantinos Vougioukas et.al.|[1906.06337](http://arxiv.org/abs/1906.06337)|null|\n", "1906.01524": "|**2019-06-04**|**Text-based Editing of Talking-head Video**|Ohad Fried et.al.|[1906.01524](http://arxiv.org/abs/1906.01524)|null|\n", "1905.11805": "|**2020-05-16**|**FReeNet: Multi-Identity Face Reenactment**|Jiangning Zhang et.al.|[1905.11805](http://arxiv.org/abs/1905.11805)|null|\n", "1905.08233": "|**2019-09-25**|**Few-Shot Adversarial Learning of Realistic Neural Talking Head Models**|Egor Zakharov et.al.|[1905.08233](http://arxiv.org/abs/1905.08233)|null|\n", "1905.03820": "|**2019-05-09**|**Hierarchical Cross-Modal Talking Face Generationwith Dynamic Pixel-Wise Loss**|Lele Chen et.al.|[1905.03820](http://arxiv.org/abs/1905.03820)|**[link](https://github.com/lelechen63/ATVGnet)**|\n", "1904.01909": "|**2020-01-17**|**ICface: Interpretable and Controllable Face Reenactment Using GANs**|Soumya Tripathy et.al.|[1904.01909](http://arxiv.org/abs/1904.01909)|null|\n", "1812.08685": "|**2018-12-20**|**DeepFakes: a New Threat to Face Recognition? Assessment and Detection**|Pavel Korshunov et.al.|[1812.08685](http://arxiv.org/abs/1812.08685)|null|\n", "1812.06589": "|**2020-05-13**|**Arbitrary Talking Face Generation via Attentional Audio-Visual Coherence Learning**|Hao Zhu et.al.|[1812.06589](http://arxiv.org/abs/1812.06589)|null|\n", "1812.02088": "|**2018-11-16**|**Influence of visual cues on head and eye movements during listening tasks in multi-talker audiovisual environments with animated characters**|Maartje M. E. Hendrikse et.al.|[1812.02088](http://arxiv.org/abs/1812.02088)|null|\n", "1811.00342": "|**2018-11-22**|**Towards Highly Accurate and Stable Face Alignment for High-Resolution Videos**|Ying Tai et.al.|[1811.00342](http://arxiv.org/abs/1811.00342)|**[link](https://github.com/tyshiwo/FHR_alignment)**|\n", "1809.02108": "|**2018-12-22**|**Deep Audio-Visual Speech Recognition**|Triantafyllos Afouras et.al.|[1809.02108](http://arxiv.org/abs/1809.02108)|null|\n", "1808.06250": "|**2018-08-19**|**Dynamic Temporal Alignment of Speech to Lips**|Tavi Halperin et.al.|[1808.06250](http://arxiv.org/abs/1808.06250)|**[link](https://github.com/tavihalperin/AV-sync)**|\n", "1807.11079": "|**2018-07-29**|**ReenactGAN: Learning to Reenact Faces via Boundary Transfer**|Wayne Wu et.al.|[1807.11079](http://arxiv.org/abs/1807.11079)|**[link](https://github.com/wywu/ReenactGAN)**|\n", "1807.07860": "|**2019-04-23**|**Talking Face Generation by Adversarially Disentangled Audio-Visual Representation**|Hang Zhou et.al.|[1807.07860](http://arxiv.org/abs/1807.07860)|null|\n", "1805.09313": "|**2018-07-19**|**End-to-End Speech-Driven Facial Animation with Temporal GANs**|Konstantinos Vougioukas et.al.|[1805.09313](http://arxiv.org/abs/1805.09313)|null|\n", "1805.00833": "|**2018-07-26**|**Learnable PINs: Cross-Modal Embeddings for Person Identity**|Arsha Nagrani et.al.|[1805.00833](http://arxiv.org/abs/1805.00833)|null|\n", "1804.04786": "|**2019-07-25**|**Talking Face Generation by Conditional Recurrent Adversarial Network**|Yang Song et.al.|[1804.04786](http://arxiv.org/abs/1804.04786)|**[link](https://github.com/susanqq/Talking_Face_Generation)**|\n", "1803.09803": "|**2018-04-23**|**Generating Talking Face Landmarks from Speech**|Sefik Emre Eskimez et.al.|[1803.09803](http://arxiv.org/abs/1803.09803)|null|\n", "1803.07716": "|**2018-03-28**|**Generative Adversarial Talking Head: Bringing Portraits to Life with a Weakly Supervised Neural Network**|Hai X. Pham et.al.|[1803.07716](http://arxiv.org/abs/1803.07716)|null|\n", "1803.07461": "|**2018-03-20**|**Speech-Driven Facial Reenactment Using Conditional Generative Adversarial Networks**|Seyed Ali Jalalifar et.al.|[1803.07461](http://arxiv.org/abs/1803.07461)|null|\n", "1801.01442": "|**2017-12-06**|**ObamaNet: Photo-realistic lip-sync from text**|Rithesh Kumar et.al.|[1801.01442](http://arxiv.org/abs/1801.01442)|null|\n", "1707.06830": "|**2017-07-21**|**Multichannel Attention Network for Analyzing Visual Behavior in Public Speaking**|Rahul Sharma et.al.|[1707.06830](http://arxiv.org/abs/1707.06830)|null|\n", "1705.02966": "|**2017-07-18**|**You said that?**|Joon Son Chung et.al.|[1705.02966](http://arxiv.org/abs/1705.02966)|null|\n", "1611.05358": "|**2017-01-30**|**Lip Reading Sentences in the Wild**|Joon Son Chung et.al.|[1611.05358](http://arxiv.org/abs/1611.05358)|**[link](https://github.com/parambadiger/Lip-Reading)**|\n", "1610.09380": "|**2016-10-28**|**Galaxy gas as obscurer: II. Separating the galaxy-scale and nuclear obscurers of Active Galactic Nuclei**|Johannes Buchner et.al.|[1610.09380](http://arxiv.org/abs/1610.09380)|**[link](https://github.com/JohannesBuchner/LightRayRider)**|\n", "1602.02651": "|**2016-02-08**|**Automatic Face Reenactment**|Pablo Garrido et.al.|[1602.02651](http://arxiv.org/abs/1602.02651)|null|\n", "1409.1411": "|**2014-09-03**|**Visual Speech Recognition**|Ahmad B. A. Hassanat et.al.|[1409.1411](http://arxiv.org/abs/1409.1411)|null|\n", "1201.4080": "|**2012-01-19**|**Progress in animation of an EMA-controlled tongue model for acoustic-visual speech synthesis**|Ingmar Steiner et.al.|[1201.4080](http://arxiv.org/abs/1201.4080)|null|\n", "0708.3740": "|**2007-08-28**|**Plate-forme Magicien d'Oz pour l'\u00e9tude de l'apport des ACAs \u00e0 l'interaction**|J\u00e9r\u00f4me Simonin et.al.|[0708.3740](http://arxiv.org/abs/0708.3740)|null|\n", "cs/9812006": "|**1998-12-05**|**A High Quality Text-To-Speech System Composed of Multiple Neural Networks**|Orhan Karaali et.al.|[cs/9812006](http://arxiv.org/abs/cs/9812006)|null|\n", "cmp-lg/9807012": "|**1998-07-31**|**Character design for soccer commmentary**|Kim Binsted et.al.|[cmp-lg/9807012](http://arxiv.org/abs/cmp-lg/9807012)|null|\n", "2401.06126": "|**2024-01-11**|**Dubbing for Everyone: Data-Efficient Visual Dubbing using Neural Rendering Priors**|Jack Saunders et.al.|[2401.06126](http://arxiv.org/abs/2401.06126)|null|\n", "2311.01811": "|**2024-01-12**|**DiffDub: Person-generic Visual Dubbing Using Inpainting Renderer with Diffusion Auto-encoder**|Tao Liu et.al.|[2311.01811](http://arxiv.org/abs/2311.01811)|**[link](https://github.com/liutaocode/DiffDub)**|\n", "2401.03476": "|**2024-01-07**|**Freetalker: Controllable Speech and Text-Driven Gesture Generation Based on Diffusion Models for Enhanced Speaker Naturalness**|Sicheng Yang et.al.|[2401.03476](http://arxiv.org/abs/2401.03476)|null|\n", "2310.07969": "|**2023-10-12**|**CleftGAN: Adapting A Style-Based Generative Adversarial Network To Create Images Depicting Cleft Lip Deformity**|Abdullah Hayajneh et.al.|[2310.07969](http://arxiv.org/abs/2310.07969)|**[link](https://github.com/abdullah-tamu/CleftGAN)**|\n", "2312.10877": "|**2023-12-18**|**Mimic: Speaking Style Disentanglement for Speech-Driven 3D Facial Animation**|Hui Fu et.al.|[2312.10877](http://arxiv.org/abs/2312.10877)|null|\n", "2312.09750": "|**2023-12-15**|**Attention-Based VR Facial Animation with Visual Mouth Camera Guidance for Immersive Telepresence Avatars**|Andre Rochow et.al.|[2312.09750](http://arxiv.org/abs/2312.09750)|null|\n", "2312.06530": "|**2023-12-11**|**Study of Non-Verbal Behavior in Conversational Agents**|Camila Vicari Maccari et.al.|[2312.06530](http://arxiv.org/abs/2312.06530)|null|\n", "2312.04369": "|**2023-12-08**|**SingingHead: A Large-scale 4D Dataset for Singing Head Animation**|Sijing Wu et.al.|[2312.04369](http://arxiv.org/abs/2312.04369)|null|\n", "2312.03775": "|**2023-12-20**|**FAAC: Facial Animation Generation with Anchor Frame and Conditional Control for Superior Fidelity and Editability**|Linze Li et.al.|[2312.03775](http://arxiv.org/abs/2312.03775)|null|\n", "2312.00870": "|**2023-12-01**|**3DiFACE: Diffusion-based Speech-driven 3D Facial Animation and Editing**|Balamurugan Thambiraja et.al.|[2312.00870](http://arxiv.org/abs/2312.00870)|null|\n", "2311.16565": "|**2023-12-02**|**DiffusionTalker: Personalization and Acceleration for Speech-Driven 3D Face Diffuser**|Peng Chen et.al.|[2311.16565](http://arxiv.org/abs/2311.16565)|null|\n", "2311.04766": "|**2023-11-13**|**DualTalker: A Cross-Modal Dual Learning Approach for Speech-Driven 3D Facial Animation**|Guinan Su et.al.|[2311.04766](http://arxiv.org/abs/2311.04766)|null|\n", "2310.20240": "|**2023-10-31**|**Breathing Life into Faces: Speech-driven 3D Facial Animation with Natural Head Pose and Detailed Shape**|Wei Zhao et.al.|[2310.20240](http://arxiv.org/abs/2310.20240)|null|\n", "2310.17011": "|**2023-10-25**|**Personalized Speech-driven Expressive 3D Facial Animation Synthesis with Style Control**|Elif Bozkurt et.al.|[2310.17011](http://arxiv.org/abs/2310.17011)|null|\n", "2310.07236": "|**2024-01-08**|**AdaMesh: Personalized Facial Expressions and Head Poses for Adaptive Speech-Driven 3D Facial Animation**|Liyang Chen et.al.|[2310.07236](http://arxiv.org/abs/2310.07236)|null|\n", "2309.11306": "|**2023-09-20**|**FaceDiffuser: Speech-Driven 3D Facial Animation Synthesis Using Diffusion**|Stefan Stan et.al.|[2309.11306](http://arxiv.org/abs/2309.11306)|**[link](https://github.com/uuembodiedsocialai/FaceDiffuser)**|\n", "2308.14448": "|**2023-09-11**|**ExpCLIP: Bridging Text and Facial Expressions via Semantic Alignment**|Yicheng Zhong et.al.|[2308.14448](http://arxiv.org/abs/2308.14448)|null|\n", "2310.05934": "|**2023-08-23**|**DF-3DFace: One-to-Many Speech Synchronized 3D Face Animation with Diffusion**|Se Jin Park et.al.|[2310.05934](http://arxiv.org/abs/2310.05934)|null|\n", "2308.06076": "|**2023-08-11**|**Versatile Face Animator: Driving Arbitrary 3D Facial Avatar in RGBD Space**|Haoyu Wang et.al.|[2308.06076](http://arxiv.org/abs/2308.06076)|**[link](https://github.com/why986/VFA)**|\n", "2307.01468": "|**2023-07-04**|**Generating Animatable 3D Cartoon Faces from Single Portraits**|Chuanyu Pan et.al.|[2307.01468](http://arxiv.org/abs/2307.01468)|null|\n", "2306.10006": "|**2023-09-01**|**Unsupervised Learning of Style-Aware Facial Animation from Real Acting Performances**|Wolfgang Paier et.al.|[2306.10006](http://arxiv.org/abs/2306.10006)|null|\n", "2305.10589": "|**2023-05-17**|**INCLG: Inpainting for Non-Cleft Lip Generation with a Multi-Task Image Processing Network**|Shuang Chen et.al.|[2305.10589](http://arxiv.org/abs/2305.10589)|null|\n", "2305.08854": "|**2023-08-30**|**Laughing Matters: Introducing Laughing-Face Generation using Diffusion Models**|Antoni Bigata Casademunt et.al.|[2305.08854](http://arxiv.org/abs/2305.08854)|**[link](https://github.com/antonibigata/Laughing-Matters)**|\n", "2305.03216": "|**2023-08-10**|**Near-realtime Facial Animation by Deep 3D Simulation Super-Resolution**|Hyojoon Park et.al.|[2305.03216](http://arxiv.org/abs/2305.03216)|null|\n", "2304.12051": "|**2023-04-24**|**VR Facial Animation for Immersive Telepresence Avatars**|Andre Rochow et.al.|[2304.12051](http://arxiv.org/abs/2304.12051)|null|\n", "2304.02814": "|**2023-04-06**|**4D Agnostic Real-Time Facial Animation Pipeline for Desktop Scenarios**|Wei Chen et.al.|[2304.02814](http://arxiv.org/abs/2304.02814)|null|\n", "2304.03117": "|**2023-04-01**|**DreamFace: Progressive Generation of Animatable 3D Faces under Text Guidance**|Longwen Zhang et.al.|[2304.03117](http://arxiv.org/abs/2304.03117)|null|\n", "2303.09797": "|**2023-12-13**|**MMFace4D: A Large-Scale Multi-Modal 4D Face Dataset for Audio-Driven 3D Face Animation**|Haozhe Wu et.al.|[2303.09797](http://arxiv.org/abs/2303.09797)|null|\n", "2303.06370": "|**2023-03-26**|**Distributed Solution of the Inverse Rig Problem in Blendshape Facial Animation**|Stevo Rackovi\u0107 et.al.|[2303.06370](http://arxiv.org/abs/2303.06370)|null|\n", "2303.05416": "|**2023-03-09**|**FaceXHuBERT: Text-less Speech-driven E(X)pressive 3D Facial Animation Synthesis Using Self-Supervised Speech Representation Learning**|Kazi Injamamul Haque et.al.|[2303.05416](http://arxiv.org/abs/2303.05416)|**[link](https://github.com/galib360/facexhubert)**|\n", "2303.03988": "|**2023-03-07**|**DINet: Deformation Inpainting Network for Realistic Face Visually Dubbing on High Resolution Video**|Zhimeng Zhang et.al.|[2303.03988](http://arxiv.org/abs/2303.03988)|**[link](https://github.com/MRzzm/DINet)**|\n", "2302.04843": "|**2023-03-27**|**Accurate and Interpretable Solution of the Inverse Rig for Realistic Blendshape Models with Quadratic Corrective Terms**|Stevo Rackovi\u0107 et.al.|[2302.04843](http://arxiv.org/abs/2302.04843)|null|\n", "2301.06059": "|**2023-01-15**|**Learning Audio-Driven Viseme Dynamics for 3D Face Animation**|Linchao Bao et.al.|[2301.06059](http://arxiv.org/abs/2301.06059)|null|\n", "2301.02008": "|**2024-01-04**|**Expressive Speech-driven Facial Animation with controllable emotions**|Yutong Chen et.al.|[2301.02008](http://arxiv.org/abs/2301.02008)|**[link](https://github.com/on1262/facialanimation)**|\n", "2301.00023": "|**2022-12-30**|**Imitator: Personalized Speech-driven 3D Facial Animation**|Balamurugan Thambiraja et.al.|[2301.00023](http://arxiv.org/abs/2301.00023)|null|\n", "2212.14784": "|**2023-01-20**|**Neural Volumetric Blendshapes: Computationally Efficient Physics-Based Facial Blendshapes**|Nicolas Wagner et.al.|[2212.14784](http://arxiv.org/abs/2212.14784)|null|\n", "2211.16710": "|**2022-11-30**|**Extracting Semantic Knowledge from GANs with Unsupervised Learning**|Jianjin Xu et.al.|[2211.16710](http://arxiv.org/abs/2211.16710)|null|\n", "2208.01149": "|**2022-08-01**|**A Feasibility Study on Image Inpainting for Non-cleft Lip Generation from Patients with Cleft Lip**|Shuang Chen et.al.|[2208.01149](http://arxiv.org/abs/2208.01149)|**[link](https://github.com/chrischen1023/nclg-mt)**|\n", "2401.08049": "|**2024-01-16**|**EmoTalker: Emotionally Editable Talking Face Generation via Diffusion Model**|Bingyuan Zhang et.al.|[2401.08049](http://arxiv.org/abs/2401.08049)|null|\n", "2401.08503": "|**2024-03-23**|**Real3D-Portrait: One-shot Realistic 3D Talking Portrait Synthesis**|Zhenhui Ye et.al.|[2401.08503](http://arxiv.org/abs/2401.08503)|**[link](https://github.com/yerfor/Real3DPortrait)**|\n", "2401.08655": "|**2024-01-25**|**SAiD: Speech-driven Blendshape Facial Animation with Diffusion**|Inkyu Park et.al.|[2401.08655](http://arxiv.org/abs/2401.08655)|**[link](https://github.com/yunik1004/said)**|\n", "2401.10113": "|**2024-01-18**|**Exposing Lip-syncing Deepfakes from Mouth Inconsistencies**|Soumyya Kanti Datta et.al.|[2401.10113](http://arxiv.org/abs/2401.10113)|**[link](https://github.com/skrantidatta/lipinc)**|\n", "2401.11002": "|**2024-01-19**|**Fast Registration of Photorealistic Avatars for VR Facial Animation**|Chaitanya Patel et.al.|[2401.11002](http://arxiv.org/abs/2401.11002)|null|\n", "2401.12568": "|**2024-01-23**|**NeRF-AD: Neural Radiance Field with Attention-based Disentanglement for Talking Face Synthesis**|Chongke Bi et.al.|[2401.12568](http://arxiv.org/abs/2401.12568)|null|\n", "2401.14861": "|**2024-01-26**|**Implicit Neural Representation for Physics-driven Actuated Soft Bodies**|Lingchen Yang et.al.|[2401.14861](http://arxiv.org/abs/2401.14861)|null|\n", "2401.15687": "|**2024-01-30**|**Media2Face: Co-speech Facial Animation Generation With Multi-Modality Guidance**|Qingcheng Zhao et.al.|[2401.15687](http://arxiv.org/abs/2401.15687)|null|\n", "2401.15668": "|**2024-01-28**|**Lips Are Lying: Spotting the Temporal Inconsistency between Audio and Visual in Lip-Syncing DeepFakes**|Weifeng Liu et.al.|[2401.15668](http://arxiv.org/abs/2401.15668)|**[link](https://github.com/aaroncomo/lipfd)**|\n", "2401.15414": "|**2024-01-27**|**An Implicit Physical Face Model Driven by Expression and Style**|Lingchen Yang et.al.|[2401.15414](http://arxiv.org/abs/2401.15414)|null|\n", "2402.01422": "|**2024-02-02**|**EmoSpeaker: One-shot Fine-grained Emotion-Controlled Talking Face Generation**|Guanwen Feng et.al.|[2402.01422](http://arxiv.org/abs/2402.01422)|null|\n", "2402.03553": "|**2024-02-05**|**One-shot Neural Face Reenactment via Finding Directions in GAN's Latent Space**|Stella Bounareli et.al.|[2402.03553](http://arxiv.org/abs/2402.03553)|null|\n", "2402.05712": "|**2024-02-08**|**DiffSpeaker: Speech-Driven 3D Facial Animation with Diffusion Transformer**|Zhiyuan Ma et.al.|[2402.05712](http://arxiv.org/abs/2402.05712)|**[link](https://github.com/theericma/diffspeaker)**|\n", "2402.12636": "|**2024-02-21**|**StyleDubber: Towards Multi-Scale Style Learning for Movie Dubbing**|Gaoxiang Cong et.al.|[2402.12636](http://arxiv.org/abs/2402.12636)|**[link](https://github.com/galaxycong/styledubber)**|\n", "2402.13724": "|**2024-02-21**|**Bring Your Own Character: A Holistic Solution for Automatic Facial Animation Generation of Customized Characters**|Zechen Bai et.al.|[2402.13724](http://arxiv.org/abs/2402.13724)|**[link](https://github.com/showlab/byoc)**|\n", "2402.16124": "|**2024-02-25**|**AVI-Talking: Learning Audio-Visual Instructions for Expressive 3D Talking Face Generation**|Yasheng Sun et.al.|[2402.16124](http://arxiv.org/abs/2402.16124)|null|\n", "2402.17485": "|**2024-02-27**|**EMO: Emote Portrait Alive -- Generating Expressive Portrait Videos with Audio2Video Diffusion Model under Weak Conditions**|Linrui Tian et.al.|[2402.17485](http://arxiv.org/abs/2402.17485)|null|\n", "2402.17364": "|**2024-02-27**|**Learning Dynamic Tetrahedra for High-Quality Talking Head Synthesis**|Zicheng Zhang et.al.|[2402.17364](http://arxiv.org/abs/2402.17364)|**[link](https://github.com/zhangzc21/dyntet)**|\n", "2402.16599": "|**2024-02-26**|**Resolution-Agnostic Neural Compression for High-Fidelity Portrait Video Conferencing via Implicit Radiance Fields**|Yifei Li et.al.|[2402.16599](http://arxiv.org/abs/2402.16599)|null|\n", "2402.18122": "|**2024-03-02**|**G4G:A Generic Framework for High Fidelity Talking Face Generation with Fine-grained Intra-modal Alignment**|Juan Zhang et.al.|[2402.18122](http://arxiv.org/abs/2402.18122)|null|\n", "2402.18092": "|**2024-02-28**|**Context-aware Talking Face Video Generation**|Meidai Xuanyuan et.al.|[2402.18092](http://arxiv.org/abs/2402.18092)|null|\n", "2402.19477": "|**2024-02-29**|**Learning a Generalized Physical Face Model From Data**|Lingchen Yang et.al.|[2402.19477](http://arxiv.org/abs/2402.19477)|null|\n", "2403.01901": "|**2024-04-01**|**FaceChain-ImagineID: Freely Crafting High-Fidelity Diverse Talking Faces from Disentangled Audio**|Chao Xu et.al.|[2403.01901](http://arxiv.org/abs/2403.01901)|**[link](https://github.com/modelscope/facechain)**|\n", "2403.06421": "|**2024-03-11**|**A Comparative Study of Perceptual Quality Metrics for Audio-driven Talking Head Videos**|Weixia Zhang et.al.|[2403.06421](http://arxiv.org/abs/2403.06421)|**[link](https://github.com/zwx8981/adth-qa)**|\n", "2403.06375": "|**2024-03-12**|**FlowVQTalker: High-Quality Emotional Talking Face Generation through Normalizing Flow and Quantization**|Shuai Tan et.al.|[2403.06375](http://arxiv.org/abs/2403.06375)|null|\n", "2403.06365": "|**2024-03-12**|**Style2Talker: High-Resolution Talking Head Generation with Emotion Style and Art Style**|Shuai Tan et.al.|[2403.06365](http://arxiv.org/abs/2403.06365)|null|\n", "2403.06363": "|**2024-03-13**|**Say Anything with Any Style**|Shuai Tan et.al.|[2403.06363](http://arxiv.org/abs/2403.06363)|null|\n", "2403.11700": "|**2024-03-22**|**Virbo: Multimodal Multilingual Avatar Video Generation in Digital Marketing**|Juan Zhang et.al.|[2403.11700](http://arxiv.org/abs/2403.11700)|null|\n", "2403.10942": "|**2024-03-19**|**ScanTalk: 3D Talking Heads from Unregistered Scans**|Federico Nocentini et.al.|[2403.10942](http://arxiv.org/abs/2403.10942)|**[link](https://github.com/miccunifi/scantalk)**|\n", "2403.12886": "|**2024-03-19**|**EmoVOCA: Speech-Driven Emotional 3D Talking Heads**|Federico Nocentini et.al.|[2403.12886](http://arxiv.org/abs/2403.12886)|**[link](https://github.com/miccunifi/EmoVOCA)**|\n", "2403.15227": "|**2024-03-22**|**LeGO: Leveraging a Surface Deformation Network for Animatable Stylized Face Generation with One Example**|Soyeon Yoon et.al.|[2403.15227](http://arxiv.org/abs/2403.15227)|**[link](https://github.com/kwanyun/LeGO_code)**|\n", "2403.16510": "|**2024-03-25**|**Make-Your-Anchor: A Diffusion-based 2D Avatar Generation Framework**|Ziyao Huang et.al.|[2403.16510](http://arxiv.org/abs/2403.16510)|**[link](https://github.com/ictmcg/make-your-anchor)**|\n", "2403.15944": "|**2024-03-23**|**Adaptive Super Resolution For One-Shot Talking-Head Generation**|Luchuan Song et.al.|[2403.15944](http://arxiv.org/abs/2403.15944)|**[link](https://github.com/songluchuan/adasr-talkinghead)**|\n", "2403.15931": "|**2024-03-27**|**X-Portrait: Expressive Portrait Animation with Hierarchical Motion Attention**|You Xie et.al.|[2403.15931](http://arxiv.org/abs/2403.15931)|null|\n", "2403.17883": "|**2024-03-26**|**Superior and Pragmatic Talking Face Generation with Teacher-Student Framework**|Chao Liang et.al.|[2403.17883](http://arxiv.org/abs/2403.17883)|null|\n", "2403.17881": "|**2024-04-09**|**Deepfake Generation and Detection: A Benchmark and Survey**|Gan Pei et.al.|[2403.17881](http://arxiv.org/abs/2403.17881)|**[link](https://github.com/flyingby/awesome-deepfake-generation-and-detection)**|\n", "2403.17694": "|**2024-03-26**|**AniPortrait: Audio-Driven Synthesis of Photorealistic Portrait Animation**|Huawei Wei et.al.|[2403.17694](http://arxiv.org/abs/2403.17694)|**[link](https://github.com/scutzzj/aniportrait)**|\n", "2403.17217": "|**2024-03-25**|**DiffusionAct: Controllable Diffusion Autoencoder for One-shot Face Reenactment**|Stella Bounareli et.al.|[2403.17217](http://arxiv.org/abs/2403.17217)|null|\n", "2403.17213": "|**2024-03-25**|**AnimateMe: 4D Facial Expressions via Diffusion Models**|Dimitrios Gerogiannis et.al.|[2403.17213](http://arxiv.org/abs/2403.17213)|null|\n", "2403.19144": "|**2024-03-28**|**MoDiTalker: Motion-Disentangled Diffusion Model for High-Fidelity Talking Head Generation**|Seyeon Kim et.al.|[2403.19144](http://arxiv.org/abs/2403.19144)|**[link](https://github.com/KU-CVLAB/MoDiTalker)**|\n", "2403.20153": "|**2024-03-29**|**Talk3D: High-Fidelity Talking Portrait Synthesis via Personalized 3D Generative Prior**|Jaehoon Ko et.al.|[2403.20153](http://arxiv.org/abs/2403.20153)|**[link](https://github.com/KU-CVLAB/Talk3D)**|\n", "2403.19920": "|**2024-04-03**|**MI-NeRF: Learning a Single Face NeRF from Multiple Identities**|Aggelina Chatziagapi et.al.|[2403.19920](http://arxiv.org/abs/2403.19920)|null|\n", "2404.01647": "|**2024-04-02**|**EDTalk: Efficient Disentanglement for Emotional Talking Head Synthesis**|Shuai Tan et.al.|[2404.01647](http://arxiv.org/abs/2404.01647)|null|\n", "2404.00636": "|**2024-04-02**|**Learning to Generate Conditional Tri-plane for 3D-aware Expression Controllable Portrait Animation**|Taekyung Ki et.al.|[2404.00636](http://arxiv.org/abs/2404.00636)|null|\n", "2404.05680": "|**2024-04-08**|**SphereHead: Stable 3D Full-head Synthesis with Spherical Tri-plane Representation**|Heyuan Li et.al.|[2404.05680](http://arxiv.org/abs/2404.05680)|null|\n", "2404.04924": "|**2024-04-07**|**GvT: A Graph-based Vision Transformer with Talking-Heads Utilizing Sparsity, Trained from Scratch on Small Datasets**|Dongjing Shan et.al.|[2404.04924](http://arxiv.org/abs/2404.04924)|null|\n", "2404.09736": "|**2024-04-15**|**FSRT: Facial Scene Representation Transformer for Face Reenactment from Factorized Appearance, Head-pose, and Facial Expression Features**|Andre Rochow et.al.|[2404.09736](http://arxiv.org/abs/2404.09736)|null|\n", "2404.09003": "|**2024-04-13**|**THQA: A Perceptual Quality Assessment Database for Talking Heads**|Yingjie Zhou et.al.|[2404.09003](http://arxiv.org/abs/2404.09003)|**[link](https://github.com/zyj-2000/thqa)**|\n", "2404.10667": "|**2024-04-16**|**VASA-1: Lifelike Audio-Driven Talking Faces Generated in Real Time**|Sicheng Xu et.al.|[2404.10667](http://arxiv.org/abs/2404.10667)|null|\n", "2309.08408": "|**2023-09-15**|**Audio-Visual Active Speaker Extraction for Sparsely Overlapped Multi-talker Speech**|Junjie Li et.al.|[2309.08408](http://arxiv.org/abs/2309.08408)|**[link](https://github.com/mrjunjieli/activeextract)**|\n", "2309.06511": "|**2023-09-12**|**DF-TransFusion: Multimodal Deepfake Detection via Lip-Audio Cross-Attention and Facial Self-Attention**|Aaditya Kharel et.al.|[2309.06511](http://arxiv.org/abs/2309.06511)|null|\n", "2307.09323": "|**2023-08-24**|**Efficient Region-Aware Neural Radiance Fields for High-Fidelity Talking Portrait Synthesis**|Jiahe Li et.al.|[2307.09323](http://arxiv.org/abs/2307.09323)|**[link](https://github.com/fictionarry/er-nerf)**|\n", "2306.07476": "|**2023-06-13**|**AniFaceDrawing: Anime Portrait Exploration during Your Sketching**|Zhengyu Huang et.al.|[2306.07476](http://arxiv.org/abs/2306.07476)|null|\n", "2212.13810": "|**2022-12-28**|**All's well that FID's well? Result quality and metric scores in GAN models for lip-sychronization tasks**|Carina Geldhauser et.al.|[2212.13810](http://arxiv.org/abs/2212.13810)|null|\n", "2211.12368": "|**2022-11-22**|**Real-time Neural Radiance Talking Portrait Synthesis via Audio-spatial Decomposition**|Jiaxiang Tang et.al.|[2211.12368](http://arxiv.org/abs/2211.12368)|null|\n", "2211.06627": "|**2023-03-22**|**MARLIN: Masked Autoencoder for facial video Representation LearnINg**|Zhixi Cai et.al.|[2211.06627](http://arxiv.org/abs/2211.06627)|**[link](https://github.com/ControlNet/MARLIN)**|\n", "2207.13530": "|**2022-07-27**|**A Hybrid Deep Animation Codec for Low-bitrate Video Conferencing**|Goluck Konuko et.al.|[2207.13530](http://arxiv.org/abs/2207.13530)|null|\n", "2207.00974": "|**2022-07-20**|**NARRATE: A Normal Assisted Free-View Portrait Stylizer**|Youjia Wang et.al.|[2207.00974](http://arxiv.org/abs/2207.00974)|null|\n", "2206.04523": "|**2022-06-09**|**Face-Dubbing++: Lip-Synchronous, Voice Preserving Translation of Videos**|Alexander Waibel et.al.|[2206.04523](http://arxiv.org/abs/2206.04523)|null|\n", "2205.15573": "|**2022-05-31**|**Text/Speech-Driven Full-Body Animation**|Wenlin Zhuang et.al.|[2205.15573](http://arxiv.org/abs/2205.15573)|null|\n", "2205.04289": "|**2023-03-27**|**A Majorization-Minimization Based Method for Nonconvex Inverse Rig Problems in Facial Animation: Algorithm Derivation**|Stevo Rackovi\u0107 et.al.|[2205.04289](http://arxiv.org/abs/2205.04289)|null|\n", "2203.16224": "|**2022-03-30**|**End to End Lip Synchronization with a Temporal AutoEncoder**|Yoav Shalev et.al.|[2203.16224](http://arxiv.org/abs/2203.16224)|**[link](https://github.com/itsyoavshalev/end-to-end-lip-synchronization-with-a-temporal-autoencoder)**|\n", "2203.08765": "|**2022-03-16**|**Efficient conditioned face animation using frontally-viewed embedding**|Maxime Oquab et.al.|[2203.08765](http://arxiv.org/abs/2203.08765)|null|\n", "2112.05329": "|**2022-03-17**|**FaceFormer: Speech-Driven 3D Facial Animation with Transformers**|Yingruo Fan et.al.|[2112.05329](http://arxiv.org/abs/2112.05329)|**[link](https://github.com/EvelynFan/FaceFormer)**|\n", "2112.02214": "|**2021-12-07**|**Joint Audio-Text Model for Expressive Speech-Driven 3D Facial Animation**|Yingruo Fan et.al.|[2112.02214](http://arxiv.org/abs/2112.02214)|null|\n", "2111.09771": "|**2022-04-06**|**Transformer-S2A: Robust and Efficient Speech-to-Animation**|Liyang Chen et.al.|[2111.09771](http://arxiv.org/abs/2111.09771)|null|\n", "2111.02751": "|**2021-11-04**|**FEAFA+: An Extended Well-Annotated Dataset for Facial Expression Analysis and 3D Facial Animation**|Wei Gan et.al.|[2111.02751](http://arxiv.org/abs/2111.02751)|null|\n", "2109.08356": "|**2021-09-20**|**Accurate, Interpretable, and Fast Animation: An Iterative, Sparse, and Nonconvex Approach**|Stevo Rackovic et.al.|[2109.08356](http://arxiv.org/abs/2109.08356)|null|\n", "2109.08061": "|**2021-10-22**|**Invertible Frowns: Video-to-Video Facial Emotion Translation**|Ian Magnusson et.al.|[2109.08061](http://arxiv.org/abs/2109.08061)|null|\n", "2108.07949": "|**2021-08-18**|**DeepFake MNIST+: A DeepFake Facial Animation Dataset**|Jiajun Huang et.al.|[2108.07949](http://arxiv.org/abs/2108.07949)|**[link](https://github.com/huangjiadidi/DeepFakeMnist)**|\n", "2106.07150": "|**2022-01-24**|**Selective Listening by Synchronizing Speech with Lips**|Zexu Pan et.al.|[2106.07150](http://arxiv.org/abs/2106.07150)|**[link](https://github.com/zexupan/reentry)**|\n", "2104.08223": "|**2022-05-20**|**MeshTalk: 3D Face Animation from Speech using Cross-Modality Disentanglement**|Alexander Richard et.al.|[2104.08223](http://arxiv.org/abs/2104.08223)|**[link](https://github.com/facebookresearch/meshtalk)**|\n", "2011.03530": "|**2020-11-06**|**Large-scale multilingual audio visual dubbing**|Yi Yang et.al.|[2011.03530](http://arxiv.org/abs/2011.03530)|null|\n", "2010.05655": "|**2020-10-12**|**Intuitive Facial Animation Editing Based On A Generative RNN Framework**|Elo\u00efse Berson et.al.|[2010.05655](http://arxiv.org/abs/2010.05655)|null|\n", "2010.00560": "|**2020-10-05**|**Dynamic Facial Asset and Rig Generation from a Single Scan**|Jiaman Li et.al.|[2010.00560](http://arxiv.org/abs/2010.00560)|null|\n", "2009.09354": "|**2020-09-20**|**An Improved Approach of Intention Discovery with Machine Learning for POMDP-based Dialogue Management**|Ruturaj Raval et.al.|[2009.09354](http://arxiv.org/abs/2009.09354)|null|\n", "2008.05023": "|**2020-08-11**|**Audio- and Gaze-driven Facial Animation of Codec Avatars**|Alexander Richard et.al.|[2008.05023](http://arxiv.org/abs/2008.05023)|null|\n", "2008.01332": "|**2020-08-04**|**Real-Time Cleaning and Refinement of Facial Animation Signals**|Elo\u00efse Berson et.al.|[2008.01332](http://arxiv.org/abs/2008.01332)|null|\n", "2007.09367": "|**2020-07-18**|**A Robust Interactive Facial Animation Editing System**|Elo\u00efse Berson et.al.|[2007.09367](http://arxiv.org/abs/2007.09367)|null|\n", "2007.03780": "|**2021-08-06**|**SofGAN: A Portrait Image Generator with Dynamic Styling**|Anpei Chen et.al.|[2007.03780](http://arxiv.org/abs/2007.03780)|**[link](https://github.com/apchenstu/sofgan)**|\n", "2003.11038": "|**2020-07-20**|**Deformable Style Transfer**|Sunnie S. Y. Kim et.al.|[2003.11038](http://arxiv.org/abs/2003.11038)|**[link](https://github.com/sunniesuhyoung/DST)**|\n", "2003.06211": "|**2020-03-26**|**High-Accuracy Facial Depth Models derived from 3D Synthetic Data**|Faisal Khan et.al.|[2003.06211](http://arxiv.org/abs/2003.06211)|null|\n", "1909.02518": "|**2019-09-06**|**Neural Style-Preserving Visual Dubbing**|Hyeongwoo Kim et.al.|[1909.02518](http://arxiv.org/abs/1909.02518)|null|\n", "1908.03904": "|**2019-08-11**|**Emotion Dependent Facial Animation from Affective Speech**|Rizwan Sadiq et.al.|[1908.03904](http://arxiv.org/abs/1908.03904)|null|\n", "1907.10402": "|**2019-07-24**|**Data-Driven Physical Face Inversion**|Yeara Kozlov et.al.|[1907.10402](http://arxiv.org/abs/1907.10402)|null|\n", "1907.10163": "|**2019-07-23**|**A system for efficient 3D printed stop-motion face animation**|Rinat Abdrashitov et.al.|[1907.10163](http://arxiv.org/abs/1907.10163)|null|\n", "1905.11142": "|**2019-05-27**|**Audio2Face: Generating Speech/Face Animation from Single Audio with Attention-Based Bidirectional LSTM Networks**|Guanzhong Tian et.al.|[1905.11142](http://arxiv.org/abs/1905.11142)|null|\n", "1905.10742": "|**2019-12-20**|**Disentangling Style and Content in Anime Illustrations**|Sitao Xiang et.al.|[1905.10742](http://arxiv.org/abs/1905.10742)|null|\n", "1905.03079": "|**2019-05-08**|**Capture, Learning, and Synthesis of 3D Speaking Styles**|Daniel Cudeiro et.al.|[1905.03079](http://arxiv.org/abs/1905.03079)|**[link](https://github.com/TimoBolkart/voca)**|\n", "1904.01509": "|**2019-04-02**|**FEAFA: A Well-Annotated Dataset for Facial Expression Analysis and 3D Facial Animation**|Yanfu Yan et.al.|[1904.01509](http://arxiv.org/abs/1904.01509)|null|\n", "1903.05448": "|**2019-03-13**|**Animating an Autonomous 3D Talking Avatar**|Dominik Borer et.al.|[1903.05448](http://arxiv.org/abs/1903.05448)|null|\n", "1807.09251": "|**2018-08-28**|**GANimation: Anatomically-aware Facial Animation from a Single Image**|Albert Pumarola et.al.|[1807.09251](http://arxiv.org/abs/1807.09251)|**[link](https://github.com/albertpumarola/GANimation)**|\n", "1805.11714": "|**2018-05-29**|**Deep Video Portraits**|Hyeongwoo Kim et.al.|[1805.11714](http://arxiv.org/abs/1805.11714)|null|\n", "1805.09488": "|**2018-05-24**|**VisemeNet: Audio-Driven Animator-Centric Speech Animation**|Yang Zhou et.al.|[1805.09488](http://arxiv.org/abs/1805.09488)|null|\n", "1805.07997": "|**2018-05-21**|**Anime Style Space Exploration Using Metric Learning and Generative Adversarial Networks**|Sitao Xiang et.al.|[1805.07997](http://arxiv.org/abs/1805.07997)|null|\n", "1710.00920": "|**2017-12-07**|**End-to-end Learning for 3D Facial Animation from Raw Waveforms of Speech**|Hai X. Pham et.al.|[1710.00920](http://arxiv.org/abs/1710.00920)|null|\n", "1707.09629": "|**2017-07-30**|**Kernel Projection of Latent Structures Regression for Facial Animation Retargeting**|Christos Ouzounis et.al.|[1707.09629](http://arxiv.org/abs/1707.09629)|null|\n", "1707.08289": "|**2017-07-26**|**Fast Deep Matting for Portrait Animation on Mobile Phone**|Bingke Zhu et.al.|[1707.08289](http://arxiv.org/abs/1707.08289)|null|\n", "1601.06684": "|**2016-07-11**|**Large-Scale MIMO is Capable of Eliminating Power-Thirsty Channel Coding for Wireless Transmission of HEVC/H.265 Video**|Shaoshi Yang et.al.|[1601.06684](http://arxiv.org/abs/1601.06684)|null|\n", "1512.08212": "|**2016-05-22**|**Improving Facial Analysis and Performance Driven Animation through Disentangling Identity and Expression**|David Rim et.al.|[1512.08212](http://arxiv.org/abs/1512.08212)|null|\n", "1511.06502": "|**2015-11-20**|**ExpressionBot: An Emotive Lifelike Robotic Face for Face-to-Face Communication**|Ali Mollahosseini et.al.|[1511.06502](http://arxiv.org/abs/1511.06502)|null|\n", "1209.4982": "|**2012-09-22**|**Using multimodal speech production data to evaluate articulatory animation for audiovisual speech synthesis**|Ingmar Steiner et.al.|[1209.4982](http://arxiv.org/abs/1209.4982)|null|\n", "1203.6722": "|**2012-03-30**|**Face Expression Recognition and Analysis: The State of the Art**|Vinay Bettadapura et.al.|[1203.6722](http://arxiv.org/abs/1203.6722)|null|\n", "1003.0431": "|**2010-03-01**|**Re-verification of a Lip Synchronization Protocol using Robust Reachability**|Piotr Kordy et.al.|[1003.0431](http://arxiv.org/abs/1003.0431)|null|\n", "0912.0600": "|**2009-12-03**|**Sequential Clustering based Facial Feature Extraction Method for Automatic Creation of Facial Models from Orthogonal Views**|Alireza Ghahari et.al.|[0912.0600](http://arxiv.org/abs/0912.0600)|null|\n", "0812.2988": "|**2008-12-16**|**The Korrontea Data Modeling**|Emmanuel Bouix et.al.|[0812.2988](http://arxiv.org/abs/0812.2988)|null|\n", "cmp-lg/9406002": "|**1994-06-01**|**Speech Dialogue with Facial Displays: Multimodal Human-Computer Conversation**|Katashi Nagao et.al.|[cmp-lg/9406002](http://arxiv.org/abs/cmp-lg/9406002)|null|\n", "2404.12888": "|**2024-04-19**|**Learn2Talk: 3D Talking Face Learns from 2D Talking Face**|Yixiang Zhuang et.al.|[2404.12888](http://arxiv.org/abs/2404.12888)|null|\n", "2404.14037": "|**2024-04-28**|**GaussianTalker: Speaker-specific Talking Head Synthesis via 3D Gaussian Splatting**|Hongyun Yu et.al.|[2404.14037](http://arxiv.org/abs/2404.14037)|null|\n", "2404.15264": "|**2024-04-23**|**TalkingGaussian: Structure-Persistent 3D Talking Head Synthesis via Gaussian Splatting**|Jiahe Li et.al.|[2404.15264](http://arxiv.org/abs/2404.15264)|**[link](https://github.com/Fictionarry/TalkingGaussian)**|\n", "2404.16012": "|**2024-04-25**|**GaussianTalker: Real-Time High-Fidelity Talking Head Synthesis with Audio-Driven 3D Gaussian Splatting**|Kyusun Cho et.al.|[2404.16012](http://arxiv.org/abs/2404.16012)|**[link](https://github.com/ku-cvlab/gaussiantalker)**|\n", "2404.18604": "|**2024-04-29**|**CSTalk: Correlation Supervised Speech-driven 3D Emotional Facial Animation Generation**|Xiangyu Liang et.al.|[2404.18604](http://arxiv.org/abs/2404.18604)|null|\n", "2404.18501": "|**2024-05-08**|**Audio-Visual Target Speaker Extraction with Reverse Selective Auditory Attention**|Ruijie Tao et.al.|[2404.18501](http://arxiv.org/abs/2404.18501)|**[link](https://github.com/taoruijie/seanet)**|\n", "2404.19110": "|**2024-04-29**|**EMOPortraits: Emotion-enhanced Multimodal One-shot Head Avatars**|Nikita Drobyshev et.al.|[2404.19110](http://arxiv.org/abs/2404.19110)|null|\n", "2404.19040": "|**2024-04-29**|**GSTalker: Real-time Audio-Driven Talking Face Generation via Deformable Gaussian Splatting**|Bo Chen et.al.|[2404.19040](http://arxiv.org/abs/2404.19040)|null|\n", "2404.19038": "|**2024-04-29**|**Embedded Representation Learning Network for Animating Styled Video Portrait**|Tianyong Wang et.al.|[2404.19038](http://arxiv.org/abs/2404.19038)|null|\n", "2405.03121": "|**2024-05-06**|**AniTalker: Animate Vivid and Diverse Talking Faces through Identity-Decoupled Facial Motion Encoding**|Tao Liu et.al.|[2405.03121](http://arxiv.org/abs/2405.03121)|**[link](https://github.com/x-lance/anitalker)**|\n", "2405.04327": "|**2024-05-07**|**Audio-Visual Speech Representation Expert for Enhanced Talking Face Video Generation and Evaluation**|Dogucan Yaman et.al.|[2405.04327](http://arxiv.org/abs/2405.04327)|null|\n", "2405.05749": "|**2024-05-10**|**NeRFFaceSpeech: One-shot Audio-driven 3D Talking Head Synthesis via Generative Prior**|Gihoon Kim et.al.|[2405.05749](http://arxiv.org/abs/2405.05749)|null|\n", "2405.05636": "|**2024-05-09**|**SwapTalk: Audio-Driven Talking Face Generation with One-Shot Customization in Latent Space**|Zeren Zhang et.al.|[2405.05636](http://arxiv.org/abs/2405.05636)|null|\n", "2405.07257": "|**2024-05-12**|**Listen, Disentangle, and Control: Controllable Speech-Driven Talking Head Generation**|Changpeng Cai et.al.|[2405.07257](http://arxiv.org/abs/2405.07257)|null|\n", "2405.08838": "|**2024-05-14**|**PolyGlotFake: A Novel Multilingual and Multimodal DeepFake Dataset**|Yang Hou et.al.|[2405.08838](http://arxiv.org/abs/2405.08838)|**[link](https://github.com/tobuta/PolyGlotFake)**|\n", "2405.10272": "|**2024-05-16**|**Faces that Speak: Jointly Synthesising Talking Face and Speech from Text**|Youngjoon Jang et.al.|[2405.10272](http://arxiv.org/abs/2405.10272)|null|\n", "2405.12970": "|**2024-05-21**|**Face Adapter for Pre-Trained Diffusion Models with Fine-Grained ID and Attribute Control**|Yue Han et.al.|[2405.12970](http://arxiv.org/abs/2405.12970)|null|\n", "2405.14709": "|**2024-05-28**|**OpFlowTalker: Realistic and Natural Talking Face Generation via Optical Flow Guidance**|Shuheng Ge et.al.|[2405.14709](http://arxiv.org/abs/2405.14709)|null|\n", "2405.13701": "|**2024-05-22**|**Metabook: An Automatically Generated Augmented Reality Storybook Interaction System to Improve Children's Engagement in Storytelling**|Yibo Wang et.al.|[2405.13701](http://arxiv.org/abs/2405.13701)|null|\n", "2405.15758": "|**2024-05-24**|**InstructAvatar: Text-Guided Emotion and Motion Control for Avatar Generation**|Yuchi Wang et.al.|[2405.15758](http://arxiv.org/abs/2405.15758)|**[link](https://github.com/wangyuchi369/InstructAvatar)**|\n", "2405.19688": "|**2024-06-14**|**DNPM: A Neural Parametric Model for the Synthesis of Facial Geometric Details**|Haitao Cao et.al.|[2405.19688](http://arxiv.org/abs/2405.19688)|null|\n", "2405.21004": "|**2024-05-31**|**MunchSonic: Tracking Fine-grained Dietary Actions through Active Acoustic Sensing on Eyeglasses**|Saif Mahmud et.al.|[2405.21004](http://arxiv.org/abs/2405.21004)|null|\n", "2405.20851": "|**2024-05-31**|**MegActor: Harness the Power of Raw Video for Vivid Portrait Animation**|Shurong Yang et.al.|[2405.20851](http://arxiv.org/abs/2405.20851)|**[link](https://github.com/megvii-research/megfaceanimate)**|\n", "2405.20412": "|**2024-05-30**|**Audio2Rig: Artist-oriented deep learning tool for facial animation**|Bastien Arcelin et.al.|[2405.20412](http://arxiv.org/abs/2405.20412)|null|\n", "2406.01900": "|**2024-06-07**|**Follow-Your-Emoji: Fine-Controllable and Expressive Freestyle Portrait Animation**|Yue Ma et.al.|[2406.01900](http://arxiv.org/abs/2406.01900)|null|\n", "2406.02880": "|**2024-06-05**|**Controllable Talking Face Generation by Implicit Facial Keypoints Editing**|Dong Zhao et.al.|[2406.02880](http://arxiv.org/abs/2406.02880)|**[link](https://github.com/NetEase-Media/ControlTalk)**|\n", "2406.08096": "|**2024-06-17**|**Make Your Actor Talk: Generalizable and High-Fidelity Lip Sync with Motion and Appearance Disentanglement**|Runyi Yu et.al.|[2406.08096](http://arxiv.org/abs/2406.08096)|null|\n", "2406.07895": "|**2024-06-12**|**Emotional Conversation: Empowering Talking Faces with Cohesive Expression, Gaze and Pose Generation**|Jiadong Liang et.al.|[2406.07895](http://arxiv.org/abs/2406.07895)|null|\n", "2406.08802": "|**2024-06-13**|**DubWise: Video-Guided Speech Duration Control in Multimodal LLM-based Text-to-Speech for Dubbing**|Neha Sahipjohn et.al.|[2406.08802](http://arxiv.org/abs/2406.08802)|null|\n", "2406.08801": "|**2024-06-16**|**Hallo: Hierarchical Audio-Driven Visual Synthesis for Portrait Image Animation**|Mingwang Xu et.al.|[2406.08801](http://arxiv.org/abs/2406.08801)|null|\n", "2406.09519": "|**2024-06-13**|**Talking Heads: Understanding Inter-layer Communication in Transformer Language Models**|Jack Merullo et.al.|[2406.09519](http://arxiv.org/abs/2406.09519)|null|\n", "2406.11597": "|**2024-07-04**|**Compressed Skinning for Facial Blendshapes**|Ladislav Kavan et.al.|[2406.11597](http://arxiv.org/abs/2406.11597)|null|\n", "2406.11259": "|**2024-06-17**|**NLDF: Neural Light Dynamic Fields for Efficient 3D Talking Head Generation**|Niu Guanchen et.al.|[2406.11259](http://arxiv.org/abs/2406.11259)|null|\n", "2406.10553": "|**2024-06-18**|**A Comprehensive Taxonomy and Analysis of Talking Head Synthesis: Techniques for Portrait Generation, Driving Mechanisms, and Editing**|Ming Meng et.al.|[2406.10553](http://arxiv.org/abs/2406.10553)|null|\n", "2406.14272": "|**2024-06-20**|**MultiTalk: Enhancing 3D Talking Head Generation Across Languages with Multilingual Video Dataset**|Kim Sung-Bin et.al.|[2406.14272](http://arxiv.org/abs/2406.14272)|null|\n", "2406.13495": "|**2024-06-19**|**DF40: Toward Next-Generation Deepfake Detection**|Zhiyuan Yan et.al.|[2406.13495](http://arxiv.org/abs/2406.13495)|**[link](https://github.com/YZY-stack/DF40)**|\n", "2406.13272": "|**2024-06-19**|**AniFaceDiff: High-Fidelity Face Reenactment via Facial Parametric Conditioned Diffusion Models**|Ken Chen et.al.|[2406.13272](http://arxiv.org/abs/2406.13272)|null|\n", "2406.13093": "|**2024-06-18**|**RITA: A Real-time Interactive Talking Avatars Framework**|Wuxinlin Cheng et.al.|[2406.13093](http://arxiv.org/abs/2406.13093)|null|\n", "2406.15177": "|**2024-06-21**|**EmpathyEar: An Open-source Avatar Multimodal Empathetic Chatbot**|Hao Fei et.al.|[2406.15177](http://arxiv.org/abs/2406.15177)|**[link](https://github.com/scofield7419/empathyear)**|\n", "2406.18284": "|**2024-06-26**|**RealTalk: Real-time and Realistic Audio-driven Face Generation with 3D Facial Prior-guided Identity Alignment Network**|Xiaozhong Ji et.al.|[2406.18284](http://arxiv.org/abs/2406.18284)|null|\n", "2407.01034": "|**2024-07-01**|**Enhancing Speech-Driven 3D Facial Animation with Audio-Visual Guidance from Lip Reading Expert**|Han EunGi et.al.|[2407.01034](http://arxiv.org/abs/2407.01034)|null|\n", "2407.03168": "|**2024-07-03**|**LivePortrait: Efficient Portrait Animation with Stitching and Retargeting Control**|Jianzhu Guo et.al.|[2407.03168](http://arxiv.org/abs/2407.03168)|**[link](https://github.com/KwaiVGI/LivePortrait)**|\n", "2407.05712": "|**2024-07-08**|**MobilePortrait: Real-Time One-Shot Neural Head Avatars on Mobile Devices**|Jianwen Jiang et.al.|[2407.05712](http://arxiv.org/abs/2407.05712)|null|\n", "2407.05577": "|**2024-07-08**|**Audio-driven High-resolution Seamless Talking Head Video Editing via StyleGAN**|Jiacheng Su et.al.|[2407.05577](http://arxiv.org/abs/2407.05577)|null|\n", "2407.08136": "|**2024-07-12**|**EchoMimic: Lifelike Audio-Driven Portrait Animations through Editable Landmark Conditions**|Zhiyuan Chen et.al.|[2407.08136](http://arxiv.org/abs/2407.08136)|**[link](https://github.com/antgroup/echomimic)**|\n", "2407.08949": "|**2024-07-12**|**One-Shot Pose-Driving Face Animation Platform**|He Feng et.al.|[2407.08949](http://arxiv.org/abs/2407.08949)|null|\n", "2407.09965": "|**2024-07-13**|**Learning Online Scale Transformation for Talking Head Video Generation**|Fa-Ting Hong et.al.|[2407.09965](http://arxiv.org/abs/2407.09965)|null|\n", "2407.10993": "|**2024-06-24**|**The Effects of Embodiment and Personality Expression on Learning in LLM-based Educational Agents**|Sinan Sonlu et.al.|[2407.10993](http://arxiv.org/abs/2407.10993)|null|\n", "2407.12501": "|**2024-07-17**|**EmoFace: Audio-driven Emotional 3D Face Animation**|Chang Liu et.al.|[2407.12501](http://arxiv.org/abs/2407.12501)|**[link](https://github.com/sjtu-lucy/emoface)**|\n", "2407.13038": "|**2024-07-17**|**Universal Facial Encoding of Codec Avatars from VR Headsets**|Shaojie Bai et.al.|[2407.13038](http://arxiv.org/abs/2407.13038)|null|\n", "2407.15153": "|**2024-07-21**|**Anchored Diffusion for Video Face Reenactment**|Idan Kligvasser et.al.|[2407.15153](http://arxiv.org/abs/2407.15153)|null|\n", "2407.14841": "|**2024-07-20**|**Text-based Talking Video Editing with Cascaded Conditional Diffusion**|Bo Han et.al.|[2407.14841](http://arxiv.org/abs/2407.14841)|null|\n", "2407.17430": "|**2024-07-24**|**A Comprehensive Review and Taxonomy of Audio-Visual Synchronization Techniques for Realistic Speech Animation**|Jose Geraldo Fernandes et.al.|[2407.17430](http://arxiv.org/abs/2407.17430)|null|\n", "2407.17253": "|**2024-07-24**|**The impact of differences in facial features between real speakers and 3D face models on synthesized lip motions**|Rabab Algadhy et.al.|[2407.17253](http://arxiv.org/abs/2407.17253)|null|\n", "2407.18595": "|**2024-07-26**|**LinguaLinker: Audio-Driven Portraits Animation with Implicit Facial Control Enhancement**|Rui Zhang et.al.|[2407.18595](http://arxiv.org/abs/2407.18595)|null|\n", "2407.18955": "|**2024-07-12**|**Real Face Video Animation Platform**|Xiaokai Chen et.al.|[2407.18955](http://arxiv.org/abs/2407.18955)|null|\n", "2407.21428": "|**2024-07-31**|**Deformable 3D Shape Diffusion Model**|Dengsheng Chen et.al.|[2407.21428](http://arxiv.org/abs/2407.21428)|null|\n", "2407.21047": "|**2024-07-22**|**PAV: Personalized Head Avatar from Unstructured Video Collection**|Akin Caliskan et.al.|[2407.21047](http://arxiv.org/abs/2407.21047)|null|\n", "2408.00762": "|**2024-08-01**|**UniTalker: Scaling up Audio-Driven 3D Facial Animation through A Unified Model**|Xiangyu Fan et.al.|[2408.00762](http://arxiv.org/abs/2408.00762)|null|\n", "2408.00458": "|**2024-08-01**|**Reenact Anything: Semantic Video Motion Transfer Using Motion-Textual Inversion**|Manuel Kansy et.al.|[2408.00458](http://arxiv.org/abs/2408.00458)|null|\n", "2408.00297": "|**2024-08-01**|**EmoTalk3D: High-Fidelity Free-View Synthesis of Emotional 3D Talking Head**|Qianyun He et.al.|[2408.00297](http://arxiv.org/abs/2408.00297)|null|\n", "2408.01826": "|**2024-08-16**|**GLDiTalker: Speech-Driven 3D Facial Animation with Graph Latent Diffusion Transformer**|Yihong Lin et.al.|[2408.01826](http://arxiv.org/abs/2408.01826)|null|\n", "2408.01732": "|**2024-08-03**|**Landmark-guided Diffusion Model for High-fidelity and Temporally Coherent Talking Head Generation**|Jintao Tan et.al.|[2408.01732](http://arxiv.org/abs/2408.01732)|null|\n", "2408.01627": "|**2024-08-03**|**JambaTalk: Speech-Driven 3D Talking Head Generation Based on Hybrid Transformer-Mamba Model**|Farzaneh Jafari et.al.|[2408.01627](http://arxiv.org/abs/2408.01627)|null|\n", "2408.03284": "|**2024-08-06**|**ReSyncer: Rewiring Style-based Generator for Unified Audio-Visually Synced Facial Performer**|Jiazhi Guan et.al.|[2408.03284](http://arxiv.org/abs/2408.03284)|null|\n", "2408.06010": "|**2024-08-12**|**DEEPTalk: Dynamic Emotion Embedding for Probabilistic Speech-Driven 3D Face Animation**|Jisoo Kim et.al.|[2408.06010](http://arxiv.org/abs/2408.06010)|null|\n", "2408.05416": "|**2024-08-10**|**High-fidelity and Lip-synced Talking Face Synthesis via Landmark-based Diffusion Model**|Weizhi Zhong et.al.|[2408.05416](http://arxiv.org/abs/2408.05416)|null|\n", "2408.05412": "|**2024-08-10**|**Style-Preserving Lip Sync via Audio-Aware Style Reference**|Weizhi Zhong et.al.|[2408.05412](http://arxiv.org/abs/2408.05412)|null|\n", "2408.05366": "|**2024-08-09**|**DeepSpeak Dataset v1.0**|Sarah Barrington et.al.|[2408.05366](http://arxiv.org/abs/2408.05366)|null|\n", "2408.07005": "|**2024-08-14**|**Content and Style Aware Audio-Driven Facial Animation**|Qingju Liu et.al.|[2408.07005](http://arxiv.org/abs/2408.07005)|null|\n", "2408.09384": "|**2024-08-18**|**FD2Talk: Towards Generalized Talking Head Generation with Facial Decoupled Diffusion Model**|Ziyu Yao et.al.|[2408.09384](http://arxiv.org/abs/2408.09384)|null|\n", "2408.09357": "|**2024-08-18**|**Meta-Learning Empowered Meta-Face: Personalized Speaking Style Adaptation for Audio-Driven 3D Talking Face Animation**|Xukun Zhou et.al.|[2408.09357](http://arxiv.org/abs/2408.09357)|null|\n", "2408.09347": "|**2024-08-18**|**S^3D-NeRF: Single-Shot Speech-Driven Neural Radiance Field for High Fidelity Talking Head Synthesis**|Dongze Li et.al.|[2408.09347](http://arxiv.org/abs/2408.09347)|null|\n", "2408.10588": "|**2024-08-20**|**DEGAS: Detailed Expressions on Full-Body Gaussian Avatars**|Zhijing Shao et.al.|[2408.10588](http://arxiv.org/abs/2408.10588)|**[link](https://github.com/initialneil/DEGAS)**|\n", "2408.11564": "|**2024-08-21**|**AutoDirector: Online Auto-scheduling Agents for Multi-sensory Composition**|Minheng Ni et.al.|[2408.11564](http://arxiv.org/abs/2408.11564)|null|\n", "2408.11518": "|**2024-08-21**|**EmoFace: Emotion-Content Disentangled Speech-Driven 3D Talking Face with Mesh Attention**|Yihong Lin et.al.|[2408.11518](http://arxiv.org/abs/2408.11518)|null|\n", "2408.13049": "|**2024-08-23**|**G3FA: Geometry-guided GAN for Face Animation**|Alireza Javanmardi et.al.|[2408.13049](http://arxiv.org/abs/2408.13049)|null|\n", "2408.13714": "|**2024-08-25**|**TalkLoRA: Low-Rank Adaptation for Speech-Driven Animation**|Jack Saunders et.al.|[2408.13714](http://arxiv.org/abs/2408.13714)|null|\n", "2408.14975": "|**2024-08-27**|**MegActor-$\u03a3$: Unlocking Flexible Mixed-Modal Control in Portrait Animation with Diffusion Transformer**|Shurong Yang et.al.|[2408.14975](http://arxiv.org/abs/2408.14975)|null|\n", "2408.16110": "|**2024-08-28**|**Micro and macro facial expressions by driven animations in realistic Virtual Humans**|Rubens Halbig Montanha et.al.|[2408.16110](http://arxiv.org/abs/2408.16110)|null|\n", "2409.02657": "|**2024-09-04**|**PoseTalk: Text-and-Audio-based Pose Control and Motion Refinement for One-Shot Talking Head Generation**|Jun Ling et.al.|[2409.02657](http://arxiv.org/abs/2409.02657)|null|\n", "2409.01113": "|**2024-09-02**|**KMTalk: Speech-Driven 3D Facial Animation with Key Motion Embedding**|Zhihao Xu et.al.|[2409.01113](http://arxiv.org/abs/2409.01113)|**[link](https://github.com/ffxzh/kmtalk)**|\n", "2409.03605": "|**2024-09-05**|**SegTalker: Segmentation-based Talking Face Generation with Mask-guided Local Editing**|Lingyu Xiong et.al.|[2409.03605](http://arxiv.org/abs/2409.03605)|null|\n", "2409.03270": "|**2024-09-05**|**SVP: Style-Enhanced Vivid Portrait Talking Head Diffusion Model**|Weipeng Tan et.al.|[2409.03270](http://arxiv.org/abs/2409.03270)|null|\n", "2409.05379": "|**2024-09-09**|**PersonaTalk: Bring Attention to Your Persona in Visual Dubbing**|Longhao Zhang et.al.|[2409.05379](http://arxiv.org/abs/2409.05379)|null|\n", "2409.05330": "|**2024-09-09**|**KAN-Based Fusion of Dual-Domain for Audio-Driven Facial Landmarks Generation**|Hoang-Son Vo-Thanh et.al.|[2409.05330](http://arxiv.org/abs/2409.05330)|**[link](https://github.com/sowwnn/KFusion-Dual-Domain-for-Speech-to-Landmarks)**|\n", "2409.07255": "|**2024-09-11**|**EMOdiffhead: Continuously Emotional Control in Talking Head Generation via Diffusion**|Jian Zhang et.al.|[2409.07255](http://arxiv.org/abs/2409.07255)|**[link](https://github.com/JianZhang-chick/EMOdiffhead)**|\n", "2409.07966": "|**2024-09-25**|**ProbTalk3D: Non-Deterministic Emotion Controllable Speech-Driven 3D Facial Animation Synthesis Using VQ-VAE**|Sichun Wu et.al.|[2409.07966](http://arxiv.org/abs/2409.07966)|**[link](https://github.com/uuembodiedsocialai/probtalk3d)**|\n", "2409.07649": "|**2024-09-11**|**DiffTED: One-shot Audio-driven TED Talk Video Generation with Diffusion-based Co-speech Gestures**|Steven Hogue et.al.|[2409.07649](http://arxiv.org/abs/2409.07649)|null|\n", "2409.10281": "|**2024-09-16**|**DreamHead: Learning Spatial-Temporal Correspondence via Hierarchical Diffusion for Audio-driven Talking Head Synthesis**|Fa-Ting Hong et.al.|[2409.10281](http://arxiv.org/abs/2409.10281)|null|\n", "2409.09292": "|**2024-09-14**|**StyleTalk++: A Unified Framework for Controlling the Speaking Styles of Talking Heads**|Suzhen Wang et.al.|[2409.09292](http://arxiv.org/abs/2409.09292)|null|\n", "2409.10848": "|**2024-09-17**|**3DFacePolicy: Speech-Driven 3D Facial Animation with Diffusion Policy**|Xuanmeng Sha et.al.|[2409.10848](http://arxiv.org/abs/2409.10848)|null|\n", "2409.12156": "|**2024-09-18**|**JEAN: Joint Expression and Audio-guided NeRF-based Talking Face Generation**|Sai Tanmay Reddy Chakkera et.al.|[2409.12156](http://arxiv.org/abs/2409.12156)|null|\n", "2409.11951": "|**2024-09-18**|**GaussianHeads: End-to-End Learning of Drivable Gaussian Head Avatars from Coarse-to-fine Representations**|Kartik Teotia et.al.|[2409.11951](http://arxiv.org/abs/2409.11951)|null|\n", "2409.15179": "|**2024-09-23**|**MIMAFace: Face Animation via Motion-Identity Modulated Appearance Feature Learning**|Yue Han et.al.|[2409.15179](http://arxiv.org/abs/2409.15179)|null|\n", "2409.13180": "|**2024-10-09**|**FreeAvatar: Robust 3D Facial Animation Transfer by Learning an Expression Foundation Model**|Feng Qiu et.al.|[2409.13180](http://arxiv.org/abs/2409.13180)|null|\n", "2409.16404": "|**2024-09-24**|**FastTalker: Jointly Generating Speech and Conversational Gestures from Text**|Zixin Guo et.al.|[2409.16404](http://arxiv.org/abs/2409.16404)|null|\n", "2409.18083": "|**2024-09-26**|**Stable Video Portraits**|Mirela Ostrek et.al.|[2409.18083](http://arxiv.org/abs/2409.18083)|null|\n", "2409.19501": "|**2024-09-29**|**Learning Frame-Wise Emotion Intensity for Audio-Driven Talking-Head Generation**|Jingyi Xu et.al.|[2409.19501](http://arxiv.org/abs/2409.19501)|null|\n", "2409.19143": "|**2024-09-27**|**Diverse Code Query Learning for Speech-Driven Facial Animation**|Chunzhi Gu et.al.|[2409.19143](http://arxiv.org/abs/2409.19143)|null|\n", "2410.00990": "|**2024-10-01**|**LaDTalk: Latent Denoising for Synthesizing Talking Head Videos with High Frequency Details**|Jian Yang et.al.|[2410.00990](http://arxiv.org/abs/2410.00990)|null|\n", "2410.06734": "|**2024-10-15**|**MimicTalk: Mimicking a personalized and expressive 3D talking face in minutes**|Zhenhui Ye et.al.|[2410.06734](http://arxiv.org/abs/2410.06734)|null|\n", "2410.07151": "|**2024-09-23**|**FaceVid-1K: A Large-Scale High-Quality Multiracial Human Face Video Dataset**|Donglin Di et.al.|[2410.07151](http://arxiv.org/abs/2410.07151)|null|\n", "2410.07757": "|**2024-10-10**|**MMHead: Towards Fine-grained Multi-modal 3D Facial Animation**|Sijing Wu et.al.|[2410.07757](http://arxiv.org/abs/2410.07757)|null|\n", "2410.10696": "|**2024-10-14**|**TALK-Act: Enhance Textural-Awareness for 2D Speaking Avatar Reenactment with Diffusion Model**|Jiazhi Guan et.al.|[2410.10696](http://arxiv.org/abs/2410.10696)|null|\n", "2410.10171": "|**2024-10-14**|**Generative Human Video Compression with Multi-granularity Temporal Trajectory Factorization**|Shanzhi Yin et.al.|[2410.10171](http://arxiv.org/abs/2410.10171)|null|\n", "2410.10122": "|**2024-10-16**|**MuseTalk: Real-Time High Quality Lip Synchronization with Latent Space Inpainting**|Yue Zhang et.al.|[2410.10122](http://arxiv.org/abs/2410.10122)|**[link](https://github.com/tmelyralab/musetalk)**|\n", "2410.11434": "|**2024-10-15**|**Titanic Calling: Low Bandwidth Video Conference from the Titanic Wreck**|Fevziye Irem Eyiokur et.al.|[2410.11434](http://arxiv.org/abs/2410.11434)|null|\n", "2410.11068": "|**2024-10-14**|**Character-aware audio-visual subtitling in context**|Jaesung Huh et.al.|[2410.11068](http://arxiv.org/abs/2410.11068)|null|\n", "2410.11041": "|**2024-10-14**|**Beyond Fixed Topologies: Unregistered Training and Comprehensive Evaluation Metrics for 3D Talking Heads**|Federico Nocentini et.al.|[2410.11041](http://arxiv.org/abs/2410.11041)|null|\n", "2410.13726": "|**2024-10-18**|**DAWN: Dynamic Frame Avatar with Non-autoregressive Diffusion Framework for Talking Head Video Generation**|Hanbo Cheng et.al.|[2410.13726](http://arxiv.org/abs/2410.13726)|**[link](https://github.com/hanbo-cheng/dawn-pytorch)**|\n", "2410.14283": "|**2024-10-18**|**Takin-ADA: Emotion Controllable Audio-Driven Animation with Canonical and Landmark Loss Optimization**|Bin Lin et.al.|[2410.14283](http://arxiv.org/abs/2410.14283)|null|\n", "2410.16395": "|**2024-10-21**|**Joker: Conditional 3D Head Synthesis with Extreme Facial Expressions**|Malte Prinzler et.al.|[2410.16395](http://arxiv.org/abs/2410.16395)|null|\n", "2410.18355": "|**2024-10-24**|**Real-time 3D-aware Portrait Video Relighting**|Ziqi Cai et.al.|[2410.18355](http://arxiv.org/abs/2410.18355)|**[link](https://github.com/GhostCai/PortraitRelighting)**|\n", "2410.22112": "|**2024-10-29**|**Multimodal Semantic Communication for Generative Audio-Driven Video Conferencing**|Haonan Tong et.al.|[2410.22112](http://arxiv.org/abs/2410.22112)|null|\n", "2410.23836": "|**2024-10-31**|**Stereo-Talker: Audio-driven 3D Human Synthesis with Prior-Guided Mixture-of-Experts**|Xiang Deng et.al.|[2410.23836](http://arxiv.org/abs/2410.23836)|null|\n", "2411.03876": "|**2024-11-06**|**Large Generative Model-assisted Talking-face Semantic Communication System**|Feibo Jiang et.al.|[2411.03876](http://arxiv.org/abs/2411.03876)|null|\n", "2411.09268": "|**2024-11-14**|**LES-Talker: Fine-Grained Emotion Editing for Talking Head Generation in Linear Emotion Space**|Guanwen Feng et.al.|[2411.09268](http://arxiv.org/abs/2411.09268)|null|\n", "2411.09209": "|**2024-11-20**|**JoyVASA: Portrait and Animal Image Animation with Diffusion-Based Audio-Driven Facial Dynamics and Head Motion Generation**|Xuyang Cao et.al.|[2411.09209](http://arxiv.org/abs/2411.09209)|**[link](https://github.com/jdh-algo/JoyVASA)**|\n", "2411.13209": "|**2024-11-20**|**Comparative Analysis of Audio Feature Extraction for Real-Time Talking Portrait Synthesis**|Pegah Salehi et.al.|[2411.13209](http://arxiv.org/abs/2411.13209)|**[link](https://github.com/pegahs1993/whisper-afe-talkingheadsgen)**|\n", "2411.13089": "|**2024-11-25**|**ESARM: 3D Emotional Speech-to-Animation via Reward Model from Automatically-Ranked Demonstrations**|Xulong Zhang et.al.|[2411.13089](http://arxiv.org/abs/2411.13089)|null|\n", "2411.16331": "|**2024-11-25**|**Sonic: Shifting Focus to Global Audio Perception in Portrait Animation**|Xiaozhong Ji et.al.|[2411.16331](http://arxiv.org/abs/2411.16331)|null|\n", "2411.15436": "|**2024-11-23**|**ConsistentAvatar: Learning to Diffuse Fully Consistent Talking Head Avatar with Temporal Guidance**|Haijie Yang et.al.|[2411.15436](http://arxiv.org/abs/2411.15436)|null|\n", "2411.16748": "|**2024-11-24**|**LetsTalk: Latent Diffusion Transformer for Talking Video Synthesis**|Haojie Zhang et.al.|[2411.16748](http://arxiv.org/abs/2411.16748)|null|\n", "2411.16726": "|**2024-11-23**|**EmotiveTalk: Expressive Talking Head Generation through Audio Information Decoupling and Emotional Video Diffusion**|Haotian Wang et.al.|[2411.16726](http://arxiv.org/abs/2411.16726)|null|\n", "2411.17911": "|**2024-11-26**|**Passive Deepfake Detection Across Multi-modalities: A Comprehensive Survey**|Hong-Hanh Nguyen-Le et.al.|[2411.17911](http://arxiv.org/abs/2411.17911)|null|\n", "2411.19525": "|**2024-11-29**|**LokiTalk: Learning Fine-Grained and Generalizable Correspondences to Enhance NeRF-based Talking Head Synthesis**|Tianqi Li et.al.|[2411.19525](http://arxiv.org/abs/2411.19525)|null|\n", "2411.19509": "|**2024-11-29**|**Ditto: Motion-Space Diffusion for Controllable Realtime Talking Head Synthesis**|Tianqi Li et.al.|[2411.19509](http://arxiv.org/abs/2411.19509)|**[link](https://github.com/antgroup/ditto-talkinghead)**|\n", "2411.19486": "|**2024-11-29**|**V2SFlow: Video-to-Speech Generation with Speech Decomposition and Rectified Flow**|Jeongsoo Choi et.al.|[2411.19486](http://arxiv.org/abs/2411.19486)|null|\n", "2412.01106": "|**2024-12-02**|**One Shot, One Talk: Whole-body Talking Avatar from a Single Image**|Jun Xiang et.al.|[2412.01106](http://arxiv.org/abs/2412.01106)|null|\n", "2412.00733": "|**2024-12-05**|**Hallo3: Highly Dynamic and Realistic Portrait Image Animation with Diffusion Transformer Networks**|Jiahao Cui et.al.|[2412.00733](http://arxiv.org/abs/2412.00733)|**[link](https://github.com/fudan-generative-vision/hallo3)**|\n", "2412.00719": "|**2024-12-01**|**Synergizing Motion and Appearance: Multi-Scale Compensatory Codebooks for Talking Head Video Generation**|Shuling Zhao et.al.|[2412.00719](http://arxiv.org/abs/2412.00719)|null|\n", "2412.03430": "|**2024-12-04**|**SINGER: Vivid Audio-driven Singing Video Generation with Multi-scale Spectral Diffusion Model**|Yan Li et.al.|[2412.03430](http://arxiv.org/abs/2412.03430)|null|\n", "2412.04448": "|**2024-12-05**|**MEMO: Memory-Guided Diffusion for Expressive Talking Video Generation**|Longtao Zheng et.al.|[2412.04448](http://arxiv.org/abs/2412.04448)|null|\n", "2412.04000": "|**2024-12-10**|**IF-MDM: Implicit Face Motion Diffusion Model for High-Fidelity Realtime Talking Head Generation**|Sejong Yang et.al.|[2412.04000](http://arxiv.org/abs/2412.04000)|null|\n", "2412.07754": "|**2024-12-10**|**PortraitTalk: Towards Customizable One-Shot Audio-to-Talking Face Generation**|Fatemeh Nazarieh et.al.|[2412.07754](http://arxiv.org/abs/2412.07754)|null|\n", "2412.08504": "|**2024-12-11**|**PointTalk: Audio-Driven Dynamic Lip Point Cloud for 3D Gaussian-based Talking Head Synthesis**|Yifan Xie et.al.|[2412.08504](http://arxiv.org/abs/2412.08504)|null|\n", "2412.09296": "|**2024-12-13**|**GoHD: Gaze-oriented and Highly Disentangled Portrait Animation with Rhythmic Poses and Realistic Expression**|Ziqi Zhou et.al.|[2412.09296](http://arxiv.org/abs/2412.09296)|**[link](https://github.com/Jia1018/GoHD)**|\n", "2412.09262": "|**2024-12-12**|**LatentSync: Audio Conditioned Latent Diffusion Models for Lip Sync**|Chunyu Li et.al.|[2412.09262](http://arxiv.org/abs/2412.09262)|**[link](https://github.com/bytedance/LatentSync)**|\n", "2412.08988": "|**2024-12-12**|**EmoDubber: Towards High Quality and Emotion Controllable Movie Dubbing**|Gaoxiang Cong et.al.|[2412.08988](http://arxiv.org/abs/2412.08988)|null|\n", "2412.09892": "|**2024-12-18**|**VQTalker: Towards Multilingual Talking Avatars through Facial Motion Tokenization**|Tao Liu et.al.|[2412.09892](http://arxiv.org/abs/2412.09892)|null|\n", "2412.12278": "|**2024-12-16**|**Towards a Universal Synthetic Video Detector: From Face or Background Manipulations to Fully AI-Generated Content**|Rohit Kundu et.al.|[2412.12278](http://arxiv.org/abs/2412.12278)|null|\n", "2412.13656": "|**2024-12-18**|**GLCF: A Global-Local Multimodal Coherence Analysis Framework for Talking Face Generation Detection**|Xiaocan Chen et.al.|[2412.13656](http://arxiv.org/abs/2412.13656)|null|\n", "2412.13641": "|**2024-12-18**|**Learning to Control an Android Robot Head for Facial Animation**|Marcel Heisler et.al.|[2412.13641](http://arxiv.org/abs/2412.13641)|null|\n", "2412.13479": "|**2024-12-18**|**Real-time One-Step Diffusion-based Expressive Portrait Videos Generation**|Hanzhong Guo et.al.|[2412.13479](http://arxiv.org/abs/2412.13479)|**[link](https://github.com/Guohanzhong/OSA-LCM)**|\n", "2412.14333": "|**2024-12-18**|**Joint Co-Speech Gesture and Expressive Talking Face Generation using Diffusion with Adapters**|Steven Hogue et.al.|[2412.14333](http://arxiv.org/abs/2412.14333)|**[link](https://github.com/ditzley/joint-gestures-and-face)**|\n", "2412.17812": "|**2024-12-23**|**FaceLift: Single Image to 3D Head with View Generation and GS-LRM**|Weijie Lyu et.al.|[2412.17812](http://arxiv.org/abs/2412.17812)|null|\n", "2412.16915": "|**2024-12-22**|**FADA: Fast Diffusion Avatar Synthesis with Mixed-Supervised Multi-CFG Distillation**|Tianyun Zhong et.al.|[2412.16915](http://arxiv.org/abs/2412.16915)|null|\n", "2412.19149": "|**2024-12-26**|**Generating Editable Head Avatars with 3D Gaussian GANs**|Guohao Li et.al.|[2412.19149](http://arxiv.org/abs/2412.19149)|**[link](https://github.com/liguohao96/egg3d)**|\n", "2412.20148": "|**2024-12-28**|**DEGSTalk: Decomposed Per-Embedding Gaussian Fields for Hair-Preserving Talking Face Synthesis**|Kaijun Deng et.al.|[2412.20148](http://arxiv.org/abs/2412.20148)|**[link](https://github.com/cvi-szu/degstalk)**|\n", "2412.19860": "|**2024-12-26**|**UniAvatar: Taming Lifelike Audio-Driven Talking Head Generation with Comprehensive Motion and Lighting Control**|Wenzhang Sun et.al.|[2412.19860](http://arxiv.org/abs/2412.19860)|null|\n", "2501.01427": "|**2025-01-07**|**VideoAnydoor: High-fidelity Video Object Insertion with Precise Motion Control**|Yuanpeng Tu et.al.|[2501.01427](http://arxiv.org/abs/2501.01427)|null|\n", "2501.00168": "|**2025-01-06**|**Takeaways from Applying LLM Capabilities to Multiple Conversational Avatars in a VR Pilot Study**|Mykola Maslych et.al.|[2501.00168](http://arxiv.org/abs/2501.00168)|null|\n", "2501.01808": "|**2025-01-09**|**MoEE: Mixture of Emotion Experts for Audio-Driven Portrait Animation**|Huaize Liu et.al.|[2501.01808](http://arxiv.org/abs/2501.01808)|null|\n", "2501.01798": "|**2025-01-03**|**JoyGen: Audio-Driven 3D Depth-Aware Talking-Face Video Editing**|Qili Wang et.al.|[2501.01798](http://arxiv.org/abs/2501.01798)|**[link](https://github.com/JOY-MM/JoyGen)**|\n", "2501.02822": "|**2025-01-06**|**RDD4D: 4D Attention-Guided Road Damage Detection And Classification**|Asma Alkalbani et.al.|[2501.02822](http://arxiv.org/abs/2501.02822)|**[link](https://github.com/msaqib17/road_damage_detection)**|\n", "2501.04586": "|**2025-01-09**|**Identity-Preserving Video Dubbing Using Motion Warping**|Runzhen Liu et.al.|[2501.04586](http://arxiv.org/abs/2501.04586)|null|\n", "2501.06227": "|**2025-01-07**|**Generating and Detecting Various Types of Fake Image and Audio Content: A Review of Modern Deep Learning Technologies and Tools**|Arash Dehghani et.al.|[2501.06227](http://arxiv.org/abs/2501.06227)|null|\n", "2501.07870": "|**2025-01-15**|**Make-A-Character 2: Animatable 3D Character Generation From a Single Image**|Lin Liu et.al.|[2501.07870](http://arxiv.org/abs/2501.07870)|null|\n", "2501.08649": "|**2025-01-15**|**Joint Learning of Depth and Appearance for Portrait Image Animation**|Xinya Ji et.al.|[2501.08649](http://arxiv.org/abs/2501.08649)|null|\n", "2501.09921": "|**2025-01-17**|**TalkingEyes: Pluralistic Speech-Driven 3D Eye Gaze Animation**|Yixiang Zhuang et.al.|[2501.09921](http://arxiv.org/abs/2501.09921)|null|\n", "2501.11927": "|**2025-01-21**|**A Lightweight and Interpretable Deepfakes Detection Framework**|Muhammad Umar Farooq et.al.|[2501.11927](http://arxiv.org/abs/2501.11927)|null|\n", "2501.10687": "|**2025-01-18**|**EMO2: End-Effector Guided Audio-Driven Avatar Video Generation**|Linrui Tian et.al.|[2501.10687](http://arxiv.org/abs/2501.10687)|null|\n", "2501.14646": "|**2025-01-24**|**SyncAnimation: A Real-Time End-to-End Framework for Audio-Driven Human Pose and Talking Head Animation**|Yujian Liu et.al.|[2501.14646](http://arxiv.org/abs/2501.14646)|null|\n", "2501.14790": "|**2025-01-09**|**Towards Dynamic Neural Communication and Speech Neuroprosthesis Based on Viseme Decoding**|Ji-Ha Park et.al.|[2501.14790](http://arxiv.org/abs/2501.14790)|null|\n", "2502.00654": "|**2025-02-02**|**EmoTalkingGaussian: Continuous Emotion-conditioned Talking Head Synthesis**|Junuk Cha et.al.|[2502.00654](http://arxiv.org/abs/2502.00654)|null|\n", "2502.04103": "|**2025-02-13**|**VTutor: An Open-Source SDK for Generative AI-Powered Animated Pedagogical Agents with Multi-Media Output**|Eason Chen et.al.|[2502.04103](http://arxiv.org/abs/2502.04103)|null|\n", "2502.04976": "|**2025-02-07**|**Towards Multimodal Empathetic Response Generation: A Rich Text-Speech-Vision Avatar-based Benchmark**|Han Zhang et.al.|[2502.04976](http://arxiv.org/abs/2502.04976)|null|\n", "2502.07203": "|**2025-02-11**|**Playmate: Flexible Control of Portrait Animation via 3D-Implicit Space Guided Diffusion**|Xingpei Ma et.al.|[2502.07203](http://arxiv.org/abs/2502.07203)|null|\n", "2502.09533": "|**2025-02-13**|**Long-Term TalkingFace Generation via Motion-Prior Conditional Diffusion Model**|Fei Shen et.al.|[2502.09533](http://arxiv.org/abs/2502.09533)|null|\n", "2502.11515": "|**2025-02-17**|**SayAnything: Audio-Driven Lip Synchronization with Conditional Video Diffusion**|Junxian Ma et.al.|[2502.11515](http://arxiv.org/abs/2502.11515)|null|\n", "2502.10841": "|**2025-02-15**|**SkyReels-A1: Expressive Portrait Animation in Video Diffusion Transformers**|Di Qiu et.al.|[2502.10841](http://arxiv.org/abs/2502.10841)|**[link](https://github.com/SkyworkAI/SkyReels-A1)**|\n", "2502.13133": "|**2025-02-18**|**AV-Flow: Transforming Text to Audio-Visual Human-like Interactions**|Aggelina Chatziagapi et.al.|[2502.13133](http://arxiv.org/abs/2502.13133)|null|\n", "2502.14178": "|**2025-02-20**|**NeRF-3DTalker: Neural Radiance Field with 3D Prior Aided Audio Disentanglement for Talking Head Synthesis**|Xiaoxing Liu et.al.|[2502.14178](http://arxiv.org/abs/2502.14178)|null|\n", "2502.17198": "|**2025-02-24**|**Dimitra: Audio-driven Diffusion model for Expressive Talking Head Generation**|Baptiste Chopin et.al.|[2502.17198](http://arxiv.org/abs/2502.17198)|null|\n", "2502.20387": "|**2025-02-27**|**InsTaG: Learning Personalized 3D Talking Head from Few-Second Video**|Jiahe Li et.al.|[2502.20387](http://arxiv.org/abs/2502.20387)|**[link](https://github.com/Fictionarry/InsTaG)**|\n", "2502.20323": "|**2025-02-28**|**ARTalk: Speech-Driven 3D Head Animation via Autoregressive Model**|Xuangeng Chu et.al.|[2502.20323](http://arxiv.org/abs/2502.20323)|null|\n", "2502.19894": "|**2025-02-27**|**High-Fidelity Relightable Monocular Portrait Animation with Lighting-Controllable Video Diffusion Model**|Mingtao Guo et.al.|[2502.19894](http://arxiv.org/abs/2502.19894)|**[link](https://github.com/MingtaoGuo/relightable-portrait-animation)**|\n", "2502.19455": "|**2025-02-26**|**FLAP: Fully-controllable Audio-driven Portrait Video Generation through 3D head conditioned diffusion mode**|Lingzhou Mu et.al.|[2502.19455](http://arxiv.org/abs/2502.19455)|null|\n", "2502.20803": "|**2025-02-28**|**Two-Stream Spatial-Temporal Transformer Framework for Person Identification via Natural Conversational Keypoints**|Masoumeh Chapariniya et.al.|[2502.20803](http://arxiv.org/abs/2502.20803)|null|\n", "2503.01715": "|**2025-03-19**|**KeyFace: Expressive Audio-Driven Facial Animation for Long Sequences via KeyFrame Interpolation**|Antoni Bigata et.al.|[2503.01715](http://arxiv.org/abs/2503.01715)|null|\n", "2503.00740": "|**2025-03-02**|**FaceShot: Bring Any Character into Life**|Junyao Gao et.al.|[2503.00740](http://arxiv.org/abs/2503.00740)|null|\n", "2503.00495": "|**2025-03-01**|**Towards High-fidelity 3D Talking Avatar with Personalized Dynamic Texture**|Xuanchen Li et.al.|[2503.00495](http://arxiv.org/abs/2503.00495)|null|\n", "2503.04067": "|**2025-03-06**|**FREAK: Frequency-modulated High-fidelity and Real-time Audio-driven Talking Portrait Synthesis**|Ziqi Ni et.al.|[2503.04067](http://arxiv.org/abs/2503.04067)|null|\n", "2503.06397": "|**2025-03-09**|**Removing Averaging: Personalized Lip-Sync Driven Characters Based on Identity Adapter**|Yanyu Zhu et.al.|[2503.06397](http://arxiv.org/abs/2503.06397)|null|\n", "2503.05978": "|**2025-03-07**|**MagicInfinite: Generating Infinite Talking Videos with Your Words and Voice**|Hongwei Yi et.al.|[2503.05978](http://arxiv.org/abs/2503.05978)|null|\n", "2503.08714": "|**2025-03-16**|**Versatile Multimodal Controls for Whole-Body Talking Human Animation**|Zheng Qin et.al.|[2503.08714](http://arxiv.org/abs/2503.08714)|null|\n", "2503.09852": "|**2025-03-12**|**StyleSpeaker: Audio-Enhanced Fine-Grained Style Modeling for Speech-Driven 3D Facial Animation**|An Yang et.al.|[2503.09852](http://arxiv.org/abs/2503.09852)|null|\n", "2503.09787": "|**2025-03-12**|**Bidirectional Learned Facial Animation Codec for Low Bitrate Talking Head Videos**|Riku Takahashi et.al.|[2503.09787](http://arxiv.org/abs/2503.09787)|null|\n", "2503.11028": "|**2025-03-14**|**EmoDiffusion: Enhancing Emotional 3D Facial Animation with Latent Diffusion Models**|Yixuan Zhang et.al.|[2503.11028](http://arxiv.org/abs/2503.11028)|null|\n", "2503.13371": "|**2025-03-17**|**SyncDiff: Diffusion-based Talking Head Synthesis with Bottlenecked Temporal Visual Prior for Improved Synchronization**|Xulin Fan et.al.|[2503.13371](http://arxiv.org/abs/2503.13371)|null|\n", "2503.12963": "|**2025-03-17**|**Unlock Pose Diversity: Accurate and Efficient Implicit Keypoint-based Spatiotemporal Diffusion for Audio-driven Talking Portrait**|Chaolong Yang et.al.|[2503.12963](http://arxiv.org/abs/2503.12963)|**[link](https://github.com/chaolongy/kdtalker)**|\n", "2503.14295": "|**2025-03-20**|**PC-Talk: Precise Facial Animation Control for Audio-Driven Talking Face Generation**|Baiqin Wang et.al.|[2503.14295](http://arxiv.org/abs/2503.14295)|null|\n", "2503.14517": "|**2025-03-14**|**Cafe-Talk: Generating 3D Talking Face Animation with Multimodal Coarse- and Fine-grained Control**|Hejia Chen et.al.|[2503.14517](http://arxiv.org/abs/2503.14517)|null|\n", "2503.16357": "|**2025-03-20**|**UniSync: A Unified Framework for Audio-Visual Synchronization**|Tao Feng et.al.|[2503.16357](http://arxiv.org/abs/2503.16357)|null|\n", "2503.15667": "|**2025-03-19**|**DiffPortrait360: Consistent Portrait Diffusion for 360 View Synthesis**|Yuming Gu et.al.|[2503.15667](http://arxiv.org/abs/2503.15667)|**[link](https://github.com/freedomgu/diffportrait360)**|\n", "2503.17032": "|**2025-03-21**|**TaoAvatar: Real-Time Lifelike Full-Body Talking Avatars for Augmented Reality via 3D Gaussian Splatting**|Jianchuan Chen et.al.|[2503.17032](http://arxiv.org/abs/2503.17032)|null|\n", "2503.16956": "|**2025-03-21**|**From Faces to Voices: Learning Hierarchical Representations for High-quality Video-to-Speech**|Ji-Hoon Kim et.al.|[2503.16956](http://arxiv.org/abs/2503.16956)|null|\n", "2503.16942": "|**2025-03-25**|**Re-HOLD: Video Hand Object Interaction Reenactment via adaptive Layout-instructed Diffusion Model**|Yingying Fan et.al.|[2503.16942](http://arxiv.org/abs/2503.16942)|null|\n", "2503.18860": "|**2025-03-25**|**HunyuanPortrait: Implicit Condition Control for Enhanced Portrait Animation**|Zunnan Xu et.al.|[2503.18860](http://arxiv.org/abs/2503.18860)|null|\n", "2503.18429": "|**2025-03-24**|**Teller: Real-Time Streaming Audio-Driven Portrait Animation with Autoregressive Motion Generation**|Dingcheng Zhen et.al.|[2503.18429](http://arxiv.org/abs/2503.18429)|null|\n", "2503.18159": "|**2025-03-23**|**DiffusionTalker: Efficient and Compact Speech-Driven 3D Talking Head via Personalizer-Guided Distillation**|Peng Chen et.al.|[2503.18159](http://arxiv.org/abs/2503.18159)|**[link](https://github.com/chenvoid/diffusiontalker)**|\n", "2503.19824": "|**2025-03-25**|**AudCast: Audio-Driven Human Video Generation by Cascaded Diffusion Transformers**|Jiazhi Guan et.al.|[2503.19824](http://arxiv.org/abs/2503.19824)|null|\n", "2503.19416": "|**2025-03-25**|**EmoHead: Emotional Talking Head via Manipulating Semantic Expression Parameters**|Xuli Shen et.al.|[2503.19416](http://arxiv.org/abs/2503.19416)|null|\n", "2503.19383": "|**2025-03-25**|**MVPortrait: Text-Guided Motion and Emotion Control for Multi-view Vivid Portrait Animation**|Yukang Lin et.al.|[2503.19383](http://arxiv.org/abs/2503.19383)|null|\n", "2503.19001": "|**2025-03-24**|**DisentTalk: Cross-lingual Talking Face Generation via Semantic Disentangled Diffusion Model**|Kangwei Liu et.al.|[2503.19001](http://arxiv.org/abs/2503.19001)|null|\n", "2503.20308": "|**2025-03-27**|**Perceptually Accurate 3D Talking Head Generation: New Definitions, Speech-Mesh Representation, and Evaluation Metrics**|Lee Chae-Yeon et.al.|[2503.20308](http://arxiv.org/abs/2503.20308)|null|\n", "2503.21144": "|**2025-03-27**|**ChatAnyone: Stylized Real-time Portrait Video Generation with Hierarchical Motion Diffusion Model**|Jinwei Qi et.al.|[2503.21144](http://arxiv.org/abs/2503.21144)|null|\n"}, "Image Animation": {"2401.01827": "|**2024-01-03**|**Moonshot: Towards Controllable Video Generation and Editing with Multimodal Conditions**|David Junhao Zhang et.al.|[2401.01827](http://arxiv.org/abs/2401.01827)|**[link](https://github.com/salesforce/lavis)**|\n", "2312.13964": "|**2024-03-25**|**PIA: Your Personalized Image Animator via Plug-and-Play Modules in Text-to-Image Models**|Yiming Zhang et.al.|[2312.13964](http://arxiv.org/abs/2312.13964)|**[link](https://github.com/open-mmlab/PIA)**|\n", "2312.03793": "|**2023-12-06**|**AnimateZero: Video Diffusion Models are Zero-Shot Image Animators**|Jiwen Yu et.al.|[2312.03793](http://arxiv.org/abs/2312.03793)|**[link](https://github.com/vvictoryuki/animatezero)**|\n", "2312.02928": "|**2023-12-05**|**LivePhoto: Real Image Animation with Text-guided Motion Control**|Xi Chen et.al.|[2312.02928](http://arxiv.org/abs/2312.02928)|null|\n", "2311.18827": "|**2023-11-30**|**Motion-Conditioned Image Animation for Video Editing**|Wilson Yan et.al.|[2311.18827](http://arxiv.org/abs/2311.18827)|null|\n", "2311.16498": "|**2023-11-27**|**MagicAnimate: Temporally Consistent Human Image Animation using Diffusion Model**|Zhongcong Xu et.al.|[2311.16498](http://arxiv.org/abs/2311.16498)|null|\n", "2311.12886": "|**2023-12-04**|**AnimateAnything: Fine-Grained Open Domain Image Animation with Motion Guidance**|Zuozhuo Dai et.al.|[2311.12886](http://arxiv.org/abs/2311.12886)|**[link](https://github.com/alibaba/animate-anything)**|\n", "2310.12190": "|**2023-11-27**|**DynamiCrafter: Animating Open-domain Images with Video Diffusion Priors**|Jinbo Xing et.al.|[2310.12190](http://arxiv.org/abs/2310.12190)|**[link](https://github.com/Doubiiu/DynamiCrafter)**|\n", "2310.10769": "|**2023-10-16**|**LAMP: Learn A Motion Pattern for Few-Shot-Based Video Generation**|Ruiqi Wu et.al.|[2310.10769](http://arxiv.org/abs/2310.10769)|**[link](https://github.com/RQ-Wu/LAMP)**|\n", "2309.14207": "|**2023-09-25**|**Automatic Animation of Hair Blowing in Still Portrait Photos**|Wenpeng Xiao et.al.|[2309.14207](http://arxiv.org/abs/2309.14207)|null|\n", "2307.04725": "|**2023-07-10**|**AnimateDiff: Animate Your Personalized Text-to-Image Diffusion Models without Specific Tuning**|Yuwei Guo et.al.|[2307.04725](http://arxiv.org/abs/2307.04725)|**[link](https://github.com/guoyww/animatediff)**|\n", "2307.04187": "|**2023-07-09**|**Predictive Coding For Animation-Based Video Compression**|Goluck Konuko et.al.|[2307.04187](http://arxiv.org/abs/2307.04187)|null|\n", "2307.03190": "|**2023-09-26**|**Text-Guided Synthesis of Eulerian Cinemagraphs**|Aniruddha Mahapatra et.al.|[2307.03190](http://arxiv.org/abs/2307.03190)|**[link](https://github.com/text2cinemagraph/text2cinemagraph)**|\n", "2305.03989": "|**2023-10-11**|**LEO: Generative Latent Image Animator for Human Video Synthesis**|Yaohui Wang et.al.|[2305.03989](http://arxiv.org/abs/2305.03989)|**[link](https://github.com/wyhsirius/LEO)**|\n", "2304.06020": "|**2023-04-12**|**VidStyleODE: Disentangled Video Editing via StyleGAN and NeuralODEs**|Moayed Haji Ali et.al.|[2304.06020](http://arxiv.org/abs/2304.06020)|null|\n", "2303.05724": "|**2023-03-10**|**3D Cinemagraphy from a Single Image**|Xingyi Li et.al.|[2303.05724](http://arxiv.org/abs/2303.05724)|null|\n", "2302.01329": "|**2023-02-02**|**Dreamix: Video Diffusion Models are General Video Editors**|Eyal Molad et.al.|[2302.01329](http://arxiv.org/abs/2302.01329)|null|\n", "2301.05905": "|**2023-01-14**|**Continuous odor profile monitoring to study olfactory navigation in small animals**|Kevin S. Chen et.al.|[2301.05905](http://arxiv.org/abs/2301.05905)|null|\n", "2211.17235": "|**2022-11-30**|**NeRFInvertor: High Fidelity NeRF-GAN Inversion for Single-shot Real Image Animation**|Yu Yin et.al.|[2211.17235](http://arxiv.org/abs/2211.17235)|null|\n", "2210.01794": "|**2022-10-04**|**Implicit Warping for Animation with Image Sets**|Arun Mallya et.al.|[2210.01794](http://arxiv.org/abs/2210.01794)|null|\n", "2209.14024": "|**2022-09-28**|**Motion Transformer for Unsupervised Image Animation**|Jiale Tao et.al.|[2209.14024](http://arxiv.org/abs/2209.14024)|**[link](https://github.com/jialetao/motrans)**|\n", "2207.09161": "|**2022-07-19**|**Single Stage Virtual Try-on via Deformable Attention Flows**|Shuai Bai et.al.|[2207.09161](http://arxiv.org/abs/2207.09161)|**[link](https://github.com/OFA-Sys/DAFlow)**|\n", "2207.03714": "|**2022-07-08**|**Jointly Harnessing Prior Structures and Temporal Consistency for Sign Language Video Generation**|Yucheng Suo et.al.|[2207.03714](http://arxiv.org/abs/2207.03714)|null|\n", "2203.14367": "|**2022-03-29**|**Thin-Plate Spline Motion Model for Image Animation**|Jian Zhao et.al.|[2203.14367](http://arxiv.org/abs/2203.14367)|**[link](https://github.com/yoyo-nb/thin-plate-spline-motion-model)**|\n", "2203.13441": "|**2022-03-25**|**3D GAN Inversion for Controllable Portrait Image Animation**|Connor Z. Lin et.al.|[2203.13441](http://arxiv.org/abs/2203.13441)|null|\n", "2203.09043": "|**2022-03-17**|**Latent Image Animator: Learning to Animate Images via Latent Space Navigation**|Yaohui Wang et.al.|[2203.09043](http://arxiv.org/abs/2203.09043)|null|\n", "2112.10457": "|**2021-12-21**|**Image Animation with Keypoint Mask**|Or Toledano et.al.|[2112.10457](http://arxiv.org/abs/2112.10457)|**[link](https://github.com/or-toledano/animation-with-keypoint-mask)**|\n", "2112.13647": "|**2021-12-19**|**Move As You Like: Image Animation in E-Commerce Scenario**|Borun Xu et.al.|[2112.13647](http://arxiv.org/abs/2112.13647)|null|\n", "2112.09401": "|**2021-12-17**|**AI-Empowered Persuasive Video Generation: A Survey**|Chang Liu et.al.|[2112.09401](http://arxiv.org/abs/2112.09401)|null|\n", "2111.11426": "|**2022-04-05**|**Neural Fields in Visual Computing and Beyond**|Yiheng Xie et.al.|[2111.11426](http://arxiv.org/abs/2111.11426)|null|\n", "2110.13598": "|**2021-10-26**|**Incremental Learning for Animal Pose Estimation using RBF k-DPP**|Gaurav Kumar Nayak et.al.|[2110.13598](http://arxiv.org/abs/2110.13598)|null|\n", "2110.04658": "|**2023-11-19**|**Differential Motion Evolution for Fine-Grained Motion Deformation in Unsupervised Image Animation**|Peirong Liu et.al.|[2110.04658](http://arxiv.org/abs/2110.04658)|null|\n", "2109.00471": "|**2021-09-03**|**Sparse to Dense Motion Transfer for Face Image Animation**|Ruiqi Zhao et.al.|[2109.00471](http://arxiv.org/abs/2109.00471)|null|\n", "2108.07949": "|**2021-08-18**|**DeepFake MNIST+: A DeepFake Facial Animation Dataset**|Jiajun Huang et.al.|[2108.07949](http://arxiv.org/abs/2108.07949)|**[link](https://github.com/huangjiadidi/DeepFakeMnist)**|\n", "2106.15342": "|**2021-06-23**|**Analisis Kualitas Layanan Website E-Commerce Bukalapak Terhadap Kepuasan Pengguna Mahasiswa Universitas Bina Darma Menggunakan Metode Webqual 4.0**|Adellia et.al.|[2106.15342](http://arxiv.org/abs/2106.15342)|null|\n", "2106.12284": "|**2022-06-11**|**Bayesian Statistics Guided Label Refurbishment Mechanism: Mitigating Label Noise in Medical Image Classification**|Mengdi Gao et.al.|[2106.12284](http://arxiv.org/abs/2106.12284)|**[link](https://github.com/neugmd/blrm)**|\n", "2104.03117": "|**2021-04-07**|**Single Source One Shot Reenactment using Weighted motion From Paired Feature Points**|Soumya Tripathy et.al.|[2104.03117](http://arxiv.org/abs/2104.03117)|null|\n", "2103.11600": "|**2021-03-22**|**PriorityCut: Occlusion-guided Regularization for Warp-based Image Animation**|Wai Ting Cheung et.al.|[2103.11600](http://arxiv.org/abs/2103.11600)|null|\n", "2012.00346": "|**2020-12-01**|**Ultra-low bitrate video conferencing using deep image animation**|Goluck Konuko et.al.|[2012.00346](http://arxiv.org/abs/2012.00346)|null|\n", "2011.06922": "|**2022-03-29**|**Image Animation with Perturbed Masks**|Yoav Shalev et.al.|[2011.06922](http://arxiv.org/abs/2011.06922)|**[link](https://github.com/itsyoavshalev/Image-Animation-with-Perturbed-Masks)**|\n", "2008.12606": "|**2020-08-27**|**Deep Spatial Transformation for Pose-Guided Person Image Generation and Animation**|Yurui Ren et.al.|[2008.12606](http://arxiv.org/abs/2008.12606)|**[link](https://github.com/RenYurui/Global-Flow-Local-Attention)**|\n", "2003.00196": "|**2020-10-01**|**First Order Motion Model for Image Animation**|Aliaksandr Siarohin et.al.|[2003.00196](http://arxiv.org/abs/2003.00196)|**[link](https://github.com/AliaksandrSiarohin/first-order-model)**|\n", "1812.08861": "|**2019-08-30**|**Animating Arbitrary Objects via Deep Motion Transfer**|Aliaksandr Siarohin et.al.|[1812.08861](http://arxiv.org/abs/1812.08861)|**[link](https://github.com/AliaksandrSiarohin/monkey-net)**|\n", "1810.03956": "|**2018-10-09**|**3D model silhouette-based tracking in depth images for puppet suit dynamic video-mapping**|Guillaume Caron et.al.|[1810.03956](http://arxiv.org/abs/1810.03956)|null|\n", "1806.09117": "|**2018-06-24**|**A Design of FPGA Based Small Animal PET Real Time Digital Signal Processing and Correction Logic**|Jiaming Lu et.al.|[1806.09117](http://arxiv.org/abs/1806.09117)|null|\n", "1801.10452": "|**2018-01-31**|**RAPTOR I: Time-dependent radiative transfer in arbitrary spacetimes**|Thomas Bronzwaer et.al.|[1801.10452](http://arxiv.org/abs/1801.10452)|null|\n", "1606.07189": "|**2016-06-23**|**Gender and Interest Targeting for Sponsored Post Advertising at Tumblr**|Mihajlo Grbovic et.al.|[1606.07189](http://arxiv.org/abs/1606.07189)|null|\n", "1503.04837": "|**2015-03-16**|**Use of Effective Audio in E-learning Courseware**|Kisor Ray et.al.|[1503.04837](http://arxiv.org/abs/1503.04837)|null|\n", "1502.01090": "|**2015-02-04**|**Multimedia-Video for Learning**|Kah Hean Chua et.al.|[1502.01090](http://arxiv.org/abs/1502.01090)|null|\n", "1301.6130": "|**2013-01-25**|**Measurements of Martian Dust Devil Winds with HiRISE**|David S. Choi et.al.|[1301.6130](http://arxiv.org/abs/1301.6130)|null|\n", "1001.0440": "|**2010-01-04**|**Tutoring System for Dance Learning**|Rajkumar Kannan et.al.|[1001.0440](http://arxiv.org/abs/1001.0440)|null|\n", "2401.09146": "|**2024-01-17**|**Continuous Piecewise-Affine Based Motion Model for Image Animation**|Hexiang Wang et.al.|[2401.09146](http://arxiv.org/abs/2401.09146)|**[link](https://github.com/devilpg/aaai2024-cpabmm)**|\n", "2403.02827": "|**2024-03-05**|**Tuning-Free Noise Rectification for High Fidelity Image-to-Video Generation**|Weijie Li et.al.|[2403.02827](http://arxiv.org/abs/2403.02827)|null|\n", "2403.05659": "|**2024-03-08**|**Audio-Synchronized Visual Animation**|Lin Zhang et.al.|[2403.05659](http://arxiv.org/abs/2403.05659)|**[link](https://github.com/lzhangbj/ASVA)**|\n", "2403.08268": "|**2024-03-13**|**Follow-Your-Click: Open-domain Regional Image Animation via Short Prompts**|Yue Ma et.al.|[2403.08268](http://arxiv.org/abs/2403.08268)|**[link](https://github.com/mayuelala/followyourclick)**|\n", "2403.14781": "|**2024-06-01**|**Champ: Controllable and Consistent Human Image Animation with 3D Parametric Guidance**|Shenhao Zhu et.al.|[2403.14781](http://arxiv.org/abs/2403.14781)|**[link](https://github.com/fudan-generative-vision/champ)**|\n", "2405.17306": "|**2024-05-28**|**Controllable Longer Image Animation with Diffusion Models**|Qiang Wang et.al.|[2405.17306](http://arxiv.org/abs/2405.17306)|null|\n", "2405.18156": "|**2024-05-28**|**VividPose: Advancing Stable Video Diffusion for Realistic Human Image Animation**|Qilin Wang et.al.|[2405.18156](http://arxiv.org/abs/2405.18156)|null|\n", "2405.18908": "|**2024-05-29**|**Evaluating the efectiveness of sonifcation in science education using Edukoi**|Lucrezia Guiotto Nai Fovino et.al.|[2405.18908](http://arxiv.org/abs/2405.18908)|null|\n", "2405.20222": "|**2024-07-11**|**MOFA-Video: Controllable Image Animation via Generative Motion Field Adaptions in Frozen Image-to-Video Diffusion Model**|Muyao Niu et.al.|[2405.20222](http://arxiv.org/abs/2405.20222)|**[link](https://github.com/myniuuu/mofa-video)**|\n", "2406.01188": "|**2024-06-03**|**UniAnimate: Taming Unified Video Diffusion Models for Consistent Human Image Animation**|Xiang Wang et.al.|[2406.01188](http://arxiv.org/abs/2406.01188)|null|\n", "2406.03035": "|**2024-06-13**|**Follow-Your-Pose v2: Multiple-Condition Guided Character Image Animation for Stable Pose Control**|Jingyun Xue et.al.|[2406.03035](http://arxiv.org/abs/2406.03035)|null|\n", "2406.08801": "|**2024-06-16**|**Hallo: Hierarchical Audio-Driven Visual Synthesis for Portrait Image Animation**|Mingwang Xu et.al.|[2406.08801](http://arxiv.org/abs/2406.08801)|null|\n", "2407.08136": "|**2024-07-12**|**EchoMimic: Lifelike Audio-Driven Portrait Animations through Editable Landmark Conditions**|Zhiyuan Chen et.al.|[2407.08136](http://arxiv.org/abs/2407.08136)|**[link](https://github.com/antgroup/echomimic)**|\n", "2407.09012": "|**2024-07-12**|**TCAN: Animating Human Images with Temporally Consistent Pose Guidance using Diffusion Models**|Jeongho Kim et.al.|[2407.09012](http://arxiv.org/abs/2407.09012)|null|\n", "2407.15642": "|**2024-07-23**|**Cinemo: Consistent and Controllable Image Animation with Motion Diffusion Models**|Xin Ma et.al.|[2407.15642](http://arxiv.org/abs/2407.15642)|**[link](https://github.com/maxin-cn/Cinemo)**|\n", "2407.17438": "|**2024-11-21**|**HumanVid: Demystifying Training Data for Camera-controllable Human Image Animation**|Zhenzhi Wang et.al.|[2407.17438](http://arxiv.org/abs/2407.17438)|**[link](https://github.com/zhenzhiwang/humanvid)**|\n", "2409.14424": "|**2024-09-22**|**Dormant: Defending against Pose-driven Human Image Animation**|Jiachen Zhou et.al.|[2409.14424](http://arxiv.org/abs/2409.14424)|**[link](https://github.com/Manu21JC/Dormant)**|\n", "2409.19946": "|**2024-09-30**|**Illustrious: an Open Advanced Illustration Model**|Sang Hyun Park et.al.|[2409.19946](http://arxiv.org/abs/2409.19946)|null|\n", "2409.19580": "|**2024-09-29**|**High Quality Human Image Animation using Regional Supervision and Motion Blur Condition**|Zhongcong Xu et.al.|[2409.19580](http://arxiv.org/abs/2409.19580)|null|\n", "2410.07718": "|**2024-10-14**|**Hallo2: Long-Duration and High-Resolution Audio-Driven Portrait Image Animation**|Jiahao Cui et.al.|[2410.07718](http://arxiv.org/abs/2410.07718)|**[link](https://github.com/fudan-generative-vision/hallo2)**|\n", "2410.10306": "|**2024-12-11**|**Animate-X: Universal Character Image Animation with Enhanced Motion Representation**|Shuai Tan et.al.|[2410.10306](http://arxiv.org/abs/2410.10306)|null|\n", "2410.15371": "|**2024-10-20**|**FrameBridge: Improving Image-to-Video Generation with Bridge Models**|Yuji Wang et.al.|[2410.15371](http://arxiv.org/abs/2410.15371)|null|\n", "2410.24037": "|**2024-10-31**|**TPC: Test-time Procrustes Calibration for Diffusion-based Human Image Animation**|Sunjae Yoon et.al.|[2410.24037](http://arxiv.org/abs/2410.24037)|null|\n", "2411.09209": "|**2024-11-28**|**JoyVASA: Portrait and Animal Image Animation with Diffusion-Based Audio-Driven Facial Dynamics and Head Motion Generation**|Xuyang Cao et.al.|[2411.09209](http://arxiv.org/abs/2411.09209)|**[link](https://github.com/jdh-algo/JoyVASA)**|\n", "2411.17697": "|**2024-11-27**|**StableAnimator: High-Quality Identity-Preserving Human Image Animation**|Shuyuan Tu et.al.|[2411.17697](http://arxiv.org/abs/2411.17697)|**[link](https://github.com/Francis-Rings/StableAnimator)**|\n", "2411.16748": "|**2024-11-24**|**LetsTalk: Latent Diffusion Transformer for Talking Video Synthesis**|Haojie Zhang et.al.|[2411.16748](http://arxiv.org/abs/2411.16748)|null|\n", "2412.01064": "|**2024-12-04**|**FLOAT: Generative Motion Latent Flow Matching for Audio-driven Talking Portrait**|Taekyung Ki et.al.|[2412.01064](http://arxiv.org/abs/2412.01064)|null|\n", "2412.00733": "|**2025-03-13**|**Hallo3: Highly Dynamic and Realistic Portrait Image Animation with Video Diffusion Transformer**|Jiahao Cui et.al.|[2412.00733](http://arxiv.org/abs/2412.00733)|**[link](https://github.com/fudan-generative-vision/hallo3)**|\n", "2412.00397": "|**2024-11-30**|**DreamDance: Animating Human Images by Enriching 3D Geometry Cues from 2D Poses**|Yatian Pang et.al.|[2412.00397](http://arxiv.org/abs/2412.00397)|null|\n", "2412.09349": "|**2025-02-25**|**DisPose: Disentangling Pose Guidance for Controllable Human Image Animation**|Hongxiang Li et.al.|[2412.09349](http://arxiv.org/abs/2412.09349)|**[link](https://github.com/lihxxx/dispose)**|\n", "2412.16153": "|**2025-03-23**|**MotiF: Making Text Count in Image Animation with Motion Focal Loss**|Shijie Wang et.al.|[2412.16153](http://arxiv.org/abs/2412.16153)|null|\n", "2501.05020": "|**2025-03-10**|**Perception-as-Control: Fine-grained Controllable Image Animation with 3D-aware Motion Representation**|Yingjie Chen et.al.|[2501.05020](http://arxiv.org/abs/2501.05020)|null|\n", "2501.08649": "|**2025-01-15**|**Joint Learning of Depth and Appearance for Portrait Image Animation**|Xinya Ji et.al.|[2501.08649](http://arxiv.org/abs/2501.08649)|null|\n", "2501.10021": "|**2025-01-20**|**X-Dyna: Expressive Dynamic Human Image Animation**|Di Chang et.al.|[2501.10021](http://arxiv.org/abs/2501.10021)|**[link](https://github.com/bytedance/x-dyna)**|\n", "2501.18801": "|**2025-01-30**|**Every Image Listens, Every Image Dances: Music-Driven Image Animation**|Zhikang Dong et.al.|[2501.18801](http://arxiv.org/abs/2501.18801)|null|\n", "2502.04299": "|**2025-02-06**|**MotionCanvas: Cinematic Shot Design with Controllable Image-to-Video Generation**|Jinbo Xing et.al.|[2502.04299](http://arxiv.org/abs/2502.04299)|null|\n", "2502.06145": "|**2025-02-10**|**Animate Anyone 2: High-Fidelity Character Image Animation with Environment Affordance**|Li Hu et.al.|[2502.06145](http://arxiv.org/abs/2502.06145)|null|\n", "2502.05979": "|**2025-03-10**|**VFX Creator: Animated Visual Effect Generation with Controllable Diffusion Transformer**|Xinyu Liu et.al.|[2502.05979](http://arxiv.org/abs/2502.05979)|null|\n", "2502.10841": "|**2025-02-15**|**SkyReels-A1: Expressive Portrait Animation in Video Diffusion Transformers**|Di Qiu et.al.|[2502.10841](http://arxiv.org/abs/2502.10841)|**[link](https://github.com/SkyworkAI/SkyReels-A1)**|\n", "2502.17414": "|**2025-02-24**|**X-Dancer: Expressive Music to Human Dance Video Generation**|Zeyuan Chen et.al.|[2502.17414](http://arxiv.org/abs/2502.17414)|null|\n", "2503.21246": "|**2025-03-27**|**DynamiCtrl: Rethinking the Basic Structure and the Role of Text for High-quality Human Image Animation**|Haoyu Zhao et.al.|[2503.21246](http://arxiv.org/abs/2503.21246)|null|\n"}, "Video Generation": {"2502.12945": "|**2025-02-19**|**LLMPopcorn: An Empirical Study of LLMs as Assistants for Popular Micro-video Generation**|Junchen Fu et.al.|[2502.12945](http://arxiv.org/abs/2502.12945)|null|\n", "2502.12782": "|**2025-02-18**|**VidCapBench: A Comprehensive Benchmark of Video Captioning for Controllable Text-to-Video Generation**|Xinlong Chen et.al.|[2502.12782](http://arxiv.org/abs/2502.12782)|null|\n", "2502.12632": "|**2025-02-18**|**MALT Diffusion: Memory-Augmented Latent Transformers for Any-Length Video Generation**|Sihyun Yu et.al.|[2502.12632](http://arxiv.org/abs/2502.12632)|null|\n", "2502.12128": "|**2025-02-21**|**LaM-SLidE: Latent Space Modeling of Spatial Dynamical Systems via Linked Entities**|Florian Sestak et.al.|[2502.12128](http://arxiv.org/abs/2502.12128)|**[link](https://github.com/ml-jku/lam-slide)**|\n", "2502.11897": "|**2025-02-17**|**DLFR-VAE: Dynamic Latent Frame Rate VAE for Video Generation**|Zhihang Yuan et.al.|[2502.11897](http://arxiv.org/abs/2502.11897)|**[link](https://github.com/thu-nics/dlfr-vae)**|\n", "2502.11655": "|**2025-02-17**|**Object-Centric Image to Video Generation with Language Guidance**|Angel Villar-Corrales et.al.|[2502.11655](http://arxiv.org/abs/2502.11655)|null|\n", "2502.11234": "|**2025-02-16**|**MaskFlow: Discrete Flows For Flexible and Efficient Long Video Generation**|Michael Fuest et.al.|[2502.11234](http://arxiv.org/abs/2502.11234)|null|\n", "2502.11079": "|**2025-02-16**|**Phantom: Subject-consistent video generation via cross-modal alignment**|Lijie Liu et.al.|[2502.11079](http://arxiv.org/abs/2502.11079)|null|\n", "2502.10841": "|**2025-02-15**|**SkyReels-A1: Expressive Portrait Animation in Video Diffusion Transformers**|Di Qiu et.al.|[2502.10841](http://arxiv.org/abs/2502.10841)|**[link](https://github.com/SkyworkAI/SkyReels-A1)**|\n", "2502.10248": "|**2025-02-17**|**Step-Video-T2V Technical Report: The Practice, Challenges, and Future of Video Foundation Model**|Guoqing Ma et.al.|[2502.10248](http://arxiv.org/abs/2502.10248)|**[link](https://github.com/stepfun-ai/step-video-t2v)**|\n", "2502.10059": "|**2025-02-14**|**RealCam-I2V: Real-World Image-to-Video Generation with Interactive Complex Camera Control**|Teng Li et.al.|[2502.10059](http://arxiv.org/abs/2502.10059)|null|\n", "2502.09268": "|**2025-02-14**|**GEVRM: Goal-Expressive Video Generation Model For Robust Visual Manipulation**|Hongyin Zhang et.al.|[2502.09268](http://arxiv.org/abs/2502.09268)|null|\n", "2502.08639": "|**2025-02-12**|**CineMaster: A 3D-Aware and Controllable Framework for Cinematic Text-to-Video Generation**|Qinghe Wang et.al.|[2502.08639](http://arxiv.org/abs/2502.08639)|null|\n", "2502.08244": "|**2025-02-12**|**FloVD: Optical Flow Meets Video Diffusion Model for Enhanced Camera-Controlled Video Synthesis**|Wonjoon Jin et.al.|[2502.08244](http://arxiv.org/abs/2502.08244)|null|\n", "2502.08234": "|**2025-02-12**|**Learning Human Skill Generators at Key-Step Levels**|Yilu Wu et.al.|[2502.08234](http://arxiv.org/abs/2502.08234)|null|\n", "2502.08189": "|**2025-02-12**|**AnyCharV: Bootstrap Controllable Character Video Generation with Fine-to-Coarse Guidance**|Zhao Wang et.al.|[2502.08189](http://arxiv.org/abs/2502.08189)|null|\n", "2502.07737": "|**2025-02-12**|**Next Block Prediction: Video Generation via Semi-Autoregressive Modeling**|Shuhuai Ren et.al.|[2502.07737](http://arxiv.org/abs/2502.07737)|null|\n", "2502.07701": "|**2025-02-17**|**Magic 1-For-1: Generating One Minute Video Clips within One Minute**|Hongwei Yi et.al.|[2502.07701](http://arxiv.org/abs/2502.07701)|**[link](https://github.com/da-group-pku/magic-1-for-1)**|\n", "2502.07531": "|**2025-02-12**|**VidCRAFT3: Camera, Object, and Lighting Control for Image-to-Video Generation**|Sixiao Zheng et.al.|[2502.07531](http://arxiv.org/abs/2502.07531)|null|\n", "2502.07508": "|**2025-02-13**|**Enhance-A-Video: Better Generated Video for Free**|Yang Luo et.al.|[2502.07508](http://arxiv.org/abs/2502.07508)|**[link](https://github.com/NUS-HPC-AI-Lab/Enhance-A-Video)**|\n", "2502.14831": "|**2025-02-20**|**Improving the Diffusability of Autoencoders**|Ivan Skorokhodov et.al.|[2502.14831](http://arxiv.org/abs/2502.14831)|null|\n", "2502.14377": "|**2025-02-28**|**RelaCtrl: Relevance-Guided Efficient Control for Diffusion Transformers**|Ke Cao et.al.|[2502.14377](http://arxiv.org/abs/2502.14377)|null|\n", "2502.14226": "|**2025-02-20**|**Designing Parameter and Compute Efficient Diffusion Transformers using Distillation**|Vignesh Sundaresha et.al.|[2502.14226](http://arxiv.org/abs/2502.14226)|null|\n", "2502.13995": "|**2025-02-19**|**FantasyID: Face Knowledge Enhanced ID-Preserving Video Generation**|Yunpeng Zhang et.al.|[2502.13995](http://arxiv.org/abs/2502.13995)|**[link](https://github.com/Fantasy-AMAP/fantasy-id)**|\n", "2502.15672": "|**2025-02-21**|**VaViM and VaVAM: Autonomous Driving through Video Generative Modeling**|Florent Bartoccioni et.al.|[2502.15672](http://arxiv.org/abs/2502.15672)|**[link](https://github.com/valeoai/VideoActionModel)**|\n", "2502.15077": "|**2025-02-20**|**Hardware-Friendly Static Quantization Method for Video Diffusion Transformers**|Sanghyun Yi et.al.|[2502.15077](http://arxiv.org/abs/2502.15077)|null|\n", "2502.14994": "|**2025-02-20**|**LAVID: An Agentic LVLM Framework for Diffusion-Generated Video Detection**|Qingyuan Liu et.al.|[2502.14994](http://arxiv.org/abs/2502.14994)|null|\n", "2502.17414": "|**2025-02-24**|**X-Dancer: Expressive Music to Human Dance Video Generation**|Zeyuan Chen et.al.|[2502.17414](http://arxiv.org/abs/2502.17414)|null|\n", "2502.17258": "|**2025-02-24**|**VideoGrain: Modulating Space-Time Attention for Multi-grained Video Editing**|Xiangpeng Yang et.al.|[2502.17258](http://arxiv.org/abs/2502.17258)|null|\n", "2502.17119": "|**2025-02-24**|**Diffusion Models for Tabular Data: Challenges, Current Progress, and Future Directions**|Zhong Li et.al.|[2502.17119](http://arxiv.org/abs/2502.17119)|**[link](https://github.com/diffusion-model-leiden/awesome-diffusion-models-for-tabular-data)**|\n", "2502.15894": "|**2025-02-21**|**RIFLEx: A Free Lunch for Length Extrapolation in Video Diffusion Transformers**|Min Zhao et.al.|[2502.15894](http://arxiv.org/abs/2502.15894)|null|\n", "2502.18137": "|**2025-02-25**|**SpargeAttn: Accurate Sparse Attention Accelerating Any Model Inference**|Jintao Zhang et.al.|[2502.18137](http://arxiv.org/abs/2502.18137)|**[link](https://github.com/thu-ml/spargeattn)**|\n", "2502.17863": "|**2025-02-25**|**ASurvey: Spatiotemporal Consistency in Video Generation**|Zhiyu Yin et.al.|[2502.17863](http://arxiv.org/abs/2502.17863)|null|\n", "2502.20307": "|**2025-02-27**|**Mobius: Text to Seamless Looping Video Generation via Latent Shift**|Xiuli Bi et.al.|[2502.20307](http://arxiv.org/abs/2502.20307)|**[link](https://github.com/yisuitt/mobius)**|\n", "2502.20126": "|**2025-02-27**|**FlexiDiT: Your Diffusion Transformer Can Easily Generate High-Quality Samples with Less Compute**|Sotiris Anagnostidis et.al.|[2502.20126](http://arxiv.org/abs/2502.20126)|null|\n", "2502.19868": "|**2025-02-27**|**C-Drag: Chain-of-Thought Driven Motion Controller for Video Generation**|Yuhao Li et.al.|[2502.19868](http://arxiv.org/abs/2502.19868)|**[link](https://github.com/weslee88524/c-drag-official-repo)**|\n", "2502.19455": "|**2025-02-26**|**FLAP: Fully-controllable Audio-driven Portrait Video Generation through 3D head conditioned diffusion mode**|Lingzhou Mu et.al.|[2502.19455](http://arxiv.org/abs/2502.19455)|null|\n", "2502.19454": "|**2025-03-03**|**TransVDM: Motion-Constrained Video Diffusion Model for Transparent Video Synthesis**|Menghao Li et.al.|[2502.19454](http://arxiv.org/abs/2502.19454)|null|\n", "2502.21314": "|**2025-03-07**|**Raccoon: Multi-stage Diffusion Training with Coarse-to-Fine Curating Videos**|Zhiyu Tan et.al.|[2502.21314](http://arxiv.org/abs/2502.21314)|null|\n", "2502.21079": "|**2025-02-28**|**Training-free and Adaptive Sparse Attention for Efficient Long Video Generation**|Yifei Xia et.al.|[2502.21079](http://arxiv.org/abs/2502.21079)|null|\n", "2502.20811": "|**2025-02-28**|**HAIC: Improving Human Action Understanding and Generation with Better Captions for Multi-modal Large Language Models**|Xiao Wang et.al.|[2502.20811](http://arxiv.org/abs/2502.20811)|null|\n", "2502.20694": "|**2025-02-28**|**WorldModelBench: Judging Video Generation Models As World Models**|Dacheng Li et.al.|[2502.20694](http://arxiv.org/abs/2502.20694)|null|\n", "2503.02341": "|**2025-03-04**|**GRADEO: Towards Human-Like Evaluation for Text-to-Video Generation via Multi-Step Reasoning**|Zhun Mou et.al.|[2503.02341](http://arxiv.org/abs/2503.02341)|null|\n", "2503.01739": "|**2025-03-03**|**VideoUFO: A Million-Scale User-Focused Dataset for Text-to-Video Generation**|Wenhao Wang et.al.|[2503.01739](http://arxiv.org/abs/2503.01739)|null|\n", "2503.01107": "|**2025-03-03**|**VideoHandles: Editing 3D Object Compositions in Videos Using Video Generative Priors**|Juil Koo et.al.|[2503.01107](http://arxiv.org/abs/2503.01107)|null|\n", "2503.00948": "|**2025-03-02**|**Extrapolating and Decoupling Image-to-Video Generation Models: Motion Modeling is Easier Than You Think**|Jie Tian et.al.|[2503.00948](http://arxiv.org/abs/2503.00948)|**[link](https://github.com/Chuge0335/EDG)**|\n", "2503.00276": "|**2025-03-01**|**Learning to Animate Images from A Few Videos to Portray Delicate Human Actions**|Haoxin Li et.al.|[2503.00276](http://arxiv.org/abs/2503.00276)|null|\n", "2503.00200": "|**2025-03-04**|**Unified Video Action Model**|Shuang Li et.al.|[2503.00200](http://arxiv.org/abs/2503.00200)|null|\n", "2503.00045": "|**2025-02-26**|**Glad: A Streaming Scene Generator for Autonomous Driving**|Bin Xie et.al.|[2503.00045](http://arxiv.org/abs/2503.00045)|null|\n", "2503.01873": "|**2025-02-26**|**Online Pseudo-average Shifting Attention(PASA) for Robust Low-precision LLM Inference: Algorithms and Numerical Analysis**|Long Cheng et.al.|[2503.01873](http://arxiv.org/abs/2503.01873)|null|\n", "2503.03751": "|**2025-03-05**|**GEN3C: 3D-Informed World-Consistent Video Generation with Precise Camera Control**|Xuanchi Ren et.al.|[2503.03751](http://arxiv.org/abs/2503.03751)|**[link](https://github.com/nv-tlabs/GEN3C)**|\n", "2503.03708": "|**2025-03-08**|**Rethinking Video Tokenization: A Conditioned Diffusion-based Approach**|Nianzu Yang et.al.|[2503.03708](http://arxiv.org/abs/2503.03708)|null|\n", "2503.03689": "|**2025-03-05**|**DualDiff+: Dual-Branch Diffusion for High-Fidelity Video Generation with Reward Guidance**|Zhao Yang et.al.|[2503.03689](http://arxiv.org/abs/2503.03689)|**[link](https://github.com/yangzhaojason/DualDiff)**|\n", "2503.03558": "|**2025-03-05**|**High-Quality Virtual Single-Viewpoint Surgical Video: Geometric Autocalibration of Multiple Cameras in Surgical Lights**|Yuna Kato et.al.|[2503.03558](http://arxiv.org/abs/2503.03558)|**[link](https://github.com/isogawalab/singleviewsurgicalvideo)**|\n", "2503.03355": "|**2025-03-05**|**Video Super-Resolution: All You Need is a Video Diffusion Model**|Zhihao Zhan et.al.|[2503.03355](http://arxiv.org/abs/2503.03355)|null|\n", "2503.04720": "|**2025-03-06**|**FluidNexus: 3D Fluid Reconstruction and Prediction from a Single Video**|Yue Gao et.al.|[2503.04720](http://arxiv.org/abs/2503.04720)|null|\n", "2503.04666": "|**2025-03-06**|**What Are You Doing? A Closer Look at Controllable Human Video Generation**|Emanuele Bugliarello et.al.|[2503.04666](http://arxiv.org/abs/2503.04666)|null|\n", "2503.04606": "|**2025-03-08**|**The Best of Both Worlds: Integrating Language Models and Diffusion Models for Video Generation**|Aoxiong Yin et.al.|[2503.04606](http://arxiv.org/abs/2503.04606)|null|\n", "2503.05242": "|**2025-03-07**|**MM-StoryAgent: Immersive Narrated Storybook Video Generation with a Multi-Agent Paradigm across Text, Image and Audio**|Xuenan Xu et.al.|[2503.05242](http://arxiv.org/abs/2503.05242)|**[link](https://github.com/x-plug/mm_storyagent)**|\n", "2503.05236": "|**2025-03-07**|**Unified Reward Model for Multimodal Understanding and Generation**|Yibin Wang et.al.|[2503.05236](http://arxiv.org/abs/2503.05236)|null|\n", "2503.04871": "|**2025-03-06**|**Toward Lightweight and Fast Decoders for Diffusion Models in Image and Video Generation**|Alexey Buzovkin et.al.|[2503.04871](http://arxiv.org/abs/2503.04871)|**[link](https://github.com/RedShift51/fast-latent-decoders)**|\n", "2503.04824": "|**2025-03-05**|**ProReflow: Progressive Reflow with Decomposed Velocity**|Lei Ke et.al.|[2503.04824](http://arxiv.org/abs/2503.04824)|null|\n", "2503.07418": "|**2025-03-10**|**AR-Diffusion: Asynchronous Video Generation with Auto-Regressive Diffusion**|Mingzhen Sun et.al.|[2503.07418](http://arxiv.org/abs/2503.07418)|null|\n", "2503.07314": "|**2025-03-10**|**Automated Movie Generation via Multi-Agent CoT Planning**|Weijia Wu et.al.|[2503.07314](http://arxiv.org/abs/2503.07314)|**[link](https://github.com/showlab/movieagent)**|\n", "2503.06923": "|**2025-03-10**|**From Reusing to Forecasting: Accelerating Diffusion Models with TaylorSeers**|Jiacheng Liu et.al.|[2503.06923](http://arxiv.org/abs/2503.06923)|**[link](https://github.com/Shenyi-Z/TaylorSeer)**|\n", "2503.06800": "|**2025-03-09**|**VideoPhy-2: A Challenging Action-Centric Physical Commonsense Evaluation in Video Generation**|Hritik Bansal et.al.|[2503.06800](http://arxiv.org/abs/2503.06800)|null|\n", "2503.06564": "|**2025-03-09**|**TR-DQ: Time-Rotation Diffusion Quantization**|Yihua Shao et.al.|[2503.06564](http://arxiv.org/abs/2503.06564)|null|\n", "2503.06545": "|**2025-03-09**|**QuantCache: Adaptive Importance-Guided Quantization with Hierarchical Latent and Layer Caching for Video Generation**|Junyi Wu et.al.|[2503.06545](http://arxiv.org/abs/2503.06545)|**[link](https://github.com/junyiwucode/quantcache)**|\n", "2503.06508": "|**2025-03-11**|**LightMotion: A Light and Tuning-free Method for Simulating Camera Motion in Video Generation**|Quanjian Song et.al.|[2503.06508](http://arxiv.org/abs/2503.06508)|null|\n", "2503.06364": "|**2025-03-09**|**Generative Video Bi-flow**|Chen Liu et.al.|[2503.06364](http://arxiv.org/abs/2503.06364)|null|\n", "2503.06310": "|**2025-03-08**|**Text2Story: Advancing Video Storytelling with Text Guidance**|Taewon Kang et.al.|[2503.06310](http://arxiv.org/abs/2503.06310)|null|\n", "2503.06171": "|**2025-03-08**|**ROCM: RLHF on consistency models**|Shivanshu Shekhar et.al.|[2503.06171](http://arxiv.org/abs/2503.06171)|null|\n", "2503.06170": "|**2025-03-12**|**Object-Centric World Model for Language-Guided Manipulation**|Youngjoon Jeong et.al.|[2503.06170](http://arxiv.org/abs/2503.06170)|null|\n", "2503.06163": "|**2025-03-08**|**VACT: A Video Automatic Causal Testing System and a Benchmark**|Haotong Yang et.al.|[2503.06163](http://arxiv.org/abs/2503.06163)|null|\n", "2503.06136": "|**2025-03-08**|**GSV3D: Gaussian Splatting-based Geometric Distillation with Stable Video Diffusion for Single-Image 3D Object Generation**|Ye Tao et.al.|[2503.06136](http://arxiv.org/abs/2503.06136)|null|\n", "2503.06053": "|**2025-03-08**|**DropletVideo: A Dataset and Approach to Explore Integral Spatio-Temporal Consistent Video Generation**|Runze Zhang et.al.|[2503.06053](http://arxiv.org/abs/2503.06053)|null|\n", "2503.05978": "|**2025-03-07**|**MagicInfinite: Generating Infinite Talking Videos with Your Words and Voice**|Hongwei Yi et.al.|[2503.05978](http://arxiv.org/abs/2503.05978)|null|\n", "2503.08665": "|**2025-03-11**|**REGEN: Learning Compact Video Embedding with (Re-)Generative Decoder**|Yitian Zhang et.al.|[2503.08665](http://arxiv.org/abs/2503.08665)|null|\n", "2503.08605": "|**2025-03-11**|**Tuning-Free Multi-Event Long Video Generation via Synchronized Coupled Sampling**|Subin Kim et.al.|[2503.08605](http://arxiv.org/abs/2503.08605)|null|\n", "2503.08307": "|**2025-03-12**|**$^R$FLAV: Rolling Flow matching for infinite Audio Video generation**|Alex Ergasti et.al.|[2503.08307](http://arxiv.org/abs/2503.08307)|**[link](https://github.com/ergastialex/r-flav)**|\n", "2503.08153": "|**2025-03-11**|**WISA: World Simulator Assistant for Physics-Aware Text-to-Video Generation**|Jing Wang et.al.|[2503.08153](http://arxiv.org/abs/2503.08153)|null|\n", "2503.08037": "|**2025-03-11**|**ObjectMover: Generative Object Movement with Video Prior**|Xin Yu et.al.|[2503.08037](http://arxiv.org/abs/2503.08037)|null|\n", "2503.08003": "|**2025-03-11**|**How Can Video Generative AI Transform K-12 Education? Examining Teachers' Perspectives through TPACK and TAM**|Unggi Lee et.al.|[2503.08003](http://arxiv.org/abs/2503.08003)|null|\n", "2503.07602": "|**2025-03-10**|**DreamRelation: Relation-Centric Video Customization**|Yujie Wei et.al.|[2503.07602](http://arxiv.org/abs/2503.07602)|null|\n", "2503.07598": "|**2025-03-11**|**VACE: All-in-One Video Creation and Editing**|Zeyinzi Jiang et.al.|[2503.07598](http://arxiv.org/abs/2503.07598)|null|\n", "2503.09595": "|**2025-03-12**|**PISA Experiments: Exploring Physics Post-Training for Video Diffusion Models by Watching Stuff Drop**|Chenyu Li et.al.|[2503.09595](http://arxiv.org/abs/2503.09595)|**[link](https://github.com/vision-x-nyu/pisa-experiments)**|\n", "2503.09344": "|**2025-03-12**|**Unified Dense Prediction of Video Diffusion**|Lehan Yang et.al.|[2503.09344](http://arxiv.org/abs/2503.09344)|null|\n", "2503.09215": "|**2025-03-12**|**Other Vehicle Trajectories Are Also Needed: A Driving World Model Unifies Ego-Other Vehicle Trajectories in Video Latant Space**|Jian Zhu et.al.|[2503.09215](http://arxiv.org/abs/2503.09215)|null|\n", "2503.09160": "|**2025-03-13**|**WonderVerse: Extendable 3D Scene Generation with Video Generative Models**|Hao Feng et.al.|[2503.09160](http://arxiv.org/abs/2503.09160)|null|\n", "2503.09154": "|**2025-03-12**|**SwapAnyone: Consistent and Realistic Video Synthesis for Swapping Any Person into Any Video**|Chengshu Zhao et.al.|[2503.09154](http://arxiv.org/abs/2503.09154)|**[link](https://github.com/pku-yuangroup/swapanyone)**|\n", "2503.09151": "|**2025-03-12**|**Reangle-A-Video: 4D Video Generation as Video-to-Video Translation**|Hyeonho Jeong et.al.|[2503.09151](http://arxiv.org/abs/2503.09151)|null|\n", "2503.10592": "|**2025-03-13**|**CameraCtrl II: Dynamic Scene Exploration via Camera-controlled Video Diffusion Models**|Hao He et.al.|[2503.10592](http://arxiv.org/abs/2503.10592)|null|\n", "2503.10589": "|**2025-03-13**|**Long Context Tuning for Video Generation**|Yuwei Guo et.al.|[2503.10589](http://arxiv.org/abs/2503.10589)|null|\n", "2503.10391": "|**2025-03-13**|**CINEMA: Coherent Multi-Subject Video Generation via MLLM-Based Guidance**|Yufan Deng et.al.|[2503.10391](http://arxiv.org/abs/2503.10391)|null|\n", "2503.10096": "|**2025-03-13**|**Semantic Latent Motion for Portrait Video Generation**|Qiyuan Zhang et.al.|[2503.10096](http://arxiv.org/abs/2503.10096)|null|\n", "2503.10076": "|**2025-03-16**|**VMBench: A Benchmark for Perception-Aligned Video Motion Generation**|Xinran Ling et.al.|[2503.10076](http://arxiv.org/abs/2503.10076)|**[link](https://github.com/gd-aigc/vmbench)**|\n", "2503.09949": "|**2025-03-13**|**UVE: Are MLLMs Unified Evaluators for AI-Generated Videos?**|Yuanxin Liu et.al.|[2503.09949](http://arxiv.org/abs/2503.09949)|**[link](https://github.com/bytedance/uve)**|\n", "2503.09942": "|**2025-03-13**|**Cosh-DiT: Co-Speech Gesture Video Synthesis via Hybrid Audio-Visual Diffusion Transformers**|Yasheng Sun et.al.|[2503.09942](http://arxiv.org/abs/2503.09942)|null|\n", "2503.09926": "|**2025-03-13**|**VideoMerge: Towards Training-free Long Video Generation**|Siyang Zhang et.al.|[2503.09926](http://arxiv.org/abs/2503.09926)|null|\n", "2503.09871": "|**2025-03-12**|**LuciBot: Automated Robot Policy Learning from Generated Videos**|Xiaowen Qiu et.al.|[2503.09871](http://arxiv.org/abs/2503.09871)|null|\n", "2503.09837": "|**2025-03-14**|**On the Limitations of Vision-Language Models in Understanding Image Transforms**|Ahmad Mustafa Anis et.al.|[2503.09837](http://arxiv.org/abs/2503.09837)|null|\n", "2503.09733": "|**2025-03-12**|**I2V3D: Controllable image-to-video generation with 3D guidance**|Zhiyuan Zhang et.al.|[2503.09733](http://arxiv.org/abs/2503.09733)|null|\n", "2503.09675": "|**2025-03-12**|**Accelerating Diffusion Sampling via Exploiting Local Transition Coherence**|Shangwen Zhu et.al.|[2503.09675](http://arxiv.org/abs/2503.09675)|null|\n", "2503.09642": "|**2025-03-12**|**Open-Sora 2.0: Training a Commercial-Level Video Generation Model in $200k**|Xiangyu Peng et.al.|[2503.09642](http://arxiv.org/abs/2503.09642)|**[link](https://github.com/hpcaitech/open-sora)**|\n", "2503.09631": "|**2025-03-11**|**V2M4: 4D Mesh Animation Reconstruction from a Single Monocular Video**|Jianqi Chen et.al.|[2503.09631](http://arxiv.org/abs/2503.09631)|null|\n", "2503.11647": "|**2025-03-14**|**ReCamMaster: Camera-Controlled Generative Rendering from A Single Video**|Jianhong Bai et.al.|[2503.11647](http://arxiv.org/abs/2503.11647)|null|\n", "2503.11513": "|**2025-03-14**|**HiTVideo: Hierarchical Tokenizers for Enhancing Text-to-Video Generation with Autoregressive Large Language Models**|Ziqin Zhou et.al.|[2503.11513](http://arxiv.org/abs/2503.11513)|null|\n", "2503.11423": "|**2025-03-14**|**TASTE-Rob: Advancing Video Generation of Task-Oriented Hand-Object Interaction for Generalizable Robotic Manipulation**|Hongxiang Zhao et.al.|[2503.11423](http://arxiv.org/abs/2503.11423)|null|\n", "2503.11251": "|**2025-03-14**|**Step-Video-TI2V Technical Report: A State-of-the-Art Text-Driven Image-to-Video Generation Model**|Haoyang Huang et.al.|[2503.11251](http://arxiv.org/abs/2503.11251)|**[link](https://github.com/stepfun-ai/step-video-ti2v)**|\n", "2503.11190": "|**2025-03-14**|**Cross-Modal Learning for Music-to-Music-Video Description Generation**|Zhuoyuan Mao et.al.|[2503.11190](http://arxiv.org/abs/2503.11190)|null|\n", "2503.10719": "|**2025-03-17**|**Long-Video Audio Synthesis with Multi-Agent Collaboration**|Yehang Zhang et.al.|[2503.10719](http://arxiv.org/abs/2503.10719)|null|\n", "2503.10704": "|**2025-03-12**|**Error Analyses of Auto-Regressive Video Diffusion Models: A Unified Framework**|Jing Wang et.al.|[2503.10704](http://arxiv.org/abs/2503.10704)|null|\n", "2503.13319": "|**2025-03-17**|**MagicDistillation: Weak-to-Strong Video Distillation for Large-Scale Portrait Few-Step Synthesis**|Shitong Shao et.al.|[2503.13319](http://arxiv.org/abs/2503.13319)|null|\n", "2503.13160": "|**2025-03-17**|**Language-guided Open-world Video Anomaly Detection**|Zihao Liu et.al.|[2503.13160](http://arxiv.org/abs/2503.13160)|null|\n", "2503.12953": "|**2025-03-17**|**Frame-wise Conditioning Adaptation for Fine-Tuning Diffusion Models in Text-to-Video Prediction**|Zheyuan Liu et.al.|[2503.12953](http://arxiv.org/abs/2503.12953)|null|\n", "2503.12828": "|**2025-03-17**|**AUTV: Creating Underwater Video Datasets with Pixel-wise Annotations**|Quang Trung Truong et.al.|[2503.12828](http://arxiv.org/abs/2503.12828)|null|\n", "2503.12535": "|**2025-03-16**|**SPC-GS: Gaussian Splatting with Semantic-Prompt Consistency for Indoor Open-World Free-view Synthesis from Sparse Inputs**|Guibiao Liao et.al.|[2503.12535](http://arxiv.org/abs/2503.12535)|null|\n", "2503.12102": "|**2025-03-15**|**A Speech-to-Video Synthesis Approach Using Spatio-Temporal Diffusion for Vocal Tract MRI**|Paula Andrea P\u00e9rez-Toro et.al.|[2503.12102](http://arxiv.org/abs/2503.12102)|null|\n", "2503.12024": "|**2025-03-15**|**SteerX: Creating Any Camera-Free 3D and 4D Scenes with Geometric Steering**|Byeongjun Park et.al.|[2503.12024](http://arxiv.org/abs/2503.12024)|**[link](https://github.com/byeongjun-park/SteerX)**|\n", "2503.14505": "|**2025-03-18**|**MusicInfuser: Making Video Diffusion Listen and Dance**|Susung Hong et.al.|[2503.14505](http://arxiv.org/abs/2503.14505)|null|\n", "2503.14428": "|**2025-03-18**|**MagicComp: Training-free Dual-Phase Refinement for Compositional Video Generation**|Hongyu Zhang et.al.|[2503.14428](http://arxiv.org/abs/2503.14428)|null|\n", "2503.14378": "|**2025-03-18**|**Impossible Videos**|Zechen Bai et.al.|[2503.14378](http://arxiv.org/abs/2503.14378)|null|\n", "2503.14325": "|**2025-03-18**|**LeanVAE: An Ultra-Efficient Reconstruction VAE for Video Diffusion Models**|Yu Cheng et.al.|[2503.14325](http://arxiv.org/abs/2503.14325)|**[link](https://github.com/westlake-repl/leanvae)**|\n", "2503.14151": "|**2025-03-18**|**Concat-ID: Towards Universal Identity-Preserving Video Synthesis**|Yong Zhong et.al.|[2503.14151](http://arxiv.org/abs/2503.14151)|null|\n", "2503.14070": "|**2025-03-18**|**Fast Autoregressive Video Generation with Diagonal Decoding**|Yang Ye et.al.|[2503.14070](http://arxiv.org/abs/2503.14070)|null|\n", "2503.14064": "|**2025-03-18**|**AIGVE-Tool: AI-Generated Video Evaluation Toolkit with Multifaceted Benchmark**|Xinhao Xiang et.al.|[2503.14064](http://arxiv.org/abs/2503.14064)|**[link](https://github.com/shanexiangh/aigve_tool)**|\n", "2503.15417": "|**2025-03-19**|**Temporal Regularization Makes Your Video Generator Stronger**|Harold Haodong Chen et.al.|[2503.15417](http://arxiv.org/abs/2503.15417)|null|\n", "2503.15138": "|**2025-03-20**|**VideoGen-of-Thought: Step-by-step generating multi-shot video with minimal manual intervention**|Mingzhe Zheng et.al.|[2503.15138](http://arxiv.org/abs/2503.15138)|null|\n", "2503.14966": "|**2025-03-19**|**Ultrasound Image-to-Video Synthesis via Latent Dynamic Diffusion Models**|Tingxiu Chen et.al.|[2503.14966](http://arxiv.org/abs/2503.14966)|**[link](https://github.com/medaitech/u_i2v)**|\n", "2503.14526": "|**2025-03-15**|**ReBot: Scaling Robot Learning with Real-to-Sim-to-Real Robotic Video Synthesis**|Yu Fang et.al.|[2503.14526](http://arxiv.org/abs/2503.14526)|null|\n", "2503.16428": "|**2025-03-20**|**XAttention: Block Sparse Attention with Antidiagonal Scoring**|Ruyi Xu et.al.|[2503.16428](http://arxiv.org/abs/2503.16428)|**[link](https://github.com/mit-han-lab/x-attention)**|\n", "2503.16421": "|**2025-03-20**|**MagicMotion: Controllable Video Generation with Dense-to-Sparse Trajectory Guidance**|Quanhao Li et.al.|[2503.16421](http://arxiv.org/abs/2503.16421)|null|\n", "2503.16400": "|**2025-03-20**|**ScalingNoise: Scaling Inference-Time Search for Generating Infinite Videos**|Haolin Yang et.al.|[2503.16400](http://arxiv.org/abs/2503.16400)|null|\n", "2503.16396": "|**2025-03-21**|**SV4D 2.0: Enhancing Spatio-Temporal Consistency in Multi-View Video Diffusion for High-Quality 4D Generation**|Chun-Han Yao et.al.|[2503.16396](http://arxiv.org/abs/2503.16396)|null|\n", "2503.16068": "|**2025-03-20**|**PoseTraj: Pose-Aware Trajectory Control in Video Diffusion**|Longbin Ji et.al.|[2503.16068](http://arxiv.org/abs/2503.16068)|null|\n", "2503.15996": "|**2025-03-20**|**Animating the Uncaptured: Humanoid Mesh Animation with Video Diffusion Models**|Marc Bened\u00ed San Mill\u00e1n et.al.|[2503.15996](http://arxiv.org/abs/2503.15996)|null|\n", "2503.15875": "|**2025-03-20**|**MiLA: Multi-view Intensive-fidelity Long-term Video Generation World Model for Autonomous Driving**|Haiguang Wang et.al.|[2503.15875](http://arxiv.org/abs/2503.15875)|**[link](https://github.com/xiaomi-mlab/mila.github.io)**|\n", "2503.15855": "|**2025-03-20**|**VideoRFSplat: Direct Scene-Level Text-to-3D Gaussian Splatting Generation with Flexible Pose and Multi-View Joint Modeling**|Hyojun Go et.al.|[2503.15855](http://arxiv.org/abs/2503.15855)|null|\n", "2503.17359": "|**2025-03-21**|**Position: Interactive Generative Video as Next-Generation Game Engine**|Jiwen Yu et.al.|[2503.17359](http://arxiv.org/abs/2503.17359)|null|\n", "2503.17029": "|**2025-03-21**|**AnimatePainter: A Self-Supervised Rendering Framework for Reconstructing Painting Process**|Junjie Hu et.al.|[2503.17029](http://arxiv.org/abs/2503.17029)|null|\n", "2503.16983": "|**2025-03-21**|**Enabling Versatile Controls for Video Diffusion Models**|Xu Zhang et.al.|[2503.16983](http://arxiv.org/abs/2503.16983)|null|\n", "2503.16942": "|**2025-03-25**|**Re-HOLD: Video Hand Object Interaction Reenactment via adaptive Layout-instructed Diffusion Model**|Yingying Fan et.al.|[2503.16942](http://arxiv.org/abs/2503.16942)|null|\n", "2503.16611": "|**2025-03-20**|**A Recipe for Generating 3D Worlds From a Single Image**|Katja Schwarz et.al.|[2503.16611](http://arxiv.org/abs/2503.16611)|null|\n", "2503.18945": "|**2025-03-25**|**Aether: Geometric-Aware Unified World Modeling**|Aether Team et.al.|[2503.18945](http://arxiv.org/abs/2503.18945)|null|\n", "2503.18942": "|**2025-03-24**|**Video-T1: Test-Time Scaling for Video Generation**|Fangfu Liu et.al.|[2503.18942](http://arxiv.org/abs/2503.18942)|null|\n", "2503.18940": "|**2025-03-24**|**Training-free Diffusion Acceleration with Bottleneck Sampling**|Ye Tian et.al.|[2503.18940](http://arxiv.org/abs/2503.18940)|null|\n", "2503.18559": "|**2025-03-25**|**AMD-Hummingbird: Towards an Efficient Text-to-Video Model**|Takashi Isobe et.al.|[2503.18559](http://arxiv.org/abs/2503.18559)|null|\n", "2503.18552": "|**2025-03-24**|**EvAnimate: Event-conditioned Image-to-Video Generation for Human Animation**|Qiang Qu et.al.|[2503.18552](http://arxiv.org/abs/2503.18552)|null|\n", "2503.18507": "|**2025-03-24**|**Can Text-to-Video Generation help Video-Language Alignment?**|Luca Zanella et.al.|[2503.18507](http://arxiv.org/abs/2503.18507)|null|\n", "2503.18429": "|**2025-03-24**|**Teller: Real-Time Streaming Audio-Driven Portrait Animation with Autoregressive Motion Generation**|Dingcheng Zhen et.al.|[2503.18429](http://arxiv.org/abs/2503.18429)|null|\n", "2503.18386": "|**2025-03-24**|**Resource-Efficient Motion Control for Video Generation via Dynamic Mask Guidance**|Sicong Feng et.al.|[2503.18386](http://arxiv.org/abs/2503.18386)|null|\n", "2503.18150": "|**2025-03-23**|**LongDiff: Training-Free Long Video Generation in One Go**|Zhuoling Li et.al.|[2503.18150](http://arxiv.org/abs/2503.18150)|null|\n", "2503.17934": "|**2025-03-23**|**TransAnimate: Taming Layer Diffusion to Generate RGBA Video**|Xuewei Chen et.al.|[2503.17934](http://arxiv.org/abs/2503.17934)|null|\n", "2503.17735": "|**2025-03-22**|**RDTF: Resource-efficient Dual-mask Training Framework for Multi-frame Animated Sticker Generation**|Zhiqiang Yuan et.al.|[2503.17735](http://arxiv.org/abs/2503.17735)|null|\n", "2503.17539": "|**2025-03-21**|**Generating, Fast and Slow: Scalable Parallel Video Generation with Video Interface Networks**|Bhishma Dedhia et.al.|[2503.17539](http://arxiv.org/abs/2503.17539)|null|\n", "2503.19907": "|**2025-03-25**|**FullDiT: Multi-Task Video Generative Foundation Model with Full Attention**|Xuan Ju et.al.|[2503.19907](http://arxiv.org/abs/2503.19907)|null|\n", "2503.19881": "|**2025-03-25**|**Mask$^2$DiT: Dual Mask-based Diffusion Transformer for Multi-Scene Long Video Generation**|Tianhao Qi et.al.|[2503.19881](http://arxiv.org/abs/2503.19881)|null|\n", "2503.19824": "|**2025-03-25**|**AudCast: Audio-Driven Human Video Generation by Cascaded Diffusion Transformers**|Jiazhi Guan et.al.|[2503.19824](http://arxiv.org/abs/2503.19824)|null|\n", "2503.19462": "|**2025-03-25**|**AccVideo: Accelerating Video Diffusion Model with Synthetic Dataset**|Haiyu Zhang et.al.|[2503.19462](http://arxiv.org/abs/2503.19462)|null|\n", "2503.19385": "|**2025-03-26**|**Inference-Time Scaling for Flow Models via Stochastic Generation and Rollover Budget Forcing**|Jaihoon Kim et.al.|[2503.19385](http://arxiv.org/abs/2503.19385)|null|\n", "2503.19383": "|**2025-03-25**|**MVPortrait: Text-Guided Motion and Emotion Control for Multi-view Vivid Portrait Animation**|Yukang Lin et.al.|[2503.19383](http://arxiv.org/abs/2503.19383)|null|\n", "2503.19369": "|**2025-03-26**|**EfficientMT: Efficient Temporal Adaptation for Motion Transfer in Text-to-Video Diffusion Models**|Yufei Cai et.al.|[2503.19369](http://arxiv.org/abs/2503.19369)|null|\n", "2503.19325": "|**2025-03-25**|**Long-Context Autoregressive Video Modeling with Next-Frame Prediction**|Yuchao Gu et.al.|[2503.19325](http://arxiv.org/abs/2503.19325)|null|\n", "2503.20731": "|**2025-03-26**|**RecTable: Fast Modeling Tabular Data with Rectified Flow**|Masane Fuchi et.al.|[2503.20731](http://arxiv.org/abs/2503.20731)|**[link](https://github.com/fmp453/rectable)**|\n", "2503.20654": "|**2025-03-26**|**AccidentSim: Generating Physically Realistic Vehicle Collision Videos from Real-World Accident Reports**|Xiangwen Zhang et.al.|[2503.20654](http://arxiv.org/abs/2503.20654)|null|\n", "2503.20523": "|**2025-03-26**|**GAIA-2: A Controllable Multi-View Generative World Model for Autonomous Driving**|Lloyd Russell et.al.|[2503.20523](http://arxiv.org/abs/2503.20523)|null|\n", "2503.20491": "|**2025-03-26**|**VPO: Aligning Text-to-Video Generation Models with Prompt Optimization**|Jiale Cheng et.al.|[2503.20491](http://arxiv.org/abs/2503.20491)|**[link](https://github.com/thu-coai/vpo)**|\n", "2503.20314": "|**2025-03-26**|**Wan: Open and Advanced Large-Scale Video Generative Models**|WanTeam et.al.|[2503.20314](http://arxiv.org/abs/2503.20314)|**[link](https://github.com/wan-video/wan2.1)**|\n", "2503.20240": "|**2025-03-26**|**Unconditional Priors Matter! Improving Conditional Generation of Fine-Tuned Diffusion Models**|Prin Phunyaphibarn et.al.|[2503.20240](http://arxiv.org/abs/2503.20240)|null|\n", "2503.20218": "|**2025-03-26**|**Video Motion Graphs**|Haiyang Liu et.al.|[2503.20218](http://arxiv.org/abs/2503.20218)|null|\n", "2503.20118": "|**2025-03-25**|**Zero-Shot Human-Object Interaction Synthesis with Multimodal Priors**|Yuke Lou et.al.|[2503.20118](http://arxiv.org/abs/2503.20118)|null|\n", "2503.19953": "|**2025-03-25**|**Self-Supervised Learning of Motion Concepts by Optimizing Counterfactuals**|Stefan Stojanov et.al.|[2503.19953](http://arxiv.org/abs/2503.19953)|null|\n", "2503.19940": "|**2025-03-25**|**FuXi-RTM: A Physics-Guided Prediction Framework with Radiative Transfer Modeling**|Qiusheng Huang et.al.|[2503.19940](http://arxiv.org/abs/2503.19940)|null|\n", "2503.21781": "|**2025-03-27**|**VideoMage: Multi-Subject and Motion Customization of Text-to-Video Diffusion Models**|Chi-Pin Huang et.al.|[2503.21781](http://arxiv.org/abs/2503.21781)|null|\n", "2503.21765": "|**2025-03-27**|**Exploring the Evolution of Physics Cognition in Video Generation: A Survey**|Minghui Lin et.al.|[2503.21765](http://arxiv.org/abs/2503.21765)|**[link](https://github.com/minnie-lin/awesome-physics-cognition-based-video-generation)**|\n", "2503.21755": "|**2025-03-27**|**VBench-2.0: Advancing Video Generation Benchmark Suite for Intrinsic Faithfulness**|Dian Zheng et.al.|[2503.21755](http://arxiv.org/abs/2503.21755)|**[link](https://github.com/vchitect/vbench)**|\n", "2503.21616": "|**2025-03-27**|**Audio-driven Gesture Generation via Deviation Feature in the Latent Space**|Jiahui Chen et.al.|[2503.21616](http://arxiv.org/abs/2503.21616)|null|\n", "2503.21144": "|**2025-03-27**|**ChatAnyone: Stylized Real-time Portrait Video Generation with Hierarchical Motion Diffusion Model**|Jinwei Qi et.al.|[2503.21144](http://arxiv.org/abs/2503.21144)|null|\n", "2503.20822": "|**2025-03-26**|**Synthetic Video Enhances Physical Fidelity in Video Synthesis**|Qi Zhao et.al.|[2503.20822](http://arxiv.org/abs/2503.20822)|null|\n"}, "TryOn": {"2502.03449": "|**2025-02-05**|**Dress-1-to-3: Single Image to Simulation-Ready 3D Outfit with Diffusion Prior and Differentiable Physics**|Xuan Li et.al.|[2502.03449](http://arxiv.org/abs/2502.03449)|null|\n", "2502.01626": "|**2025-02-03**|**MFP-VTON: Enhancing Mask-Free Person-to-Person Virtual Try-On via Diffusion Transformer**|Le Shen et.al.|[2502.01626](http://arxiv.org/abs/2502.01626)|null|\n", "2501.16757": "|**2025-03-15**|**ITVTON: Virtual Try-On Diffusion Transformer Based on Integrated Image and Text**|Haifeng Ni et.al.|[2501.16757](http://arxiv.org/abs/2501.16757)|null|\n", "2501.15891": "|**2025-03-26**|**Any2AnyTryon: Leveraging Adaptive Position Embeddings for Versatile Virtual Clothing Tasks**|Hailong Guo et.al.|[2501.15891](http://arxiv.org/abs/2501.15891)|null|\n", "2501.15616": "|**2025-01-26**|**IPVTON: Image-based 3D Virtual Try-on with Image Prompt Adapter**|Xiaojing Zhong et.al.|[2501.15616](http://arxiv.org/abs/2501.15616)|null|\n", "2501.15571": "|**2025-01-26**|**Cross-Cultural Fashion Design via Interactive Large Language Models and Diffusion Models**|Spencer Ramsey et.al.|[2501.15571](http://arxiv.org/abs/2501.15571)|null|\n", "2501.11776": "|**2025-01-20**|**EfficientVITON: An Efficient Virtual Try-On Model using Optimized Diffusion Process**|Mostafa Atef et.al.|[2501.11776](http://arxiv.org/abs/2501.11776)|null|\n", "2501.11325": "|**2025-01-20**|**CatV2TON: Taming Diffusion Transformers for Vision-Based Virtual Try-On with Temporal Concatenation**|Zheng Chong et.al.|[2501.11325](http://arxiv.org/abs/2501.11325)|**[link](https://github.com/zheng-chong/catv2ton)**|\n", "2501.10212": "|**2025-01-17**|**Disharmony: Forensics using Reverse Lighting Harmonization**|Philip Wootaek Shin et.al.|[2501.10212](http://arxiv.org/abs/2501.10212)|null|\n", "2501.08682": "|**2025-03-11**|**RealVVT: Towards Photorealistic Video Virtual Try-on via Spatio-Temporal Consistency**|Siqi Li et.al.|[2501.08682](http://arxiv.org/abs/2501.08682)|null|\n", "2501.06769": "|**2025-01-12**|**ODPG: Outfitting Diffusion with Pose Guided Condition**|Seohyun Lee et.al.|[2501.06769](http://arxiv.org/abs/2501.06769)|null|\n", "2501.05369": "|**2025-01-09**|**1-2-1: Renaissance of Single-Network Paradigm for Virtual Try-On**|Shuliang Ning et.al.|[2501.05369](http://arxiv.org/abs/2501.05369)|null|\n", "2501.04666": "|**2025-01-08**|**Enhancing Virtual Try-On with Synthetic Pairs and Error-Aware Noise Scheduling**|Nannan Li et.al.|[2501.04666](http://arxiv.org/abs/2501.04666)|null|\n", "2501.03910": "|**2025-01-07**|**HYB-VITON: A Hybrid Approach to Virtual Try-On Combining Explicit and Implicit Warping**|Kosuke Takemoto et.al.|[2501.03910](http://arxiv.org/abs/2501.03910)|null|\n", "2501.03630": "|**2025-01-10**|**MC-VTON: Minimal Control Virtual Try-On Diffusion Transformer**|Junsheng Luan et.al.|[2501.03630](http://arxiv.org/abs/2501.03630)|null|\n", "2501.01427": "|**2025-01-07**|**VideoAnydoor: High-fidelity Video Object Insertion with Precise Motion Control**|Yuanpeng Tu et.al.|[2501.01427](http://arxiv.org/abs/2501.01427)|null|\n", "2412.18797": "|**2024-12-25**|**DRDM: A Disentangled Representations Diffusion Model for Synthesizing Realistic Person Images**|Enbo Huang et.al.|[2412.18797](http://arxiv.org/abs/2412.18797)|null|\n", "2412.16978": "|**2024-12-22**|**PromptDresser: Improving the Quality and Controllability of Virtual Try-On via Generative Textual Prompt and Prompt-aware Mask**|Jeongho Kim et.al.|[2412.16978](http://arxiv.org/abs/2412.16978)|**[link](https://github.com/rlawjdghek/promptdresser)**|\n", "2412.14465": "|**2024-12-19**|**DiffusionTrend: A Minimalist Approach to Virtual Fashion Try-On**|Wengyi Zhan et.al.|[2412.14465](http://arxiv.org/abs/2412.14465)|null|\n", "2412.14168": "|**2024-12-19**|**FashionComposer: Compositional Fashion Image Generation**|Sihui Ji et.al.|[2412.14168](http://arxiv.org/abs/2412.14168)|null|\n", "2502.14373": "|**2025-02-20**|**CrossVTON: Mimicking the Logic Reasoning on Cross-category Virtual Try-on guided by Tri-zone Priors**|Donghao Luo et.al.|[2502.14373](http://arxiv.org/abs/2502.14373)|null|\n", "2503.08650": "|**2025-03-11**|**MF-VITON: High-Fidelity Mask-Free Virtual Try-On with Minimal Input**|Zhenchen Wan et.al.|[2503.08650](http://arxiv.org/abs/2503.08650)|null|\n", "2503.12588": "|**2025-03-16**|**Progressive Limb-Aware Virtual Try-On**|Xiaoyu Han et.al.|[2503.12588](http://arxiv.org/abs/2503.12588)|null|\n", "2503.12165": "|**2025-03-15**|**VTON 360: High-Fidelity Virtual Try-On from Any Viewing Direction**|Zijian He et.al.|[2503.12165](http://arxiv.org/abs/2503.12165)|null|\n", "2503.14151": "|**2025-03-18**|**Concat-ID: Towards Universal Identity-Preserving Video Synthesis**|Yong Zhong et.al.|[2503.14151](http://arxiv.org/abs/2503.14151)|null|\n", "2503.14074": "|**2025-03-18**|**Limb-Aware Virtual Try-On Network with Progressive Clothing Warping**|Shengping Zhang et.al.|[2503.14074](http://arxiv.org/abs/2503.14074)|**[link](https://github.com/aipixel/pl-vtonv2)**|\n", "2503.16065": "|**2025-03-20**|**Shining Yourself: High-Fidelity Ornaments Virtual Try-on with Diffusion Model**|Yingmao Miao et.al.|[2503.16065](http://arxiv.org/abs/2503.16065)|null|\n", "2503.19486": "|**2025-03-25**|**Exploring Disentangled and Controllable Human Image Synthesis: From End-to-End to Stage-by-Stage**|Zhengwentai Sun et.al.|[2503.19486](http://arxiv.org/abs/2503.19486)|null|\n", "2503.20418": "|**2025-03-26**|**ITA-MDT: Image-Timestep-Adaptive Masked Diffusion Transformer Framework for Image-Based Virtual Try-On**|Ji Woo Hong et.al.|[2503.20418](http://arxiv.org/abs/2503.20418)|null|\n"}, "Visual Edit": {"2502.11158": "|**2025-02-18**|**AnyRefill: A Unified, Data-Efficient Framework for Left-Prompt-Guided Vision Tasks**|Ming Xie et.al.|[2502.11158](http://arxiv.org/abs/2502.11158)|null|\n", "2502.10258": "|**2025-02-14**|**PromptArtisan: Multi-instruction Image Editing in Single Pass with Complete Attention Control**|Kunal Swami et.al.|[2502.10258](http://arxiv.org/abs/2502.10258)|null|\n", "2502.10190": "|**2025-02-14**|**VideoDiff: Human-AI Video Co-Creation with Alternatives**|Mina Huh et.al.|[2502.10190](http://arxiv.org/abs/2502.10190)|null|\n", "2502.10064": "|**2025-02-14**|**Hands-off Image Editing: Language-guided Editing without any Task-specific Labeling, Masking or even Training**|Rodrigo Santos et.al.|[2502.10064](http://arxiv.org/abs/2502.10064)|null|\n", "2502.08621": "|**2025-02-14**|**SportsBuddy: Designing and Evaluating an AI-Powered Sports Video Storytelling Tool Through Real-World Deployment**|Tica Lin et.al.|[2502.08621](http://arxiv.org/abs/2502.08621)|null|\n", "2502.06734": "|**2025-02-10**|**Se\u00f1orita-2M: A High-Quality Instruction-based Dataset for General Video Editing by Video Specialists**|Bojia Zi et.al.|[2502.06734](http://arxiv.org/abs/2502.06734)|null|\n", "2502.06575": "|**2025-02-10**|**Predictive Red Teaming: Breaking Policies Without Breaking Robots**|Anirudha Majumdar et.al.|[2502.06575](http://arxiv.org/abs/2502.06575)|null|\n", "2502.05433": "|**2025-02-08**|**AdaFlow: Efficient Long Video Editing via Adaptive Attention Slimming And Keyframe Selection**|Shuheng Zhang et.al.|[2502.05433](http://arxiv.org/abs/2502.05433)|null|\n", "2502.04299": "|**2025-02-06**|**MotionCanvas: Cinematic Shot Design with Controllable Image-to-Video Generation**|Jinbo Xing et.al.|[2502.04299](http://arxiv.org/abs/2502.04299)|null|\n", "2502.04050": "|**2025-02-06**|**PartEdit: Fine-Grained Image Editing using Pre-Trained Diffusion Models**|Aleksandar Cvejic et.al.|[2502.04050](http://arxiv.org/abs/2502.04050)|null|\n", "2502.03726": "|**2025-02-06**|**DICE: Distilling Classifier-Free Guidance into Text Embeddings**|Zhenyu Zhou et.al.|[2502.03726](http://arxiv.org/abs/2502.03726)|null|\n", "2502.03629": "|**2025-02-05**|**REALEDIT: Reddit Edits As a Large-scale Empirical Dataset for Image Transformations**|Peter Sushko et.al.|[2502.03629](http://arxiv.org/abs/2502.03629)|null|\n", "2502.04364": "|**2025-02-05**|**Lost in Edits? A $\u03bb$-Compass for AIGC Provenance**|Wenhao You et.al.|[2502.04364](http://arxiv.org/abs/2502.04364)|null|\n", "2502.02225": "|**2025-02-04**|**Exploring the latent space of diffusion models directly through singular value decomposition**|Li Wang et.al.|[2502.02225](http://arxiv.org/abs/2502.02225)|null|\n", "2502.02172": "|**2025-02-04**|**EditIQ: Automated Cinematic Editing of Static Wide-Angle Videos via Dialogue Interpretation and Saliency Cues**|Rohit Girmaji et.al.|[2502.02172](http://arxiv.org/abs/2502.02172)|null|\n", "2502.02091": "|**2025-02-04**|**Efficient Dynamic Scene Editing via 4D Gaussian-based Static-Dynamic Separation**|JooHyun Kwon et.al.|[2502.02091](http://arxiv.org/abs/2502.02091)|null|\n", "2501.18590": "|**2025-01-30**|**DiffusionRenderer: Neural Inverse and Forward Rendering with Video Diffusion Models**|Ruofan Liang et.al.|[2501.18590](http://arxiv.org/abs/2501.18590)|null|\n", "2501.14945": "|**2025-01-24**|**MATCHA:Towards Matching Anything**|Fei Xue et.al.|[2501.14945](http://arxiv.org/abs/2501.14945)|null|\n", "2501.14524": "|**2025-01-24**|**Training-Free Style and Content Transfer by Leveraging U-Net Skip Connections in Stable Diffusion 2.***|Ludovica Schaerf et.al.|[2501.14524](http://arxiv.org/abs/2501.14524)|null|\n", "2501.13920": "|**2025-01-23**|**IMAGINE-E: Image Generation Intelligence Evaluation of State-of-the-art Text-to-Image Models**|Jiayi Lei et.al.|[2501.13920](http://arxiv.org/abs/2501.13920)|null|\n", "2502.14397": "|**2025-02-23**|**PhotoDoodle: Learning Artistic Image Editing from Few-Shot Pairwise Data**|Shijie Huang et.al.|[2502.14397](http://arxiv.org/abs/2502.14397)|**[link](https://github.com/showlab/PhotoDoodle)**|\n", "2502.17363": "|**2025-02-25**|**KV-Edit: Training-Free Image Editing for Precise Background Preservation**|Tianrui Zhu et.al.|[2502.17363](http://arxiv.org/abs/2502.17363)|**[link](https://github.com/Xilluill/KV-Edit)**|\n", "2502.17258": "|**2025-02-24**|**VideoGrain: Modulating Space-Time Attention for Multi-grained Video Editing**|Xiangpeng Yang et.al.|[2502.17258](http://arxiv.org/abs/2502.17258)|null|\n", "2502.16302": "|**2025-02-22**|**DualNeRF: Text-Driven 3D Scene Editing via Dual-Field Representation**|Yuxuan Xiong et.al.|[2502.16302](http://arxiv.org/abs/2502.16302)|null|\n", "2502.18116": "|**2025-02-26**|**Bayesian Optimization for Controlled Image Editing via LLMs**|Chengkun Cai et.al.|[2502.18116](http://arxiv.org/abs/2502.18116)|null|\n", "2502.20376": "|**2025-02-27**|**Tight Inversion: Image-Conditioned Inversion for Real Image Editing**|Edo Kadosh et.al.|[2502.20376](http://arxiv.org/abs/2502.20376)|null|\n", "2502.19930": "|**2025-02-27**|**Identity-preserving Distillation Sampling by Fixed-Point Iterator**|SeonHwa Kim et.al.|[2502.19930](http://arxiv.org/abs/2502.19930)|null|\n", "2502.19453": "|**2025-02-26**|**SVGEditBench V2: A Benchmark for Instruction-based SVG Editing**|Kunato Nishina et.al.|[2502.19453](http://arxiv.org/abs/2502.19453)|**[link](https://github.com/mti-lab/svgeditbenchv2)**|\n", "2503.02187": "|**2025-03-04**|**h-Edit: Effective and Flexible Diffusion-Based Editing via Doob's h-Transform**|Toan Nguyen et.al.|[2503.02187](http://arxiv.org/abs/2503.02187)|**[link](https://github.com/nktoan/h-edit)**|\n", "2503.01107": "|**2025-03-03**|**VideoHandles: Editing 3D Object Compositions in Videos Using Video Generative Priors**|Juil Koo et.al.|[2503.01107](http://arxiv.org/abs/2503.01107)|null|\n", "2503.00605": "|**2025-03-01**|**GenVDM: Generating Vector Displacement Maps From a Single Image**|Yuezhi Yang et.al.|[2503.00605](http://arxiv.org/abs/2503.00605)|null|\n", "2503.04215": "|**2025-03-06**|**Energy-Guided Optimization for Personalized Image Editing with Pretrained Text-to-Image Diffusion Models**|Rui Jiang et.al.|[2503.04215](http://arxiv.org/abs/2503.04215)|null|\n", "2503.03944": "|**2025-03-05**|**GuardDoor: Safeguarding Against Malicious Diffusion Editing via Protective Backdoors**|Yaopei Zeng et.al.|[2503.03944](http://arxiv.org/abs/2503.03944)|null|\n", "2503.05639": "|**2025-03-10**|**VideoPainter: Any-length Video Inpainting and Editing with Plug-and-Play Context Control**|Yuxuan Bian et.al.|[2503.05639](http://arxiv.org/abs/2503.05639)|**[link](https://github.com/TencentARC/VideoPainter)**|\n", "2503.05424": "|**2025-03-07**|**Towards Locally Explaining Prediction Behavior via Gradual Interventions and Measuring Property Gradients**|Niklas Penzel et.al.|[2503.05424](http://arxiv.org/abs/2503.05424)|null|\n", "2503.07050": "|**2025-03-10**|**TIDE : Temporal-Aware Sparse Autoencoders for Interpretable Diffusion Transformers in Image Generation**|Victor Shea-Jay Huang et.al.|[2503.07050](http://arxiv.org/abs/2503.07050)|null|\n", "2503.06809": "|**2025-03-10**|**Interactive Tumor Progression Modeling via Sketch-Based Image Editing**|Gexin Huang et.al.|[2503.06809](http://arxiv.org/abs/2503.06809)|null|\n", "2503.06419": "|**2025-03-09**|**Consistent Image Layout Editing with Diffusion Models**|Tao Xia et.al.|[2503.06419](http://arxiv.org/abs/2503.06419)|null|\n", "2503.06268": "|**2025-03-08**|**Get In Video: Add Anything You Want to the Video**|Shaobin Zhuang et.al.|[2503.06268](http://arxiv.org/abs/2503.06268)|null|\n", "2503.06134": "|**2025-03-08**|**X2I: Seamless Integration of Multimodal Understanding into Diffusion Transformer via Attention Distillation**|Jian Ma et.al.|[2503.06134](http://arxiv.org/abs/2503.06134)|**[link](https://github.com/oppo-mente-lab/x2i)**|\n", "2503.08677": "|**2025-03-12**|**OmniPaint: Mastering Object-Oriented Editing via Disentangled Insertion-Removal Inpainting**|Yongsheng Yu et.al.|[2503.08677](http://arxiv.org/abs/2503.08677)|null|\n", "2503.08434": "|**2025-03-13**|**Bokeh Diffusion: Defocus Blur Control in Text-to-Image Diffusion Models**|Armando Fortes et.al.|[2503.08434](http://arxiv.org/abs/2503.08434)|null|\n", "2503.08250": "|**2025-03-11**|**Aligning Text to Image in Diffusion Models is Easier Than You Think**|Jaa-Yeon Lee et.al.|[2503.08250](http://arxiv.org/abs/2503.08250)|null|\n", "2503.08037": "|**2025-03-11**|**ObjectMover: Generative Object Movement with Video Prior**|Xin Yu et.al.|[2503.08037](http://arxiv.org/abs/2503.08037)|null|\n", "2503.07938": "|**2025-03-11**|**CAD-VAE: Leveraging Correlation-Aware Latents for Comprehensive Fair Disentanglement**|Chenrui Ma et.al.|[2503.07938](http://arxiv.org/abs/2503.07938)|null|\n", "2503.07703": "|**2025-03-10**|**Seedream 2.0: A Native Chinese-English Bilingual Image Generation Foundation Model**|Lixue Gong et.al.|[2503.07703](http://arxiv.org/abs/2503.07703)|null|\n", "2503.07598": "|**2025-03-11**|**VACE: All-in-One Video Creation and Editing**|Zeyinzi Jiang et.al.|[2503.07598](http://arxiv.org/abs/2503.07598)|null|\n", "2503.09419": "|**2025-03-12**|**Alias-Free Latent Diffusion Models:Improving Fractional Shift Equivariance of Diffusion Latent Space**|Yifan Zhou et.al.|[2503.09419](http://arxiv.org/abs/2503.09419)|**[link](https://github.com/singlezombie/afldm)**|\n", "2503.09130": "|**2025-03-12**|**InteractEdit: Zero-Shot Editing of Human-Object Interactions in Images**|Jiun Tian Hoe et.al.|[2503.09130](http://arxiv.org/abs/2503.09130)|null|\n", "2503.10634": "|**2025-03-14**|**V2Edit: Versatile Video Diffusion Editor for Videos and 3D Scenes**|Yanming Zhang et.al.|[2503.10634](http://arxiv.org/abs/2503.10634)|null|\n", "2503.10613": "|**2025-03-13**|**CoSTA$\\ast$: Cost-Sensitive Toolpath Agent for Multi-turn Image Editing**|Advait Gupta et.al.|[2503.10613](http://arxiv.org/abs/2503.10613)|**[link](https://github.com/tianyi-lab/CoSTAR)**|\n", "2503.10270": "|**2025-03-13**|**EEdit : Rethinking the Spatial and Temporal Redundancy for Efficient Image Editing**|Zexuan Yan et.al.|[2503.10270](http://arxiv.org/abs/2503.10270)|**[link](https://github.com/yuriyanzexuan/eedit)**|\n", "2503.10112": "|**2025-03-13**|**MoEdit: On Learning Quantity Perception for Multi-object Image Editing**|Yanfeng Li et.al.|[2503.10112](http://arxiv.org/abs/2503.10112)|**[link](https://github.com/tear-kitty/moedit)**|\n", "2503.09837": "|**2025-03-14**|**On the Limitations of Vision-Language Models in Understanding Image Transforms**|Ahmad Mustafa Anis et.al.|[2503.09837](http://arxiv.org/abs/2503.09837)|null|\n", "2503.11571": "|**2025-03-14**|**RASA: Replace Anyone, Say Anything -- A Training-Free Framework for Audio-Driven and Universal Portrait Video Editing**|Tianrui Pan et.al.|[2503.11571](http://arxiv.org/abs/2503.11571)|null|\n", "2503.11054": "|**2025-03-14**|**LUSD: Localized Update Score Distillation for Text-Guided Image Editing**|Worameth Chinchuthakun et.al.|[2503.11054](http://arxiv.org/abs/2503.11054)|**[link](https://github.com/sincostanx/lusd)**|\n", "2503.13436": "|**2025-03-17**|**Unified Autoregressive Visual Generation and Understanding with Continuous Tokens**|Lijie Fan et.al.|[2503.13436](http://arxiv.org/abs/2503.13436)|null|\n", "2503.13327": "|**2025-03-17**|**Edit Transfer: Learning Image Editing via Vision In-Context Relations**|Lan Chen et.al.|[2503.13327](http://arxiv.org/abs/2503.13327)|null|\n", "2503.12944": "|**2025-03-17**|**GIFT: Generated Indoor video frames for Texture-less point tracking**|Jianzheng Huang et.al.|[2503.12944](http://arxiv.org/abs/2503.12944)|null|\n", "2503.12838": "|**2025-03-17**|**DreamLayer: Simultaneous Multi-Layer Generation via Diffusion Mode**|Junjia Huang et.al.|[2503.12838](http://arxiv.org/abs/2503.12838)|null|\n", "2503.12652": "|**2025-03-16**|**UniVG: A Generalist Diffusion Model for Unified Image Generation and Editing**|Tsu-Jui Fu et.al.|[2503.12652](http://arxiv.org/abs/2503.12652)|null|\n", "2503.12590": "|**2025-03-16**|**Personalize Anything for Free with Diffusion Transformer**|Haoran Feng et.al.|[2503.12590](http://arxiv.org/abs/2503.12590)|null|\n", "2503.11905": "|**2025-03-14**|**Upcycling Text-to-Image Diffusion Models for Multi-Task Capabilities**|Ruchika Chavhan et.al.|[2503.11905](http://arxiv.org/abs/2503.11905)|null|\n", "2503.11720": "|**2025-03-13**|**Fine-Tuning Diffusion Generative Models via Rich Preference Optimization**|Hanyang Zhao et.al.|[2503.11720](http://arxiv.org/abs/2503.11720)|null|\n", "2503.14482": "|**2025-03-18**|**ICE-Bench: A Unified and Comprehensive Benchmark for Image Creating and Editing**|Yulin Pan et.al.|[2503.14482](http://arxiv.org/abs/2503.14482)|null|\n", "2503.14350": "|**2025-03-19**|**VEGGIE: Instructional Editing and Reasoning of Video Concepts with Grounded Generation**|Shoubin Yu et.al.|[2503.14350](http://arxiv.org/abs/2503.14350)|null|\n", "2503.13994": "|**2025-03-18**|**TarPro: Targeted Protection against Malicious Image Editing**|Kaixin Shen et.al.|[2503.13994](http://arxiv.org/abs/2503.13994)|null|\n", "2503.13684": "|**2025-03-17**|**FiVE: A Fine-grained Video Editing Benchmark for Evaluating Emerging Diffusion and Rectified Flow Models**|Minghan Li et.al.|[2503.13684](http://arxiv.org/abs/2503.13684)|null|\n", "2503.16153": "|**2025-03-20**|**FreeFlux: Understanding and Exploiting Layer-Specific Roles in RoPE-Based MMDiT for Versatile Image Editing**|Tianyi Wei et.al.|[2503.16153](http://arxiv.org/abs/2503.16153)|null|\n", "2503.16025": "|**2025-03-20**|**Single Image Iterative Subject-driven Generation and Editing**|Yair Shpitzer et.al.|[2503.16025](http://arxiv.org/abs/2503.16025)|**[link](https://github.com/yairshp/SISO)**|\n", "2503.15686": "|**2025-03-23**|**Multi-focal Conditioned Latent Diffusion for Person Image Synthesis**|Jiaqi Liu et.al.|[2503.15686](http://arxiv.org/abs/2503.15686)|**[link](https://github.com/jqliu09/mcld)**|\n", "2503.17276": "|**2025-03-21**|**HyperNVD: Accelerating Neural Video Decomposition via Hypernetworks**|Maria Pilligua et.al.|[2503.17276](http://arxiv.org/abs/2503.17276)|null|\n", "2503.16795": "|**2025-03-21**|**DCEdit: Dual-Level Controlled Image Editing via Precisely Localized Semantics**|Yihan Hu et.al.|[2503.16795](http://arxiv.org/abs/2503.16795)|null|\n", "2503.18406": "|**2025-03-25**|**Instruct-CLIP: Improving Instruction-Guided Image Editing with Automated Data Refinement Using Contrastive Learning**|Sherry X. Chen et.al.|[2503.18406](http://arxiv.org/abs/2503.18406)|**[link](https://github.com/sherryxtchen/instruct-clip)**|\n", "2503.18386": "|**2025-03-24**|**Resource-Efficient Motion Control for Video Generation via Dynamic Mask Guidance**|Sicong Feng et.al.|[2503.18386](http://arxiv.org/abs/2503.18386)|null|\n", "2503.18364": "|**2025-03-24**|**MaSS13K: A Matting-level Semantic Segmentation Benchmark**|Chenxi Xie et.al.|[2503.18364](http://arxiv.org/abs/2503.18364)|**[link](https://github.com/xiechenxi99/mass13k)**|\n", "2503.18238": "|**2025-03-23**|**Collaborating with AI Agents: Field Experiments on Teamwork, Productivity, and Performance**|Harang Ju et.al.|[2503.18238](http://arxiv.org/abs/2503.18238)|null|\n", "2503.17975": "|**2025-03-25**|**Shot Sequence Ordering for Video Editing: Benchmarks, Metrics, and Cinematology-Inspired Computing Methods**|Yuzhi Li et.al.|[2503.17975](http://arxiv.org/abs/2503.17975)|null|\n", "2503.17899": "|**2025-03-23**|**What Time Tells Us? An Explorative Study of Time Awareness Learned from Static Images**|Dongheng Lin et.al.|[2503.17899](http://arxiv.org/abs/2503.17899)|null|\n", "2503.17641": "|**2025-03-22**|**InstructVEdit: A Holistic Approach for Instructional Video Editing**|Chi Zhang et.al.|[2503.17641](http://arxiv.org/abs/2503.17641)|null|\n", "2503.17593": "|**2025-03-22**|**Guidance Free Image Editing via Explicit Conditioning**|Mehdi Noroozi et.al.|[2503.17593](http://arxiv.org/abs/2503.17593)|null|\n", "2503.19839": "|**2025-03-25**|**FireEdit: Fine-grained Instruction-based Image Editing via Region-aware Vision Language Model**|Jun Zhou et.al.|[2503.19839](http://arxiv.org/abs/2503.19839)|null|\n", "2503.19191": "|**2025-03-24**|**FDS: Frequency-Aware Denoising Score for Text-Guided Latent Diffusion Image Editing**|Yufan Ren et.al.|[2503.19191](http://arxiv.org/abs/2503.19191)|null|\n", "2503.20782": "|**2025-03-26**|**Zero-Shot Audio-Visual Editing via Cross-Modal Delta Denoising**|Yan-Bo Lin et.al.|[2503.20782](http://arxiv.org/abs/2503.20782)|null|\n", "2503.20318": "|**2025-03-26**|**EditCLIP: Representation Learning for Image Editing**|Qian Wang et.al.|[2503.20318](http://arxiv.org/abs/2503.20318)|**[link](https://github.com/qianwangx/editclip)**|\n", "2503.20314": "|**2025-03-26**|**Wan: Open and Advanced Large-Scale Video Generative Models**|WanTeam et.al.|[2503.20314](http://arxiv.org/abs/2503.20314)|**[link](https://github.com/wan-video/wan2.1)**|\n", "2503.20287": "|**2025-03-26**|**InsViE-1M: Effective Instruction-based Video Editing with Elaborate Dataset Construction**|Yuhui Wu et.al.|[2503.20287](http://arxiv.org/abs/2503.20287)|**[link](https://github.com/langmanbusi/insvie)**|\n", "2503.21541": "|**2025-03-27**|**LOCATEdit: Graph Laplacian Optimized Cross Attention for Localized Text-Guided Image Editing**|Achint Soni et.al.|[2503.21541](http://arxiv.org/abs/2503.21541)|**[link](https://github.com/locatedit/locatedit)**|\n"}, "Others": {"2502.13134": "|**2025-02-18**|**RHINO: Learning Real-Time Humanoid-Human-Object Interaction from Human Demonstrations**|Jingxiao Chen et.al.|[2502.13134](http://arxiv.org/abs/2502.13134)|null|\n", "2502.13133": "|**2025-02-18**|**AV-Flow: Transforming Text to Audio-Visual Human-like Interactions**|Aggelina Chatziagapi et.al.|[2502.13133](http://arxiv.org/abs/2502.13133)|null|\n", "2502.13105": "|**2025-02-18**|**Enhanced uncertainty quantification variational autoencoders for the solution of Bayesian inverse problems**|Andrea Tonini et.al.|[2502.13105](http://arxiv.org/abs/2502.13105)|null|\n", "2502.13070": "|**2025-02-18**|**Real-time interpretation of neutron vibrational spectra with symmetry-equivariant Hessian matrix prediction**|Bowen Han et.al.|[2502.13070](http://arxiv.org/abs/2502.13070)|null|\n", "2502.13027": "|**2025-02-18**|**A deep learning framework for efficient pathology image analysis**|Peter Neidlinger et.al.|[2502.13027](http://arxiv.org/abs/2502.13027)|null|\n", "2502.12975": "|**2025-02-18**|**Instance-Level Moving Object Segmentation from a Single Image with Events**|Zhexiong Wan et.al.|[2502.12975](http://arxiv.org/abs/2502.12975)|null|\n", "2502.12961": "|**2025-02-18**|**Adaptive Tool Use in Large Language Models with Meta-Cognition Trigger**|Wenjun Li et.al.|[2502.12961](http://arxiv.org/abs/2502.12961)|null|\n", "2502.12935": "|**2025-02-18**|**Neuro-oscillatory models of cortical speech processing**|Olesia Dogonasheva et.al.|[2502.12935](http://arxiv.org/abs/2502.12935)|null|\n", "2502.12925": "|**2025-02-18**|**Keep what you need : extracting efficient subnetworks from large audio representation models**|David Genova et.al.|[2502.12925](http://arxiv.org/abs/2502.12925)|**[link](https://github.com/gnvircam/audio-representation-trimming)**|\n", "2502.12890": "|**2025-02-18**|**Testing and Combining Transient Spectral Classification Tools on 4MOST-like Blended Spectra**|Andrew Milligan et.al.|[2502.12890](http://arxiv.org/abs/2502.12890)|null|\n", "2502.12834": "|**2025-02-18**|**NTP-INT: Network Traffic Prediction-Driven In-band Network Telemetry for High-load Switches**|Penghui Zhang et.al.|[2502.12834](http://arxiv.org/abs/2502.12834)|null|\n", "2502.12817": "|**2025-02-19**|**An Attention-Assisted AI Model for Real-Time Underwater Sound Speed Estimation Leveraging Remote Sensing Sea Surface Temperature Data**|Pengfei Wu et.al.|[2502.12817](http://arxiv.org/abs/2502.12817)|null|\n", "2502.12785": "|**2025-02-18**|**An Adaptive Model Order Reduction Approach for the Finite Element Method in Time Domain in Electromagnetics**|Ruth Medeiros et.al.|[2502.12785](http://arxiv.org/abs/2502.12785)|null|\n", "2502.12755": "|**2025-02-18**|**Efficient Machine Translation Corpus Generation: Integrating Human-in-the-Loop Post-Editing with Large Language Models**|Kamer Ali Yuksel et.al.|[2502.12755](http://arxiv.org/abs/2502.12755)|**[link](https://github.com/aixplain/Efficient-MT)**|\n", "2502.12745": "|**2025-02-18**|**MediaMind: Revolutionizing Media Monitoring using Agentification**|Ahmet Gunduz et.al.|[2502.12745](http://arxiv.org/abs/2502.12745)|null|\n", "2502.12716": "|**2025-02-18**|**Soft Arm-Motor Thrust Characterization for a Pneumatically Actuated Soft Morphing Quadrotor**|Vidya Sumathy et.al.|[2502.12716](http://arxiv.org/abs/2502.12716)|null|\n", "2502.12655": "|**2025-02-18**|**LiMo-Calib: On-Site Fast LiDAR-Motor Calibration for Quadruped Robot-Based Panoramic 3D Sensing System**|Jianping Li et.al.|[2502.12655](http://arxiv.org/abs/2502.12655)|**[link](https://github.com/kafeiyin00/limo-calib)**|\n", "2502.12617": "|**2025-02-18**|**A Graph-Enhanced Deep-Reinforcement Learning Framework for the Aircraft Landing Problem**|Vatsal Maru et.al.|[2502.12617](http://arxiv.org/abs/2502.12617)|null|\n", "2502.12571": "|**2025-02-18**|**A Novel Gain Modeling Technique for LLC Resonant Converters based on The Hybrid Deep-Learning/GMDH Neural Network**|Parham Mohammadi et.al.|[2502.12571](http://arxiv.org/abs/2502.12571)|null|\n", "2502.12526": "|**2025-02-18**|**AnimAlte:Designing AI-Infused Cartoon Videos to Improve Preschoolers' Language Learning with Family Engagement at Home**|Shiya Tsang et.al.|[2502.12526](http://arxiv.org/abs/2502.12526)|null|\n", "2502.13945": "|**2025-02-19**|**GPU-Friendly Laplacian Texture Blending**|Bartlomiej Wronski et.al.|[2502.13945](http://arxiv.org/abs/2502.13945)|null|\n", "2502.13891": "|**2025-02-19**|**Highly Dynamic and Flexible Spatio-Temporal Spectrum Management with AI-Driven O-RAN: A Multi-Granularity Marketplace Framework**|Mehdi Rasti et.al.|[2502.13891](http://arxiv.org/abs/2502.13891)|null|\n", "2502.13879": "|**2025-02-19**|**A measurement-based approach to analyze the power consumption of the softwarized 5G core**|Arturo Bellin et.al.|[2502.13879](http://arxiv.org/abs/2502.13879)|null|\n", "2502.13823": "|**2025-02-19**|**An Online Optimization-Based Trajectory Planning Approach for Cooperative Landing Tasks**|Jingshan Chen et.al.|[2502.13823](http://arxiv.org/abs/2502.13823)|null|\n", "2502.13808": "|**2025-02-19**|**MGFI-Net: A Multi-Grained Feature Integration Network for Enhanced Medical Image Segmentation**|Yucheng Zeng et.al.|[2502.13808](http://arxiv.org/abs/2502.13808)|null|\n", "2502.13789": "|**2025-02-19**|**From Correctness to Comprehension: AI Agents for Personalized Error Diagnosis in Education**|Yi-Fan Zhang et.al.|[2502.13789](http://arxiv.org/abs/2502.13789)|null|\n", "2502.13764": "|**2025-02-19**|**An Overall Real-Time Mechanism for Classification and Quality Evaluation of Rice**|Wanke Xia et.al.|[2502.13764](http://arxiv.org/abs/2502.13764)|null|\n", "2502.13746": "|**2025-02-19**|**A Digital Urban Twin Enabling Interactive Pollution Predictions and Enhanced Planning**|Dennis Teutscher et.al.|[2502.13746](http://arxiv.org/abs/2502.13746)|null|\n", "2502.13719": "|**2025-02-19**|**TrustRAG: An Information Assistant with Retrieval Augmented Generation**|Yixing Fan et.al.|[2502.13719](http://arxiv.org/abs/2502.13719)|**[link](https://github.com/gomate-community/trustrag)**|\n", "2502.13705": "|**2025-02-19**|**Millimeter-Wave ISAC Testbed Using Programmable Digital Coding Dynamic Metasurface Antenna: Practical Design and Implementation**|Abdul Jabbar et.al.|[2502.13705](http://arxiv.org/abs/2502.13705)|null|\n", "2502.13664": "|**2025-02-19**|**DNA Sensing with Whispering Gallery Mode Microlasers**|Soraya Caixeiro et.al.|[2502.13664](http://arxiv.org/abs/2502.13664)|null|\n", "2502.13472": "|**2025-02-19**|**FlexDuo: A Pluggable System for Enabling Full-Duplex Capabilities in Speech Dialogue Systems**|Borui Liao et.al.|[2502.13472](http://arxiv.org/abs/2502.13472)|null|\n", "2502.13435": "|**2025-02-19**|**Radio observations of the ultra-long GRB 220627A reveal a hot cocoon supporting the blue supergiant progenitor scenario**|James K. Leung et.al.|[2502.13435](http://arxiv.org/abs/2502.13435)|null|\n", "2502.13421": "|**2025-02-19**|**Virtual Encounters of the Haptic Kind: Towards a Multi-User VR System for Real-Time Social Touch**|Premankur Banerjee et.al.|[2502.13421](http://arxiv.org/abs/2502.13421)|null|\n", "2502.13388": "|**2025-02-19**|**Reflection of Episodes: Learning to Play Game from Expert and Self Experiences**|Xiaojie Xu et.al.|[2502.13388](http://arxiv.org/abs/2502.13388)|null|\n", "2502.13352": "|**2025-02-19**|**Integrated Sensing and Communication for 6G Holographic Digital Twins**|Haijun Zhang et.al.|[2502.13352](http://arxiv.org/abs/2502.13352)|null|\n", "2502.13233": "|**2025-02-18**|**SearchRAG: Can Search Engines Be Helpful for LLM-based Medical Question Answering?**|Yucheng Shi et.al.|[2502.13233](http://arxiv.org/abs/2502.13233)|null|\n", "2502.14835": "|**2025-02-20**|**Adaptive Syndrome Extraction**|Noah Berthusen et.al.|[2502.14835](http://arxiv.org/abs/2502.14835)|null|\n", "2502.14785": "|**2025-02-20**|**Real-Time Device Reach Forecasting Using HLL and MinHash Data Sketches**|Chandrashekar Muniyappa et.al.|[2502.14785](http://arxiv.org/abs/2502.14785)|null|\n", "2502.14782": "|**2025-02-20**|**A Neural Operator-Based Emulator for Regional Shallow Water Dynamics**|Peter Rivera-Casillas et.al.|[2502.14782](http://arxiv.org/abs/2502.14782)|null|\n", "2502.14780": "|**2025-02-20**|**ReVision: A Dataset and Baseline VLM for Privacy-Preserving Task-Oriented Visual Instruction Rewriting**|Abhijit Mishra et.al.|[2502.14780](http://arxiv.org/abs/2502.14780)|null|\n", "2502.14740": "|**2025-02-20**|**YOLOv12: A Breakdown of the Key Architectural Features**|Mujadded Al Rabbani Alif et.al.|[2502.14740](http://arxiv.org/abs/2502.14740)|null|\n", "2502.14683": "|**2025-02-20**|**Machine learning assisted tracking of magnetic objects using quantum diamond magnetometry**|Fernando Meneses et.al.|[2502.14683](http://arxiv.org/abs/2502.14683)|null|\n", "2502.14632": "|**2025-02-20**|**Augmenting Coaching with GenAI: Insights into Use, Effectiveness, and Future Potential**|Jennifer Haase et.al.|[2502.14632](http://arxiv.org/abs/2502.14632)|null|\n", "2502.14618": "|**2025-02-20**|**Compact multi-channel analyzer for SiPM detectors with real time on-board signal analysis**|P. Ku\u010dera et.al.|[2502.14618](http://arxiv.org/abs/2502.14618)|null|\n", "2502.14599": "|**2025-02-20**|**Enhancing nuclear cross-section predictions with deep learning: the DINo algorithm**|Levana Gesson et.al.|[2502.14599](http://arxiv.org/abs/2502.14599)|null|\n", "2502.14571": "|**2025-02-20**|**Predicting Filter Medium Performances in Chamber Filter Presses with Digital Twins Using Neural Network Technologies**|Dennis Teutscher et.al.|[2502.14571](http://arxiv.org/abs/2502.14571)|null|\n", "2502.14469": "|**2025-02-20**|**Enhancing Smart Environments with Context-Aware Chatbots using Large Language Models**|Aurora Polo-Rodr\u00edguez et.al.|[2502.14469](http://arxiv.org/abs/2502.14469)|null|\n", "2502.14455": "|**2025-02-20**|**An Efficient Ground-aerial Transportation System for Pest Control Enabled by AI-based Autonomous Nano-UAVs**|Luca Crupi et.al.|[2502.14455](http://arxiv.org/abs/2502.14455)|null|\n", "2502.14418": "|**2025-02-20**|**Role of the Pretraining and the Adaptation data sizes for low-resource real-time MRI video segmentation**|Masoud Thajudeen Tholan et.al.|[2502.14418](http://arxiv.org/abs/2502.14418)|null|\n", "2502.14389": "|**2025-02-20**|**Leveraging Small LLMs for Argument Mining in Education: Argument Component Identification, Classification, and Assessment**|Lucile Favero et.al.|[2502.14389](http://arxiv.org/abs/2502.14389)|null|\n", "2502.14332": "|**2025-02-20**|**A Collaborative Jade Recognition System for Mobile Devices Based on Lightweight and Large Models**|Zhenyu Wang et.al.|[2502.14332](http://arxiv.org/abs/2502.14332)|null|\n", "2502.14320": "|**2025-02-20**|**It Takes Two to Tango: Serverless Workflow Serving via Bilaterally Engaged Resource Adaptation**|Jing Wu et.al.|[2502.14320](http://arxiv.org/abs/2502.14320)|null|\n", "2502.14314": "|**2025-02-20**|**ODVerse33: Is the New YOLO Version Always Better? A Multi Domain benchmark from YOLO v5 to v11**|Tianyou Jiang et.al.|[2502.14314](http://arxiv.org/abs/2502.14314)|null|\n", "2502.14307": "|**2025-02-20**|**\u03bcRL: Discovering Transient Execution Vulnerabilities Using Reinforcement Learning**|M. Caner Tol et.al.|[2502.14307](http://arxiv.org/abs/2502.14307)|null|\n", "2502.14291": "|**2025-02-20**|**A Note on Efficient Privacy-Preserving Similarity Search for Encrypted Vectors**|Dongfang Zhao et.al.|[2502.14291](http://arxiv.org/abs/2502.14291)|null|\n", "2502.14290": "|**2025-02-20**|**Road to 6G Digital Twin Networks: Multi-Task Adaptive Ray-Tracing as a Key Enabler**|Li Yu et.al.|[2502.14290](http://arxiv.org/abs/2502.14290)|null|\n", "2502.15641": "|**2025-02-21**|**A Deep Neural Network-based Frequency Predictor for Frequency-Constrained Optimal Power Flow**|Fan Jiang et.al.|[2502.15641](http://arxiv.org/abs/2502.15641)|null|\n", "2502.15630": "|**2025-02-21**|**Reduced-Order Model Guided Contact-Implicit Model Predictive Control for Humanoid Locomotion**|Sergio A. Esteban et.al.|[2502.15630](http://arxiv.org/abs/2502.15630)|null|\n", "2502.15594": "|**2025-02-21**|**SafeInt: Shielding Large Language Models from Jailbreak Attacks via Safety-Aware Representation Intervention**|Jiaqi Wu et.al.|[2502.15594](http://arxiv.org/abs/2502.15594)|null|\n", "2502.15583": "|**2025-02-21**|**Chats-Grid: An Iterative Retrieval Q&A Optimization Scheme Leveraging Large Model and Retrieval Enhancement Generation in smart grid**|Yunfeng Li et.al.|[2502.15583](http://arxiv.org/abs/2502.15583)|null|\n", "2502.15555": "|**2025-02-21**|**Forecasting and Analysis of Solar Energetic Particle Radiation Storms**|Olga Malandraki et.al.|[2502.15555](http://arxiv.org/abs/2502.15555)|null|\n", "2502.15545": "|**2025-02-21**|**Estimating Vehicle Speed on Roadways Using RNNs and Transformers: A Video-based Approach**|Sai Krishna Reddy Mareddy et.al.|[2502.15545](http://arxiv.org/abs/2502.15545)|null|\n", "2502.15544": "|**2025-02-21**|**Learning-based Model Predictive Control for Passenger-Oriented Train Rescheduling with Flexible Train Composition**|Xiaoyu Liu et.al.|[2502.15544](http://arxiv.org/abs/2502.15544)|null|\n", "2502.15472": "|**2025-02-21**|**Aligning Task- and Reconstruction-Oriented Communications for Edge Intelligence**|Yufeng Diao et.al.|[2502.15472](http://arxiv.org/abs/2502.15472)|null|\n", "2502.15422": "|**2025-02-21**|**Evaluating Multimodal Generative AI with Korean Educational Standards**|Sanghee Park et.al.|[2502.15422](http://arxiv.org/abs/2502.15422)|null|\n", "2502.15336": "|**2025-02-21**|**Exploring Embodied Multimodal Large Models: Development, Datasets, and Future Directions**|Shoubin Chen et.al.|[2502.15336](http://arxiv.org/abs/2502.15336)|null|\n", "2502.15307": "|**2025-02-21**|**Road Traffic Sign Recognition method using Siamese network Combining Efficient-CNN based Encoder**|Zhenghao Xi et.al.|[2502.15307](http://arxiv.org/abs/2502.15307)|null|\n", "2502.15306": "|**2025-02-21**|**A Data-Driven Real-Time Optimal Power Flow Algorithm Using Local Feedback**|Heng Liang et.al.|[2502.15306](http://arxiv.org/abs/2502.15306)|null|\n", "2502.15259": "|**2025-02-21**|**A deep learning-based noise correction method for light-field fluorescence microscopy**|Bohan Qu et.al.|[2502.15259](http://arxiv.org/abs/2502.15259)|null|\n", "2502.15252": "|**2025-02-21**|**Real-Time Moving Flock Detection in Pedestrian Trajectories Using Sequential Deep Learning Models**|Amartaivan Sanjjamts et.al.|[2502.15252](http://arxiv.org/abs/2502.15252)|null|\n", "2502.15162": "|**2025-02-21**|**Realm: Real-Time Line-of-Sight Maintenance in Multi-Robot Navigation with Unknown Obstacles**|Ruofei Bai et.al.|[2502.15162](http://arxiv.org/abs/2502.15162)|**[link](https://github.com/bairuofei/los_constrained_navigation)**|\n", "2502.15158": "|**2025-02-21**|**Improving Streaming Speech Recognition With Time-Shifted Contextual Attention And Dynamic Right Context Masking**|Khanh Le et.al.|[2502.15158](http://arxiv.org/abs/2502.15158)|null|\n", "2502.15098": "|**2025-02-20**|**MADEA: A Malware Detection Architecture for IoT blending Network Monitoring and Device Attestation**|Renascence Tarafder Prapty et.al.|[2502.15098](http://arxiv.org/abs/2502.15098)|null|\n", "2502.15068": "|**2025-02-20**|**ODS: A self-reporting system for radio telescopes to coexist with adaptive satellite constellations**|Bang D. Nhan et.al.|[2502.15068](http://arxiv.org/abs/2502.15068)|null|\n", "2502.15056": "|**2025-02-20**|**Fundamental Survey on Neuromorphic Based Audio Classification**|Amlan Basu et.al.|[2502.15056](http://arxiv.org/abs/2502.15056)|null|\n", "2502.15043": "|**2025-02-20**|**DDAT: Diffusion Policies Enforcing Dynamically Admissible Robot Trajectories**|Jean-Baptiste Bouvier et.al.|[2502.15043](http://arxiv.org/abs/2502.15043)|null|\n", "2502.17434": "|**2025-02-24**|**V-HOP: Visuo-Haptic 6D Object Pose Tracking**|Hongyu Li et.al.|[2502.17434](http://arxiv.org/abs/2502.17434)|null|\n", "2502.17419": "|**2025-02-24**|**From System 1 to System 2: A Survey of Reasoning Large Language Models**|Zhong-Zhi Li et.al.|[2502.17419](http://arxiv.org/abs/2502.17419)|**[link](https://github.com/zzli2022/awesome-slow-reason-system)**|\n", "2502.17397": "|**2025-02-24**|**Robust Confinement State Classification with Uncertainty Quantification through Ensembled Data-Driven Methods**|Yoeri Poels et.al.|[2502.17397](http://arxiv.org/abs/2502.17397)|null|\n", "2502.17386": "|**2025-02-24**|**Data efficiency and long-term prediction capabilities for neural operator surrogate models of edge plasma simulations**|N. Carey et.al.|[2502.17386](http://arxiv.org/abs/2502.17386)|null|\n", "2502.17350": "|**2025-02-24**|**Goal-Oriented Middleware Filtering at Transport Layer Based on Value of Updates**|Polina Kutsevol et.al.|[2502.17350](http://arxiv.org/abs/2502.17350)|null|\n", "2502.17346": "|**2025-02-24**|**User-Centric Evaluation Methods for Digital Twin Applications in Extended Reality**|Francesco Vona et.al.|[2502.17346](http://arxiv.org/abs/2502.17346)|null|\n", "2502.17326": "|**2025-02-24**|**A Web-Based Application Leveraging Geospatial Information to Automate On-Farm Trial Design**|Sneha Jha et.al.|[2502.17326](http://arxiv.org/abs/2502.17326)|null|\n", "2502.17309": "|**2025-02-24**|**Hybrid Human-Machine Perception via Adaptive LiDAR for Advanced Driver Assistance Systems**|Federico Scar\u00ec et.al.|[2502.17309](http://arxiv.org/abs/2502.17309)|null|\n", "2502.17252": "|**2025-02-24**|**Extremum Seeking Control for Antenna Pointing via Symmetric Product Approximation**|Bo Wang et.al.|[2502.17252](http://arxiv.org/abs/2502.17252)|null|\n", "2502.17239": "|**2025-02-24**|**Baichuan-Audio: A Unified Framework for End-to-End Speech Interaction**|Tianpeng Li et.al.|[2502.17239](http://arxiv.org/abs/2502.17239)|**[link](https://github.com/baichuan-inc/baichuan-audio)**|\n", "2502.17208": "|**2025-02-24**|**A highly sensitive, self-adhesive, biocompatible DLP 3D printed organohydrogel for flexible sensors and wearable devices**|Ze Zhang et.al.|[2502.17208](http://arxiv.org/abs/2502.17208)|null|\n", "2502.17167": "|**2025-02-24**|**A Novel Multiple Access Scheme for Heterogeneous Wireless Communications using Symmetry-aware Continual Deep Reinforcement Learning**|Hamidreza Mazandarani et.al.|[2502.17167](http://arxiv.org/abs/2502.17167)|null|\n", "2502.17161": "|**2025-02-24**|**Real-time Monitoring of Economic Shocks using Company Websites**|Michael Koenig et.al.|[2502.17161](http://arxiv.org/abs/2502.17161)|null|\n", "2502.17143": "|**2025-02-24**|**Sentiment analysis of texts from social networks based on machine learning methods for monitoring public sentiment**|Arsen Tolebay Nurlanuly et.al.|[2502.17143](http://arxiv.org/abs/2502.17143)|null|\n", "2502.16979": "|**2025-02-24**|**Inducing And Probing Charge Migration In Molecular Systems**|Sucharita Giri et.al.|[2502.16979](http://arxiv.org/abs/2502.16979)|null|\n", "2502.16970": "|**2025-02-24**|**220 GHz RIS-Aided Multi-user Terahertz Communication System: Prototype Design and Over-the-Air Experimental Trials**|Yanzhao Hou et.al.|[2502.16970](http://arxiv.org/abs/2502.16970)|null|\n", "2502.16963": "|**2025-02-24**|**Make LLM Inference Affordable to Everyone: Augmenting GPU Memory with NDP-DIMM**|Lian Liu et.al.|[2502.16963](http://arxiv.org/abs/2502.16963)|null|\n", "2502.16909": "|**2025-02-24**|**Design of a communication system Images for identification of vehicle plates**|Fabrizio Andre Farf\u00e1n Prado et.al.|[2502.16909](http://arxiv.org/abs/2502.16909)|null|\n", "2502.16907": "|**2025-02-24**|**MambaFlow: A Novel and Flow-guided State Space Model for Scene Flow Estimation**|Jiehao Luo et.al.|[2502.16907](http://arxiv.org/abs/2502.16907)|**[link](https://github.com/scnu-rislab/mambaflow)**|\n", "2502.16887": "|**2025-02-24**|**Primitive-Swarm: An Ultra-lightweight and Scalable Planner for Large-scale Aerial Swarms**|Jialiang Hou et.al.|[2502.16887](http://arxiv.org/abs/2502.16887)|**[link](https://github.com/zju-fast-lab/primitive-planner)**|\n", "2502.18442": "|**2025-02-25**|**Ion counting and temperature determination of Coulomb-crystallized laser-cooled ions in traps using convolutional neural networks**|Yanning Yin et.al.|[2502.18442](http://arxiv.org/abs/2502.18442)|**[link](https://github.com/yanningyin/coulomb-crystal-cnn)**|\n", "2502.18437": "|**2025-02-25**|**CRESSim-MPM: A Material Point Method Library for Surgical Soft Body Simulation with Cutting and Suturing**|Yafei Ou et.al.|[2502.18437](http://arxiv.org/abs/2502.18437)|null|\n", "2502.18381": "|**2025-02-25**|**Semantic and Goal-oriented Wireless Network Coverage: The Area of Effectiveness**|Mattia Merluzzi et.al.|[2502.18381](http://arxiv.org/abs/2502.18381)|null|\n", "2502.18240": "|**2025-02-25**|**Causal AI-based Root Cause Identification: Research to Practice at Scale**|Saurabh Jha et.al.|[2502.18240](http://arxiv.org/abs/2502.18240)|null|\n", "2502.18233": "|**2025-02-25**|**Software implemented fault diagnosis of natural gas pumping unit based on feedforward neural network**|Mykola Kozlenko et.al.|[2502.18233](http://arxiv.org/abs/2502.18233)|null|\n", "2502.18228": "|**2025-02-25**|**Debt Collection Negotiations with Large Language Models: An Evaluation System and Optimizing Decision Making with Multi-Agent**|Xiaofeng Wang et.al.|[2502.18228](http://arxiv.org/abs/2502.18228)|null|\n", "2502.18201": "|**2025-02-25**|**Intersubjective Model of AI-mediated Communication: Augmenting Human-Human Text Chat through LLM-based Adaptive Agent Pair**|Shutaro Aoyama et.al.|[2502.18201](http://arxiv.org/abs/2502.18201)|null|\n", "2502.18177": "|**2025-02-25**|**Recurrent Neural Networks for Dynamic VWAP Execution: Adaptive Trading Strategies with Temporal Kolmogorov-Arnold Networks**|Remi Genet et.al.|[2502.18177](http://arxiv.org/abs/2502.18177)|**[link](https://github.com/remigenet/deepdynamicvwap)**|\n", "2502.18152": "|**2025-02-25**|**Edge Training and Inference with Analog ReRAM Technology for Hand Gesture Recognition**|Victoria Clerico et.al.|[2502.18152](http://arxiv.org/abs/2502.18152)|null|\n", "2502.18151": "|**2025-02-25**|**A Real-time Spatio-Temporal Trajectory Planner for Autonomous Vehicles with Semantic Graph Optimization**|Shan He et.al.|[2502.18151](http://arxiv.org/abs/2502.18151)|null|\n", "2502.18143": "|**2025-02-25**|**LightFC-X: Lightweight Convolutional Tracker for RGB-X Tracking**|Yunfeng Li et.al.|[2502.18143](http://arxiv.org/abs/2502.18143)|**[link](https://github.com/liyunfenglyf/lightfc-x)**|\n", "2502.18046": "|**2025-02-25**|**Enhancing 5G O-RAN Communication Efficiency Through AI-Based Latency Forecasting**|Ra\u00fal Parada et.al.|[2502.18046](http://arxiv.org/abs/2502.18046)|null|\n", "2502.18023": "|**2025-02-25**|**Detecting Knowledge Boundary of Vision Large Language Models by Sampling-Based Inference**|Zhuo Chen et.al.|[2502.18023](http://arxiv.org/abs/2502.18023)|null|\n", "2502.17960": "|**2025-02-25**|**Advising Agent for Supporting Human-Multi-Drone Team Collaboration**|Hodaya Barr et.al.|[2502.17960](http://arxiv.org/abs/2502.17960)|null|\n", "2502.17929": "|**2025-02-25**|**Integrating Boosted learning with Differential Evolution (DE) Optimizer: A Prediction of Groundwater Quality Risk Assessment in Odisha**|Sonalika Subudhi et.al.|[2502.17929](http://arxiv.org/abs/2502.17929)|null|\n", "2502.17907": "|**2025-02-25**|**BD Currency Detection: A CNN Based Approach with Mobile App Integration**|Syed Jubayer Jaman et.al.|[2502.17907](http://arxiv.org/abs/2502.17907)|null|\n", "2502.17856": "|**2025-02-25**|**I Stan Alien Idols and Also the People Behind Them: Understanding How Seams Between Virtual and Real Identities Engage VTuber Fans -- A Case Study of PLAVE**|Dakyeom Ahn et.al.|[2502.17856](http://arxiv.org/abs/2502.17856)|null|\n", "2502.17822": "|**2025-02-26**|**Easy-Poly: A Easy Polyhedral Framework For 3D Multi-Object Tracking**|Peng Zhang et.al.|[2502.17822](http://arxiv.org/abs/2502.17822)|null|\n", "2502.17796": "|**2025-02-25**|**LAM: Large Avatar Model for One-shot Animatable Gaussian Head**|Yisheng He et.al.|[2502.17796](http://arxiv.org/abs/2502.17796)|null|\n", "2502.17729": "|**2025-02-24**|**Optimized Memory System Architecture for VESA VDC-M Decoder with Multi-Slice Support**|Hannah Yang et.al.|[2502.17729](http://arxiv.org/abs/2502.17729)|null|\n", "2502.19398": "|**2025-02-26**|**Nontrapping Tunable Topological Photonic Memory**|Amirreza Ahmadnejad et.al.|[2502.19398](http://arxiv.org/abs/2502.19398)|null|\n", "2502.19354": "|**2025-02-26**|**Two-Stage Weighted Projection for Reliable Low-Complexity Cooperative and Non-Cooperative Localization**|Harish K. Dureppagari et.al.|[2502.19354](http://arxiv.org/abs/2502.19354)|null|\n", "2502.19318": "|**2025-02-26**|**Does 3D Gaussian Splatting Need Accurate Volumetric Rendering?**|Adam Celarek et.al.|[2502.19318](http://arxiv.org/abs/2502.19318)|**[link](https://github.com/cg-tuwien/does_3d_gaussian_splatting_need_accurate_volumetric_rendering)**|\n", "2502.19303": "|**2025-02-26**|**Operando XPS in Reactive Plasmas: The Importance of The Wall Reactions**|J. Trey Diulus et.al.|[2502.19303](http://arxiv.org/abs/2502.19303)|null|\n", "2502.19282": "|**2025-02-26**|**Pilot and Data Power Control for Uplink Cell-free massive MIMO**|Saeed Mohammadzadeh et.al.|[2502.19282](http://arxiv.org/abs/2502.19282)|null|\n", "2502.19247": "|**2025-02-27**|**ProxyTransformation: Preshaping Point Cloud Manifold With Proxy Attention For 3D Visual Grounding**|Qihang Peng et.al.|[2502.19247](http://arxiv.org/abs/2502.19247)|null|\n", "2502.19220": "|**2025-02-26**|**Few Shot Alternating GD and Minimization for Generalizable Real-Time MRI**|Silpa Babu et.al.|[2502.19220](http://arxiv.org/abs/2502.19220)|null|\n", "2502.19181": "|**2025-02-26**|**Multi-level Attention-guided Graph Neural Network for Image Restoration**|Jiatao Jiang et.al.|[2502.19181](http://arxiv.org/abs/2502.19181)|null|\n", "2502.19148": "|**2025-02-26**|**Amulet: ReAlignment During Test Time for Personalized Preference Adaptation of LLMs**|Zhaowei Zhang et.al.|[2502.19148](http://arxiv.org/abs/2502.19148)|null|\n", "2502.19090": "|**2025-02-26**|**EndoMamba: An Efficient Foundation Model for Endoscopic Videos**|Qingyao Tian et.al.|[2502.19090](http://arxiv.org/abs/2502.19090)|null|\n", "2502.19078": "|**2025-02-26**|**Sparse Brains are Also Adaptive Brains: Cognitive-Load-Aware Dynamic Activation for LLMs**|Yiheng Yang et.al.|[2502.19078](http://arxiv.org/abs/2502.19078)|null|\n", "2502.19004": "|**2025-02-26**|**A Multi-Agent DRL-Based Framework for Optimal Resource Allocation and Twin Migration in the Multi-Tier Vehicular Metaverse**|Nahom Abishu Hayla et.al.|[2502.19004](http://arxiv.org/abs/2502.19004)|null|\n", "2502.18982": "|**2025-02-26**|**Enhanced Neuromorphic Semantic Segmentation Latency through Stream Event**|D. Hareb et.al.|[2502.18982](http://arxiv.org/abs/2502.18982)|null|\n", "2502.18929": "|**2025-02-26**|**Real-time Sign-Problem-Suppressed Quantum Monte Carlo Algorithm For Noisy Quantum Circuit Simulations**|Tong Shen et.al.|[2502.18929](http://arxiv.org/abs/2502.18929)|**[link](https://github.com/uscqserver/datarepo_qmcopensysdynamics)**|\n", "2502.18860": "|**2025-02-26**|**Exploring Rewriting Approaches for Different Conversational Tasks**|Md Mehrab Tanjim et.al.|[2502.18860](http://arxiv.org/abs/2502.18860)|null|\n", "2502.18846": "|**2025-02-26**|**RL-OGM-Parking: Lidar OGM-Based Hybrid Reinforcement Learning Planner for Autonomous Parking**|Zhitao Wang et.al.|[2502.18846](http://arxiv.org/abs/2502.18846)|null|\n", "2502.18836": "|**2025-02-26**|**REALM-Bench: A Real-World Planning Benchmark for LLMs and Multi-Agent Systems**|Longling Geng et.al.|[2502.18836](http://arxiv.org/abs/2502.18836)|**[link](https://github.com/genglongling/realm-bench)**|\n", "2502.18812": "|**2025-02-26**|**Work Statistics via Real-Time Effective Field Theory: Application to Work Extraction from Thermal Bath with Qubit Coupling**|Jhh-Jing Hong et.al.|[2502.18812](http://arxiv.org/abs/2502.18812)|null|\n", "2502.18778": "|**2025-02-26**|**M2-omni: Advancing Omni-MLLM for Comprehensive Modality Support with Competitive Performance**|Qingpei Guo et.al.|[2502.18778](http://arxiv.org/abs/2502.18778)|null|\n", "2502.18755": "|**2025-02-26**|**M-ANT: Efficient Low-bit Group Quantization for LLMs via Mathematically Adaptive Numerical Type**|Weiming Hu et.al.|[2502.18755](http://arxiv.org/abs/2502.18755)|null|\n", "2502.20386": "|**2025-02-27**|**ATLAS Navigator: Active Task-driven LAnguage-embedded Gaussian Splatting**|Dexter Ong et.al.|[2502.20386](http://arxiv.org/abs/2502.20386)|null|\n", "2502.20370": "|**2025-02-27**|**Ready-to-React: Online Reaction Policy for Two-Character Interaction Generation**|Zhi Cen et.al.|[2502.20370](http://arxiv.org/abs/2502.20370)|null|\n", "2502.20347": "|**2025-02-27**|**Modeling Driver Behavior in Speed Advisory Systems: Koopman-based Approach with Online Update**|Mehmet Fatih Ozkan et.al.|[2502.20347](http://arxiv.org/abs/2502.20347)|null|\n", "2502.20326": "|**2025-02-27**|**Deep Reinforcement Learning based Autonomous Decision-Making for Cooperative UAVs: A Search and Rescue Real World Application**|Thomas Hickling et.al.|[2502.20326](http://arxiv.org/abs/2502.20326)|null|\n", "2502.20323": "|**2025-02-27**|**ARTalk: Speech-Driven 3D Head Animation via Autoregressive Model**|Xuangeng Chu et.al.|[2502.20323](http://arxiv.org/abs/2502.20323)|null|\n", "2502.20320": "|**2025-02-27**|**ACCORD: Application Context-aware Cross-layer Optimization and Resource Design for 5G/NextG Machine-centric Applications**|Azuka Chiejina et.al.|[2502.20320](http://arxiv.org/abs/2502.20320)|null|\n", "2502.20304": "|**2025-02-27**|**Fast $\\ell_1$-Regularized EEG Source Localization Using Variable Projection**|Jack Michael Solomon et.al.|[2502.20304](http://arxiv.org/abs/2502.20304)|null|\n", "2502.20287": "|**2025-02-27**|**Electric power system security: the case for an integrated cyber-physical risk management framework**|Efthymios Karangelos et.al.|[2502.20287](http://arxiv.org/abs/2502.20287)|null|\n", "2502.20279": "|**2025-02-27**|**Online Meta-learning for AutoML in Real-time (OnMAR)**|Mia Gerber et.al.|[2502.20279](http://arxiv.org/abs/2502.20279)|null|\n", "2502.20225": "|**2025-02-27**|**DIN-CTS: Low-Complexity Depthwise-Inception Neural Network with Contrastive Training Strategy for Deepfake Speech Detection**|Lam Pham et.al.|[2502.20225](http://arxiv.org/abs/2502.20225)|null|\n", "2502.20078": "|**2025-02-27**|**BEV-DWPVO: BEV-based Differentiable Weighted Procrustes for Low Scale-drift Monocular Visual Odometry on Ground**|Yufei Wei et.al.|[2502.20078](http://arxiv.org/abs/2502.20078)|null|\n", "2502.20075": "|**2025-02-27**|**Methodology for GPU Frequency Switching Latency Measurement**|Daniel Velicka et.al.|[2502.20075](http://arxiv.org/abs/2502.20075)|null|\n", "2502.20045": "|**2025-02-27**|**Text2VDM: Text to Vector Displacement Maps for Expressive and Interactive 3D Sculpting**|Hengyu Meng et.al.|[2502.20045](http://arxiv.org/abs/2502.20045)|null|\n", "2502.19892": "|**2025-02-27**|**ColorDynamic: Generalizable, Scalable, Real-time, End-to-end Local Planner for Unstructured and Dynamic Environments**|Jinghao Xin et.al.|[2502.19892](http://arxiv.org/abs/2502.19892)|**[link](https://github.com/xinjinghao/colordynamic)**|\n", "2502.19802": "|**2025-02-27**|**ServoLNN: Lagrangian Neural Networks Driven by Servomechanisms**|Brandon Johns et.al.|[2502.19802](http://arxiv.org/abs/2502.19802)|**[link](https://github.com/brandon-johns/servolnn)**|\n", "2502.19769": "|**2025-02-27**|**QORT-Former: Query-optimized Real-time Transformer for Understanding Two Hands Manipulating Objects**|Elkhan Ismayilzada et.al.|[2502.19769](http://arxiv.org/abs/2502.19769)|null|\n", "2502.19751": "|**2025-02-28**|**Lightweight Contrastive Distilled Hashing for Online Cross-modal Retrieval**|Jiaxing Li et.al.|[2502.19751](http://arxiv.org/abs/2502.19751)|null|\n", "2502.19739": "|**2025-02-27**|**LUCAS: Layered Universal Codec Avatars**|Di Liu et.al.|[2502.19739](http://arxiv.org/abs/2502.19739)|null|\n", "2502.19734": "|**2025-02-27**|**FPGA-Accelerated SpeckleNN with SNL for Real-time X-ray Single-Particle Imaging**|Abhilasha Dave et.al.|[2502.19734](http://arxiv.org/abs/2502.19734)|null|\n", "2502.19732": "|**2025-02-27**|**Speculative Decoding and Beyond: An In-Depth Review of Techniques**|Yunhai Hu et.al.|[2502.19732](http://arxiv.org/abs/2502.19732)|null|\n", "2502.21306": "|**2025-02-28**|**Solar prosumage under different pricing regimes: Interactions with the transmission grid**|Dana Kirchem et.al.|[2502.21306](http://arxiv.org/abs/2502.21306)|null|\n", "2502.21267": "|**2025-02-28**|**ReaLJam: Real-Time Human-AI Music Jamming with Reinforcement Learning-Tuned Transformers**|Alexander Scarlatos et.al.|[2502.21267](http://arxiv.org/abs/2502.21267)|null|\n", "2502.21256": "|**2025-02-28**|**ALVI Interface: Towards Full Hand Motion Decoding for Amputees Using sEMG**|Aleksandr Kovalev et.al.|[2502.21256](http://arxiv.org/abs/2502.21256)|null|\n", "2502.21207": "|**2025-02-28**|**ReConForM : Real-time Contact-aware Motion Retargeting for more Diverse Character Morphologies**|Th\u00e9o Cheynel et.al.|[2502.21207](http://arxiv.org/abs/2502.21207)|null|\n", "2502.21198": "|**2025-02-28**|**AI-Enhanced Self-Triggering for Extensive Air Showers: Performance and FPGA Feasibility**|Qader Dorosti et.al.|[2502.21198](http://arxiv.org/abs/2502.21198)|null|\n", "2502.21117": "|**2025-02-28**|**Distributed Data Access in Industrial Edge Networks**|Theofanis P. Raptis et.al.|[2502.21117](http://arxiv.org/abs/2502.21117)|null|\n", "2502.21079": "|**2025-02-28**|**Training-free and Adaptive Sparse Attention for Efficient Long Video Generation**|Yifei Xia et.al.|[2502.21079](http://arxiv.org/abs/2502.21079)|null|\n", "2502.21057": "|**2025-02-28**|**Robust Deterministic Policy Gradient for Disturbance Attenuation and Its Application to Quadrotor Control**|Taeho Lee et.al.|[2502.21057](http://arxiv.org/abs/2502.21057)|null|\n", "2502.21056": "|**2025-02-28**|**Vibrotactile information coding strategies for a body-worn vest to aid robot-human collaboration**|Adrian Vecina Tercero et.al.|[2502.21056](http://arxiv.org/abs/2502.21056)|null|\n", "2502.21035": "|**2025-02-28**|**S4ConvD: Adaptive Scaling and Frequency Adjustment for Energy-Efficient Sensor Networks in Smart Buildings**|Melanie Schaller et.al.|[2502.21035](http://arxiv.org/abs/2502.21035)|**[link](https://github.com/MilanShao/S4ConvD)**|\n", "2502.20979": "|**2025-02-28**|**Real-Time Aerial Fire Detection on Resource-Constrained Devices Using Knowledge Distillation**|Sabina Jangirova et.al.|[2502.20979](http://arxiv.org/abs/2502.20979)|null|\n", "2502.20934": "|**2025-02-28**|**Less is More? Revisiting the Importance of Frame Rate in Real-Time Zero-Shot Surgical Video Segmentation**|Utku Ozbulak et.al.|[2502.20934](http://arxiv.org/abs/2502.20934)|null|\n", "2502.20926": "|**2025-02-28**|**Data-Importance-Aware Waterfilling for Adaptive Real-Time Communication in Computer Vision Applications**|Chunmei Xu et.al.|[2502.20926](http://arxiv.org/abs/2502.20926)|null|\n", "2502.20876": "|**2025-02-28**|**Real time simulations of scalar fields with kernelled complex Langevin equation**|Daniel Alvestad et.al.|[2502.20876](http://arxiv.org/abs/2502.20876)|null|\n", "2502.20856": "|**2025-02-28**|**Movable Antenna Aided Multiuser Communications: Antenna Position Optimization Based on Statistical Channel Information**|Ge Yan et.al.|[2502.20856](http://arxiv.org/abs/2502.20856)|null|\n", "2502.20766": "|**2025-02-28**|**FlexPrefill: A Context-Aware Sparse Attention Mechanism for Efficient Long-Sequence Inference**|Xunhao Lai et.al.|[2502.20766](http://arxiv.org/abs/2502.20766)|**[link](https://github.com/bytedance/FlexPrefill)**|\n", "2502.20762": "|**2025-02-28**|**Towards Practical Real-Time Neural Video Compression**|Zhaoyang Jia et.al.|[2502.20762](http://arxiv.org/abs/2502.20762)|**[link](https://github.com/microsoft/dcvc)**|\n", "2502.20718": "|**2025-02-28**|**Computationally Efficient Safe Control of Linear Systems under Severe Sensor Attacks**|Xiao Tan et.al.|[2502.20718](http://arxiv.org/abs/2502.20718)|null|\n", "2502.20651": "|**2025-02-28**|**The Common Objects Underwater (COU) Dataset for Robust Underwater Object Detection**|Rishi Mukherjee et.al.|[2502.20651](http://arxiv.org/abs/2502.20651)|null|\n", "2502.20622": "|**2025-02-28**|**RTGen: Real-Time Generative Detection Transformer**|Chi Ruan et.al.|[2502.20622](http://arxiv.org/abs/2502.20622)|null|\n", "2503.02881": "|**2025-03-04**|**Reactive Diffusion Policy: Slow-Fast Visual-Tactile Policy Learning for Contact-Rich Manipulation**|Han Xue et.al.|[2503.02881](http://arxiv.org/abs/2503.02881)|null|\n", "2503.02861": "|**2025-03-04**|**Evaluation of Architectural Synthesis Using Generative AI**|Jingfei Huang et.al.|[2503.02861](http://arxiv.org/abs/2503.02861)|null|\n", "2503.02853": "|**2025-03-04**|**CADDI: An in-Class Activity Detection Dataset using IMU data from low-cost sensors**|Luis Marquez-Carpintero et.al.|[2503.02853](http://arxiv.org/abs/2503.02853)|null|\n", "2503.02831": "|**2025-03-04**|**Meta-Learning to Explore via Memory Density Feedback**|Kevin L. McKee et.al.|[2503.02831](http://arxiv.org/abs/2503.02831)|null|\n", "2503.02823": "|**2025-03-04**|**A Multimodal Symphony: Integrating Taste and Sound through Generative AI**|Matteo Spanio et.al.|[2503.02823](http://arxiv.org/abs/2503.02823)|null|\n", "2503.02723": "|**2025-03-04**|**ImpedanceGPT: VLM-driven Impedance Control of Swarm of Mini-drones for Intelligent Navigation in Dynamic Environment**|Faryal Batool et.al.|[2503.02723](http://arxiv.org/abs/2503.02723)|null|\n", "2503.02717": "|**2025-03-04**|**Catheter Detection and Segmentation in X-ray Images via Multi-task Learning**|Lin Xi et.al.|[2503.02717](http://arxiv.org/abs/2503.02717)|null|\n", "2503.02652": "|**2025-03-04**|**Cellular Automaton With CNN**|Valery Ashu et.al.|[2503.02652](http://arxiv.org/abs/2503.02652)|**[link](https://github.com/ashuvalery/custom_cnn)**|\n", "2503.02587": "|**2025-03-04**|**Learning Dexterous In-Hand Manipulation with Multifingered Hands via Visuomotor Diffusion**|Piotr Koczy et.al.|[2503.02587](http://arxiv.org/abs/2503.02587)|null|\n", "2503.02572": "|**2025-03-04**|**RaceVLA: VLA-based Racing Drone Navigation with Human-like Behaviour**|Valerii Serpiva et.al.|[2503.02572](http://arxiv.org/abs/2503.02572)|null|\n", "2503.02569": "|**2025-03-04**|**Prediction of amino acid content in live black soldier fly larvae using near infrared spectroscopy**|R. M. Zaalberg et.al.|[2503.02569](http://arxiv.org/abs/2503.02569)|null|\n", "2503.02541": "|**2025-03-04**|**The Stochastic Light Confinement of LiquidO**|LiquidO Collaboration et.al.|[2503.02541](http://arxiv.org/abs/2503.02541)|null|\n", "2503.02452": "|**2025-03-04**|**2DGS-Avatar: Animatable High-fidelity Clothed Avatar via 2D Gaussian Splatting**|Qipeng Yan et.al.|[2503.02452](http://arxiv.org/abs/2503.02452)|null|\n", "2503.02440": "|**2025-03-04**|**Artificial Intelligence in Reactor Physics: Current Status and Future Prospects**|Ruizhi Zhang et.al.|[2503.02440](http://arxiv.org/abs/2503.02440)|null|\n", "2503.02425": "|**2025-03-05**|**Real-time station monitor and stationtest pipelines for LOFAR 2.0**|Jun Wang et.al.|[2503.02425](http://arxiv.org/abs/2503.02425)|null|\n", "2503.02412": "|**2025-03-05**|**SEB-Naver: A SE(2)-based Local Navigation Framework for Car-like Robots on Uneven Terrain**|Xiaoying Li et.al.|[2503.02412](http://arxiv.org/abs/2503.02412)|**[link](https://github.com/zju-fast-lab/seb_naver)**|\n", "2503.02398": "|**2025-03-04**|**PersonaX: A Recommendation Agent Oriented User Modeling Framework for Long Behavior Sequence**|Yunxiao Shi et.al.|[2503.02398](http://arxiv.org/abs/2503.02398)|**[link](https://github.com/ancientshi/personax)**|\n", "2503.02394": "|**2025-03-05**|**BHViT: Binarized Hybrid Vision Transformer**|Tian Gao et.al.|[2503.02394](http://arxiv.org/abs/2503.02394)|**[link](https://github.com/IMRL/BHViT)**|\n", "2503.02392": "|**2025-03-04**|**Long distance local local oscillator continuous variable quantum key distribution with digital signal processing**|Dengke Qi et.al.|[2503.02392](http://arxiv.org/abs/2503.02392)|null|\n", "2503.02301": "|**2025-03-04**|**Towards Large Language Model Guided Kernel Direct Fuzzing**|Xie Li et.al.|[2503.02301](http://arxiv.org/abs/2503.02301)|null|\n", "2503.03747": "|**2025-03-05**|**PacketCLIP: Multi-Modal Embedding of Network Traffic and Language for Cybersecurity Reasoning**|Ryozo Masukawa et.al.|[2503.03747](http://arxiv.org/abs/2503.03747)|null|\n", "2503.03663": "|**2025-03-05**|**LION-FS: Fast & Slow Video-Language Thinker as Online Video Assistant**|Wei Li et.al.|[2503.03663](http://arxiv.org/abs/2503.03663)|null|\n", "2503.03612": "|**2025-03-05**|**Large language models in finance: estimating financial sentiment for stock prediction**|Kemal Kirtac et.al.|[2503.03612](http://arxiv.org/abs/2503.03612)|null|\n", "2503.03594": "|**2025-03-05**|**Small but Mighty: Enhancing Time Series Forecasting with Lightweight LLMs**|Haoran Fan et.al.|[2503.03594](http://arxiv.org/abs/2503.03594)|null|\n", "2503.03590": "|**2025-03-05**|**Digital Twin-Enabled Blockage-Aware Dynamic mmWave Multi-Hop V2X Communication**|Supat Roongpraiwan et.al.|[2503.03590](http://arxiv.org/abs/2503.03590)|null|\n", "2503.03581": "|**2025-03-05**|**imuQP: An Inverse-Matrix-Updates-Based Fast QP Solver Suitable for Real-Time MPC**|Victor Truong Thinh Lam et.al.|[2503.03581](http://arxiv.org/abs/2503.03581)|null|\n", "2503.03570": "|**2025-03-05**|**Towards an Emotion-Aware Metaverse: A Human-Centric Shipboard Fire Drill Simulator**|Musaab H. Hamed-Ahmed et.al.|[2503.03570](http://arxiv.org/abs/2503.03570)|null|\n", "2503.03532": "|**2025-03-05**|**AI-Enabled Conversational Journaling for Advancing Parkinson's Disease Symptom Tracking**|Mashrur Rashik et.al.|[2503.03532](http://arxiv.org/abs/2503.03532)|**[link](https://github.com/mashrur29/AI-Enabled-Conversational-Journaling-Agent)**|\n", "2503.03505": "|**2025-03-05**|**Parallelized Planning-Acting for Efficient LLM-based Multi-Agent Systems**|Yaoru Li et.al.|[2503.03505](http://arxiv.org/abs/2503.03505)|**[link](https://github.com/zju-vipa/odyssey)**|\n", "2503.03479": "|**2025-03-05**|**Feature Point Extraction for Extra-Affine Image**|Tao Wang et.al.|[2503.03479](http://arxiv.org/abs/2503.03479)|null|\n", "2503.03428": "|**2025-03-05**|**Privacy is All You Need: Revolutionizing Wearable Health Data with Advanced PETs**|Karthik Barma et.al.|[2503.03428](http://arxiv.org/abs/2503.03428)|null|\n", "2503.03412": "|**2025-03-05**|**REACT: Real-time Efficient Attribute Clustering and Transfer for Updatable 3D Scene Graph**|Phuoc Nguyen et.al.|[2503.03412](http://arxiv.org/abs/2503.03412)|**[link](https://github.com/aalto-intelligent-robotics/REACT)**|\n", "2503.03391": "|**2025-03-05**|**Multi-Agent DRL for Queue-Aware Task Offloading in Hierarchical MEC-Enabled Air-Ground Networks**|Muhammet Hevesli et.al.|[2503.03391](http://arxiv.org/abs/2503.03391)|null|\n", "2503.03379": "|**2025-03-05**|**Prosperity: Accelerating Spiking Neural Networks via Product Sparsity**|Chiyue Wei et.al.|[2503.03379](http://arxiv.org/abs/2503.03379)|**[link](https://github.com/dubcyfor3/Prosperity)**|\n", "2503.03372": "|**2025-03-05**|**A Novel Multi-Criteria Local Latin Hypercube Refinement System for Commutation Angle Improvement in IPMSMs**|Pedram Asef et.al.|[2503.03372](http://arxiv.org/abs/2503.03372)|null|\n", "2503.03346": "|**2025-03-05**|**SEAL: Safety Enhanced Trajectory Planning and Control Framework for Quadrotor Flight in Complex Environments**|Yiming Wang et.al.|[2503.03346](http://arxiv.org/abs/2503.03346)|**[link](https://github.com/ma29-hit/seal)**|\n", "2503.03334": "|**2025-03-05**|**IoT Integration Protocol for Enhanced Hospital Care**|Ellie Zontou et.al.|[2503.03334](http://arxiv.org/abs/2503.03334)|null|\n", "2503.03330": "|**2025-03-05**|**Automated Attendee Recognition System for Large-Scale Social Events or Conference Gathering**|Dhruv Motwani et.al.|[2503.03330](http://arxiv.org/abs/2503.03330)|null|\n", "2503.03326": "|**2025-03-05**|**Arc Blanc: a real time ocean simulation framework**|David Algis et.al.|[2503.03326](http://arxiv.org/abs/2503.03326)|null|\n", "2503.03325": "|**2025-03-05**|**Golden Cudgel Network for Real-Time Semantic Segmentation**|Guoyu Yang et.al.|[2503.03325](http://arxiv.org/abs/2503.03325)|**[link](https://github.com/gyyang23/gcnet)**|\n", "2503.04721": "|**2025-03-06**|**Full-Duplex-Bench: A Benchmark to Evaluate Full-duplex Spoken Dialogue Models on Turn-taking Capabilities**|Guan-Ting Lin et.al.|[2503.04721](http://arxiv.org/abs/2503.04721)|null|\n", "2503.04714": "|**2025-03-06**|**An Extended State Space Model of Aggregated Electric Vehicles for Flexibility Estimation and Power Control**|Yiping Liu et.al.|[2503.04714](http://arxiv.org/abs/2503.04714)|null|\n", "2503.04694": "|**2025-03-06**|**Rapid updating of multivariate resource models based on new information using EnKF-MDA and multi-Gaussian transformation**|Sultan Abulkhair et.al.|[2503.04694](http://arxiv.org/abs/2503.04694)|null|\n", "2503.04688": "|**2025-03-06**|**Teach YOLO to Remember: A Self-Distillation Approach for Continual Object Detection**|Riccardo De Monte et.al.|[2503.04688](http://arxiv.org/abs/2503.04688)|null|\n", "2503.04641": "|**2025-03-06**|**Simulating the Real World: A Unified Survey of Multimodal Generative Models**|Yuqi Hu et.al.|[2503.04641](http://arxiv.org/abs/2503.04641)|**[link](https://github.com/aleeehu/world-simulator)**|\n", "2503.04613": "|**2025-03-06**|**Whole-Body Model-Predictive Control of Legged Robots with MuJoCo**|John Z. Zhang et.al.|[2503.04613](http://arxiv.org/abs/2503.04613)|null|\n", "2503.04528": "|**2025-03-06**|**Federated Dynamic Modeling and Learning for Spatiotemporal Data Forecasting**|Thien Pham et.al.|[2503.04528](http://arxiv.org/abs/2503.04528)|null|\n", "2503.04525": "|**2025-03-06**|**Learning Deterministic One-Counter Automata in Polynomial Time**|Prince Mathew et.al.|[2503.04525](http://arxiv.org/abs/2503.04525)|null|\n", "2503.04521": "|**2025-03-06**|**Dynamic Pricing for On-Demand DNN Inference in the Edge-AI Market**|Songyuan Li et.al.|[2503.04521](http://arxiv.org/abs/2503.04521)|null|\n", "2503.04462": "|**2025-03-06**|**PALo: Learning Posture-Aware Locomotion for Quadruped Robots**|Xiangyu Miao et.al.|[2503.04462](http://arxiv.org/abs/2503.04462)|null|\n", "2503.04459": "|**2025-03-07**|**Question-Aware Gaussian Experts for Audio-Visual Question Answering**|Hongyeob Kim et.al.|[2503.04459](http://arxiv.org/abs/2503.04459)|**[link](https://github.com/AIM-SKKU/QA-TIGER)**|\n", "2503.04452": "|**2025-03-06**|**A lightweight model FDM-YOLO for small target improvement based on YOLOv8**|Xuerui Zhang et.al.|[2503.04452](http://arxiv.org/abs/2503.04452)|null|\n", "2503.04431": "|**2025-03-06**|**Observation of non-adiabatic Landau-Zener tunneling among Floquet states**|Yun Yen et.al.|[2503.04431](http://arxiv.org/abs/2503.04431)|null|\n", "2503.04391": "|**2025-03-06**|**Real-Time 3D Magnetic Field Camera for a Spherical Volume**|Fynn Foerger et.al.|[2503.04391](http://arxiv.org/abs/2503.04391)|null|\n", "2503.04340": "|**2025-03-06**|**Energy Consumption of Robotic Arm with the Local Reduction Method**|Halima Ibrahim Kure et.al.|[2503.04340](http://arxiv.org/abs/2503.04340)|null|\n", "2503.04250": "|**2025-03-06**|**An Egocentric Vision-Language Model based Portable Real-time Smart Assistant**|Yifei Huang et.al.|[2503.04250](http://arxiv.org/abs/2503.04250)|**[link](https://github.com/opengvlab/vinci)**|\n", "2503.04235": "|**2025-03-06**|**Geometry-Constrained Monocular Scale Estimation Using Semantic Segmentation for Dynamic Scenes**|Hui Zhang et.al.|[2503.04235](http://arxiv.org/abs/2503.04235)|null|\n", "2503.04217": "|**2025-03-06**|**Just Roll with It: Exploring the Mitigating Effects of Postural Alignment on Vection-Induced Cybersickness in Virtual Reality Over Time**|Charlotte Croucher et.al.|[2503.04217](http://arxiv.org/abs/2503.04217)|null|\n", "2503.04208": "|**2025-03-06**|**White Gaussian Noise Generation with a Vacuum State Quantum Entropy Source Chip**|Guan-Ru Qiao et.al.|[2503.04208](http://arxiv.org/abs/2503.04208)|null|\n", "2503.04193": "|**2025-03-06**|**Towards Multi-dimensional Elasticity for Pervasive Stream Processing Services**|Boris Sedlak et.al.|[2503.04193](http://arxiv.org/abs/2503.04193)|null|\n", "2503.05675": "|**2025-03-07**|**Algorithmic Data Minimization for Machine Learning over Internet-of-Things Data Streams**|Ted Shaowang et.al.|[2503.05675](http://arxiv.org/abs/2503.05675)|null|\n", "2503.05620": "|**2025-03-07**|**Learning LLM Preference over Intra-Dialogue Pairs: A Framework for Utterance-level Understandings**|Xuanqing Liu et.al.|[2503.05620](http://arxiv.org/abs/2503.05620)|null|\n", "2503.05604": "|**2025-03-07**|**CACTUS: An Open Dataset and Framework for Automated Cardiac Assessment and Classification of Ultrasound Images Using Deep Transfer Learning**|Hanae Elmekki et.al.|[2503.05604](http://arxiv.org/abs/2503.05604)|null|\n", "2503.05552": "|**2025-03-07**|**Synchronization between media followers and political supporters during an election process: towards a real time study**|R\u00e9mi Perrier et.al.|[2503.05552](http://arxiv.org/abs/2503.05552)|null|\n", "2503.05529": "|**2025-03-07**|**PoSSUM: A Protocol for Surveying Social-media Users with Multimodal LLMs**|Roberto Cerina et.al.|[2503.05529](http://arxiv.org/abs/2503.05529)|null|\n", "2503.05516": "|**2025-03-07**|**Cognitive Bias Detection Using Advanced Prompt Engineering**|Frederic Lemieux et.al.|[2503.05516](http://arxiv.org/abs/2503.05516)|null|\n", "2503.05493": "|**2025-03-07**|**Benchmarking LLMs in Recommendation Tasks: A Comparative Evaluation with Conventional Recommenders**|Qijiong Liu et.al.|[2503.05493](http://arxiv.org/abs/2503.05493)|null|\n", "2503.05490": "|**2025-03-07**|**Adaptive Neural Unscented Kalman Filter**|Amit Levy et.al.|[2503.05490](http://arxiv.org/abs/2503.05490)|null|\n", "2503.05464": "|**2025-03-07**|**Automatic Teaching Platform on Vision Language Retrieval Augmented Generation**|Ruslan Gokhman et.al.|[2503.05464](http://arxiv.org/abs/2503.05464)|null|\n", "2503.05419": "|**2025-03-07**|**Physics-based machine learning for fatigue lifetime prediction under non-uniform loading scenarios**|Abedulgader Baktheer et.al.|[2503.05419](http://arxiv.org/abs/2503.05419)|null|\n", "2503.05332": "|**2025-03-07**|**CoMoGaussian: Continuous Motion-Aware Gaussian Splatting from Motion-Blurred Images**|Jungho Lee et.al.|[2503.05332](http://arxiv.org/abs/2503.05332)|**[link](https://github.com/jho-yonsei/comogaussian)**|\n", "2503.05328": "|**2025-03-07**|**Dynamic Knowledge Integration for Evidence-Driven Counter-Argument Generation with Large Language Models**|Anar Yeginbergen et.al.|[2503.05328](http://arxiv.org/abs/2503.05328)|null|\n", "2503.05303": "|**2025-03-07**|**Robust Intrusion Detection System with Explainable Artificial Intelligence**|Bet\u00fcl G\u00fcven\u00e7 Paltun et.al.|[2503.05303](http://arxiv.org/abs/2503.05303)|null|\n", "2503.05301": "|**2025-03-07**|**A Helping (Human) Hand in Kinematic Structure Estimation**|Adrian Pfisterer et.al.|[2503.05301](http://arxiv.org/abs/2503.05301)|null|\n", "2503.05274": "|**2025-03-07**|**Evidential Uncertainty Estimation for Multi-Modal Trajectory Prediction**|Sajad Marvi et.al.|[2503.05274](http://arxiv.org/abs/2503.05274)|null|\n", "2503.05273": "|**2025-03-07**|**Luminosity measurement with the LHCb RICH detectors in Run 3**|Paula Alvarez Cartelle et.al.|[2503.05273](http://arxiv.org/abs/2503.05273)|null|\n", "2503.05251": "|**2025-03-07**|**A Map-free Deep Learning-based Framework for Gate-to-Gate Monocular Visual Navigation aboard Miniaturized Aerial Vehicles**|Lorenzo Scarciglia et.al.|[2503.05251](http://arxiv.org/abs/2503.05251)|null|\n", "2503.05248": "|**2025-03-07**|**Optimizing LLM Inference Throughput via Memory-aware and SLA-constrained Dynamic Batching**|Bowen Pang et.al.|[2503.05248](http://arxiv.org/abs/2503.05248)|**[link](https://github.com/kevinlee1110/dynamic-batching)**|\n", "2503.05236": "|**2025-03-07**|**Unified Reward Model for Multimodal Understanding and Generation**|Yibin Wang et.al.|[2503.05236](http://arxiv.org/abs/2503.05236)|null|\n", "2503.05226": "|**2025-03-07**|**Reward-Centered ReST-MCTS: A Robust Decision-Making Framework for Robotic Manipulation in High Uncertainty Environments**|Xibai Wang et.al.|[2503.05226](http://arxiv.org/abs/2503.05226)|null|\n", "2503.07486": "|**2025-03-10**|**Real-Time Monitoring of Multimode Squeezing**|Mahmoud Kalash et.al.|[2503.07486](http://arxiv.org/abs/2503.07486)|null|\n", "2503.07465": "|**2025-03-10**|**YOLOE: Real-Time Seeing Anything**|Ao Wang et.al.|[2503.07465](http://arxiv.org/abs/2503.07465)|**[link](https://github.com/THU-MIG/yoloe)**|\n", "2503.07446": "|**2025-03-10**|**EigenGS Representation: From Eigenspace to Gaussian Image Space**|Lo-Wei Tai et.al.|[2503.07446](http://arxiv.org/abs/2503.07446)|null|\n", "2503.07420": "|**2025-03-10**|**The Interplay of AI-and-RAN: Dynamic Resource Allocation for Converged 6G Platform**|Syed Danial Ali Shah et.al.|[2503.07420](http://arxiv.org/abs/2503.07420)|null|\n", "2503.07376": "|**2025-03-10**|**AttentionSwarm: Reinforcement Learning with Attention Control Barier Function for Crazyflie Drones in Dynamic Environments**|Grik Tadevosyan et.al.|[2503.07376](http://arxiv.org/abs/2503.07376)|null|\n", "2503.07375": "|**2025-03-10**|**Probabilistic Segmentation for Robust Field of View Estimation**|R. Spencer Hallyburton et.al.|[2503.07375](http://arxiv.org/abs/2503.07375)|null|\n", "2503.07371": "|**2025-03-10**|**HGO-YOLO: Advancing Anomaly Behavior Detection with Hierarchical Features and Lightweight Optimized Detection**|Qizhi Zheng et.al.|[2503.07371](http://arxiv.org/abs/2503.07371)|null|\n", "2503.07338": "|**2025-03-10**|**Temporal Triplane Transformers as Occupancy World Models**|Haoran Xu et.al.|[2503.07338](http://arxiv.org/abs/2503.07338)|null|\n", "2503.07279": "|**2025-03-10**|**VizTrust: A Visual Analytics Tool for Capturing User Trust Dynamics in Human-AI Communication**|Xin Wang et.al.|[2503.07279](http://arxiv.org/abs/2503.07279)|**[link](https://github.com/xin-wang-kr/VizTrust-project)**|\n", "2503.07252": "|**2025-03-10**|**Semantic Communications with Computer Vision Sensing for Edge Video Transmission**|Yubo Peng et.al.|[2503.07252](http://arxiv.org/abs/2503.07252)|null|\n", "2503.07234": "|**2025-03-10**|**CoT-Drive: Efficient Motion Forecasting for Autonomous Driving with LLMs and Chain-of-Thought Prompting**|Haicheng Liao et.al.|[2503.07234](http://arxiv.org/abs/2503.07234)|null|\n", "2503.07181": "|**2025-03-10**|**Interactive visualization of large molecular systems with VTX: example with a minimal whole-cell model**|Maxime Maria et.al.|[2503.07181](http://arxiv.org/abs/2503.07181)|null|\n", "2503.07143": "|**2025-03-10**|**Spatiotemporal Deep Learning Network for Photon-Level Block Compressed Sensing Imaging**|Changzhi Yu et.al.|[2503.07143](http://arxiv.org/abs/2503.07143)|null|\n", "2503.07138": "|**2025-03-10**|**Strat{\u00e9}gies de contr{\u00f4}le pour les {\u00e9}oliennes flottantes : {\u00e9}tat de l'art et perspectives**|Flavie Didier et.al.|[2503.07138](http://arxiv.org/abs/2503.07138)|null|\n", "2503.07095": "|**2025-03-10**|**Sum frequency generation from real-time simulations in two-dimensional crystals**|Mike N. Pionteck et.al.|[2503.07095](http://arxiv.org/abs/2503.07095)|null|\n", "2503.07044": "|**2025-03-10**|**DatawiseAgent: A Notebook-Centric LLM Agent Framework for Automated Data Science**|Ziming You et.al.|[2503.07044](http://arxiv.org/abs/2503.07044)|null|\n", "2503.07014": "|**2025-03-10**|**Vib2Mol: from vibrational spectra to molecular structures-a versatile deep learning model**|Xinyu Lu et.al.|[2503.07014](http://arxiv.org/abs/2503.07014)|null|\n", "2503.07013": "|**2025-03-10**|**Learning Nash Equilibrial Hamiltonian for Two-Player Collision-Avoiding Interactions**|Lei Zhang et.al.|[2503.07013](http://arxiv.org/abs/2503.07013)|null|\n", "2503.07005": "|**2025-03-10**|**Streaming Self-Corrected Dual-Comb Spectrometer**|Alexander Eber et.al.|[2503.07005](http://arxiv.org/abs/2503.07005)|null|\n", "2503.06996": "|**2025-03-10**|**Public space security management using digital twin technologies**|Stylianos Zindros et.al.|[2503.06996](http://arxiv.org/abs/2503.06996)|null|\n", "2503.07568": "|**2025-03-10**|**Runtime Detection of Adversarial Attacks in AI Accelerators Using Performance Counters**|Habibur Rahaman et.al.|[2503.07568](http://arxiv.org/abs/2503.07568)|null|\n", "2503.07541": "|**2025-03-10**|**Geometric Retargeting: A Principled, Ultrafast Neural Hand Retargeting Algorithm**|Zhao-Heng Yin et.al.|[2503.07541](http://arxiv.org/abs/2503.07541)|null|\n", "2503.07536": "|**2025-03-11**|**LMM-R1: Empowering 3B LMMs with Strong Reasoning Abilities Through Two-Stage Rule-Based RL**|Yingzhe Peng et.al.|[2503.07536](http://arxiv.org/abs/2503.07536)|null|\n", "2503.07528": "|**2025-03-10**|**Real-Time Structural Deflection Estimation in Hydraulically Actuated Systems Using 3D Flexible Multibody Simulation and DNNs**|Qasim Khadim et.al.|[2503.07528](http://arxiv.org/abs/2503.07528)|null|\n", "2503.07527": "|**2025-03-10**|**Real-Time Load Estimation for Load-lifting Exoskeletons Using Insole Pressure Sensors and Machine Learning**|Kaida Wu et.al.|[2503.07527](http://arxiv.org/abs/2503.07527)|null|\n", "2503.07517": "|**2025-03-10**|**FastInstShadow: A Simple Query-Based Model for Instance Shadow Detection**|Takeru Inoue et.al.|[2503.07517](http://arxiv.org/abs/2503.07517)|null|\n", "2503.08686": "|**2025-03-11**|**OmniMamba: Efficient and Unified Multimodal Understanding and Generation via State Space Models**|Jialv Zou et.al.|[2503.08686](http://arxiv.org/abs/2503.08686)|**[link](https://github.com/hustvl/omnimamba)**|\n", "2503.08683": "|**2025-03-11**|**CoLMDriver: LLM-based Negotiation Benefits Cooperative Autonomous Driving**|Changxing Liu et.al.|[2503.08683](http://arxiv.org/abs/2503.08683)|**[link](https://github.com/cxliu0314/colmdriver)**|\n", "2503.08648": "|**2025-03-11**|**GraphSense: Graph Embedding Based Code Suggestion Framework**|H. R Navod Thisura Peiris et.al.|[2503.08648](http://arxiv.org/abs/2503.08648)|**[link](https://github.com/NavodPeiris/graphsense)**|\n", "2503.08599": "|**2025-03-11**|**MAREA: A Delay-Aware Multi-time-Scale Radio Resource Orchestrator for 6G O-RAN**|Oscar Adamuz-Hinojosa et.al.|[2503.08599](http://arxiv.org/abs/2503.08599)|null|\n", "2503.08539": "|**2025-03-11**|**Desirable Unfamiliarity: Insights from Eye Movements on Engagement and Readability of Dictation Interfaces**|Zhaohui Liang et.al.|[2503.08539](http://arxiv.org/abs/2503.08539)|null|\n", "2503.08509": "|**2025-03-11**|**DISTINGUISH Workflow: A New Paradigm of Dynamic Well Placement Using Generative Machine Learning**|Sergey Alyaev et.al.|[2503.08509](http://arxiv.org/abs/2503.08509)|**[link](https://github.com/geosteering-no/GAN-geosteering)**|\n", "2503.08407": "|**2025-03-11**|**WildSeg3D: Segment Any 3D Objects in the Wild from 2D Images**|Yansong Guo et.al.|[2503.08407](http://arxiv.org/abs/2503.08407)|null|\n", "2503.08375": "|**2025-03-11**|**Gait in Eight: Efficient On-Robot Learning for Omnidirectional Quadruped Locomotion**|Nico Bohlinger et.al.|[2503.08375](http://arxiv.org/abs/2503.08375)|null|\n", "2503.08348": "|**2025-03-11**|**Design and Implementation of FourCropNet: A CNN-Based System for Efficient Multi-Crop Disease Detection and Management**|H. P. Khandagale et.al.|[2503.08348](http://arxiv.org/abs/2503.08348)|null|\n", "2503.08330": "|**2025-03-11**|**KiteRunner: Language-Driven Cooperative Local-Global Navigation Policy with UAV Mapping in Outdoor Environments**|Shibo Huang et.al.|[2503.08330](http://arxiv.org/abs/2503.08330)|null|\n", "2503.08246": "|**2025-03-11**|**Dynamic DBSCAN with Euler Tour Sequences**|Seiyun Shin et.al.|[2503.08246](http://arxiv.org/abs/2503.08246)|null|\n", "2503.08224": "|**2025-03-11**|**HRAvatar: High-Quality and Relightable Gaussian Head Avatar**|Dongbin Zhang et.al.|[2503.08224](http://arxiv.org/abs/2503.08224)|null|\n", "2503.08179": "|**2025-03-12**|**ProtTeX: Structure-In-Context Reasoning and Editing of Proteins with Large Language Models**|Zicheng Ma et.al.|[2503.08179](http://arxiv.org/abs/2503.08179)|null|\n", "2503.08166": "|**2025-03-11**|**Dynamic Scene Reconstruction: Recent Advance in Real-time Rendering and Streaming**|Jiaxuan Zhu et.al.|[2503.08166](http://arxiv.org/abs/2503.08166)|null|\n", "2503.08165": "|**2025-03-11**|**Multimodal Generation of Animatable 3D Human Models with AvatarForge**|Xinhang Liu et.al.|[2503.08165](http://arxiv.org/abs/2503.08165)|null|\n", "2503.08162": "|**2025-03-11**|**FASIONAD++ : Integrating High-Level Instruction and Information Bottleneck in FAt-Slow fusION Systems for Enhanced Safety in Autonomous Driving with Adaptive Feedback**|Kangan Qian et.al.|[2503.08162](http://arxiv.org/abs/2503.08162)|null|\n", "2503.08112": "|**2025-03-11**|**In-situ dynamic spatial reconfiguration of nanoplasmonics using photothermal-shock tweezers**|Runlin Zhu et.al.|[2503.08112](http://arxiv.org/abs/2503.08112)|null|\n", "2503.08084": "|**2025-03-11**|**Instruction-Augmented Long-Horizon Planning: Embedding Grounding Mechanisms in Embodied Mobile Manipulation**|Fangyuan Wang et.al.|[2503.08084](http://arxiv.org/abs/2503.08084)|null|\n", "2503.07997": "|**2025-03-11**|**A Survey of Challenges and Sensing Technologies in Autonomous Retail Systems**|Shimmy Rukundo et.al.|[2503.07997](http://arxiv.org/abs/2503.07997)|null|\n", "2503.07984": "|**2025-03-11**|**Decentralized Integration of Grid Edge Resources into Wholesale Electricity Markets via Mean-field Games**|Chen Feng et.al.|[2503.07984](http://arxiv.org/abs/2503.07984)|null|\n", "2503.09527": "|**2025-03-12**|**CombatVLA: An Efficient Vision-Language-Action Model for Combat Tasks in 3D Action Role-Playing Games**|Peng Chen et.al.|[2503.09527](http://arxiv.org/abs/2503.09527)|null|\n", "2503.09516": "|**2025-03-12**|**Search-R1: Training LLMs to Reason and Leverage Search Engines with Reinforcement Learning**|Bowen Jin et.al.|[2503.09516](http://arxiv.org/abs/2503.09516)|**[link](https://github.com/petergriffinjin/search-r1)**|\n", "2503.09513": "|**2025-03-12**|**RESTRAIN: Reinforcement Learning-Based Secure Framework for Trigger-Action IoT Environment**|Md Morshed Alam et.al.|[2503.09513](http://arxiv.org/abs/2503.09513)|null|\n", "2503.09511": "|**2025-03-12**|**TRACE: Real-Time Multimodal Common Ground Tracking in Situated Collaborative Dialogues**|Hannah VanderHoeven et.al.|[2503.09511](http://arxiv.org/abs/2503.09511)|null|\n", "2503.09474": "|**2025-03-12**|**SurgicalVLM-Agent: Towards an Interactive AI Co-Pilot for Pituitary Surgery**|Jiayuan Huang et.al.|[2503.09474](http://arxiv.org/abs/2503.09474)|null|\n", "2503.09464": "|**2025-03-12**|**Hybrid Rendering for Multimodal Autonomous Driving: Merging Neural and Physics-Based Simulation**|M\u00e1t\u00e9 T\u00f3th et.al.|[2503.09464](http://arxiv.org/abs/2503.09464)|null|\n", "2503.09447": "|**2025-03-12**|**Online Language Splatting**|Saimouli Katragadda et.al.|[2503.09447](http://arxiv.org/abs/2503.09447)|null|\n", "2503.09445": "|**2025-03-12**|**Astrea: A MOE-based Visual Understanding Model with Progressive Alignment**|Xiaoda Yang et.al.|[2503.09445](http://arxiv.org/abs/2503.09445)|null|\n", "2503.09435": "|**2025-03-12**|**A Model-based Approach for Glucose Control via Physical Activity**|Pierluigi Francesco De Paola et.al.|[2503.09435](http://arxiv.org/abs/2503.09435)|null|\n", "2503.09433": "|**2025-03-12**|**CASTLE: Benchmarking Dataset for Static Code Analyzers and LLMs towards CWE Detection**|Richard A. Dubniczky et.al.|[2503.09433](http://arxiv.org/abs/2503.09433)|null|\n", "2503.09430": "|**2025-03-12**|**IUP: Integrated and Programmable User Plane for Next-Generation Mobile Networks**|Chieh-Chun Chen et.al.|[2503.09430](http://arxiv.org/abs/2503.09430)|null|\n", "2503.09427": "|**2025-03-12**|**Multimodal Language Modeling for High-Accuracy Single Cell Transcriptomics Analysis and Generation**|Yaorui Shi et.al.|[2503.09427](http://arxiv.org/abs/2503.09427)|**[link](https://github.com/syr-cn/scmmgpt)**|\n", "2503.09387": "|**2025-03-12**|**VideoScan: Enabling Efficient Streaming Video Understanding via Frame-level Semantic Carriers**|Ruanjun Li et.al.|[2503.09387](http://arxiv.org/abs/2503.09387)|null|\n", "2503.09335": "|**2025-03-12**|**NVP-HRI: Zero Shot Natural Voice and Posture-based Human-Robot Interaction via Large Language Model**|Yuzhi Lai et.al.|[2503.09335](http://arxiv.org/abs/2503.09335)|null|\n", "2503.09321": "|**2025-03-12**|**DAVE: Diagnostic benchmark for Audio Visual Evaluation**|Gorjan Radevski et.al.|[2503.09321](http://arxiv.org/abs/2503.09321)|null|\n", "2503.09293": "|**2025-03-12**|**Better Together: Unified Motion Capture and 3D Avatar Reconstruction**|Arthur Moreau et.al.|[2503.09293](http://arxiv.org/abs/2503.09293)|null|\n", "2503.09198": "|**2025-03-12**|**A 3d particle visualization system for temperature management**|Benoit Lange et.al.|[2503.09198](http://arxiv.org/abs/2503.09198)|null|\n", "2503.09136": "|**2025-03-12**|**Earth as an Exoplanet: Investigating the effects of cloud variability on the direct-imaging of atmospheres**|Soumil Kelkar et.al.|[2503.09136](http://arxiv.org/abs/2503.09136)|null|\n", "2503.09132": "|**2025-03-12**|**Investigation of Frame Differences as Motion Cues for Video Object Segmentation**|Sota Kawamura et.al.|[2503.09132](http://arxiv.org/abs/2503.09132)|null|\n", "2503.09127": "|**2025-03-12**|**Spiritus: An AI-Assisted Tool for Creating 2D Characters and Animations**|Qirui Sun et.al.|[2503.09127](http://arxiv.org/abs/2503.09127)|null|\n", "2503.10573": "|**2025-03-13**|**Unveiling the Mathematical Reasoning in DeepSeek Models: A Comparative Study of Large Language Models**|Afrar Jahin et.al.|[2503.10573](http://arxiv.org/abs/2503.10573)|null|\n", "2503.10530": "|**2025-03-13**|**Lightweight Models for Emotional Analysis in Video**|Quoc-Tien Nguyen et.al.|[2503.10530](http://arxiv.org/abs/2503.10530)|null|\n", "2503.10498": "|**2025-03-13**|**Safety Filter for Limiting the Current of Grid-Forming Matrix Modular Multilevel Converters**|Michael Schneeberger et.al.|[2503.10498](http://arxiv.org/abs/2503.10498)|null|\n", "2503.10488": "|**2025-03-13**|**Streaming Generation of Co-Speech Gestures via Accelerated Rolling Diffusion**|Evgeniia Vu et.al.|[2503.10488](http://arxiv.org/abs/2503.10488)|null|\n", "2503.10419": "|**2025-03-13**|**A nonlinear real time capable motion cueing algorithm based on deep reinforcement learning**|Hendrik Scheidel et.al.|[2503.10419](http://arxiv.org/abs/2503.10419)|null|\n", "2503.10332": "|**2025-03-13**|**Increasing quantum speed meter sensitivity using optical spring**|L. A. Barinov et.al.|[2503.10332](http://arxiv.org/abs/2503.10332)|null|\n", "2503.10325": "|**2025-03-13**|**Collaborative Speculative Inference for Efficient LLM Inference Serving**|Luyao Gao et.al.|[2503.10325](http://arxiv.org/abs/2503.10325)|null|\n", "2503.10270": "|**2025-03-13**|**EEdit : Rethinking the Spatial and Temporal Redundancy for Efficient Image Editing**|Zexuan Yan et.al.|[2503.10270](http://arxiv.org/abs/2503.10270)|**[link](https://github.com/yuriyanzexuan/eedit)**|\n", "2503.10254": "|**2025-03-13**|**HyperSeq: A Hyper-Adaptive Representation for Predictive Sequencing of States**|Roham Koohestani et.al.|[2503.10254](http://arxiv.org/abs/2503.10254)|null|\n", "2503.10216": "|**2025-03-13**|**CoStoDet-DDPM: Collaborative Training of Stochastic and Deterministic Models Improves Surgical Workflow Anticipation and Recognition**|Kaixiang Yang et.al.|[2503.10216](http://arxiv.org/abs/2503.10216)|**[link](https://github.com/kk42yy/costodet-ddpm)**|\n", "2503.10096": "|**2025-03-13**|**Semantic Latent Motion for Portrait Video Generation**|Qiyuan Zhang et.al.|[2503.10096](http://arxiv.org/abs/2503.10096)|null|\n", "2503.10094": "|**2025-03-13**|**Semantic Synergy: Unlocking Policy Insights and Learning Pathways Through Advanced Skill Mapping**|Phoebe Koundouri et.al.|[2503.10094](http://arxiv.org/abs/2503.10094)|null|\n", "2503.10058": "|**2025-03-13**|**Deep Learning Approaches for Anti-Money Laundering on Mobile Transactions: Review, Framework, and Directions**|Jiani Fan et.al.|[2503.10058](http://arxiv.org/abs/2503.10058)|null|\n", "2503.10045": "|**2025-03-13**|**CPLOYO: A Pulmonary Nodule Detection Model with Multi-Scale Feature Fusion and Nonlinear Feature Learning**|Meng Wang et.al.|[2503.10045](http://arxiv.org/abs/2503.10045)|null|\n", "2503.10034": "|**2025-03-13**|**V2X-ReaLO: An Open Online Framework and Dataset for Cooperative Perception in Reality**|Hao Xiang et.al.|[2503.10034](http://arxiv.org/abs/2503.10034)|null|\n", "2503.10029": "|**2025-03-13**|**HandProxy: Expanding the Affordances of Speech Interfaces in Immersive Environments with a Virtual Proxy Hand**|Chen Liang et.al.|[2503.10029](http://arxiv.org/abs/2503.10029)|null|\n", "2503.10017": "|**2025-03-13**|**Speedy MASt3R**|Jingxing Li et.al.|[2503.10017](http://arxiv.org/abs/2503.10017)|null|\n", "2503.10006": "|**2025-03-13**|**On Persistently Resetting Learning Integrators: A Framework For Model-Free Feedback Optimization**|Mahmoud Abdelgalil et.al.|[2503.10006](http://arxiv.org/abs/2503.10006)|null|\n", "2503.10004": "|**2025-03-13**|**Combining Cooperative Re-Routing with Intersection Coordination for Connected and Automated Vehicles in Urban Networks**|Panagiotis Typaldos et.al.|[2503.10004](http://arxiv.org/abs/2503.10004)|null|\n", "2503.09978": "|**2025-03-13**|**A Conditional Point Cloud Diffusion Model for Deformable Liver Motion Tracking Via a Single Arbitrarily-Angled X-ray Projection**|Jiacheng Xie et.al.|[2503.09978](http://arxiv.org/abs/2503.09978)|null|\n", "2503.11646": "|**2025-03-14**|**Adversarial Data Collection: Human-Collaborative Perturbations for Efficient and Robust Robotic Imitation Learning**|Siyuan Huang et.al.|[2503.11646](http://arxiv.org/abs/2503.11646)|null|\n", "2503.11630": "|**2025-03-14**|**The time scale of redundancy between prosody and linguistic context**|Tamar I. Regev et.al.|[2503.11630](http://arxiv.org/abs/2503.11630)|null|\n", "2503.11622": "|**2025-03-14**|**RNN-DAS: A New Deep Learning Approach for Detection and Real-Time Monitoring of Volcano-Tectonic Events Using Distributed Acoustic Sensing**|Javier Fernandez-Carabantes et.al.|[2503.11622](http://arxiv.org/abs/2503.11622)|null|\n", "2503.11586": "|**2025-03-14**|**Broaden your SCOPE! Efficient Multi-turn Conversation Planning for LLMs using Semantic Space**|Zhiliang Chen et.al.|[2503.11586](http://arxiv.org/abs/2503.11586)|**[link](https://github.com/chenzhiliang94/convo-plan-scope)**|\n", "2503.11562": "|**2025-03-14**|**Designing Neural Synthesizers for Low Latency Interaction**|Franco Caspe et.al.|[2503.11562](http://arxiv.org/abs/2503.11562)|null|\n", "2503.11538": "|**2025-03-14**|**FLASH\u03bc: Fast Localizing And Sizing of Holographic Microparticles**|Ayush Paliwal et.al.|[2503.11538](http://arxiv.org/abs/2503.11538)|null|\n", "2503.11505": "|**2025-03-14**|**Real-time edge dynamics of non-Hermitian lattices**|Tian-Hua Yang et.al.|[2503.11505](http://arxiv.org/abs/2503.11505)|**[link](https://github.com/thomasyangth/nhwp-sp)**|\n", "2503.11461": "|**2025-03-14**|**MRS-CWC: A Weakly Constrained Multi-Robot System with Controllable Constraint Stiffness for Mobility and Navigation in Unknown 3D Rough Environments**|Runze Xiao et.al.|[2503.11461](http://arxiv.org/abs/2503.11461)|null|\n", "2503.11420": "|**2025-03-14**|**AQUA-SLAM: Tightly-Coupled Underwater Acoustic-Visual-Inertial SLAM with Sensor Calibration**|Shida Xu et.al.|[2503.11420](http://arxiv.org/abs/2503.11420)|null|\n", "2503.11388": "|**2025-03-14**|**Certified Inductive Synthesis for Online Mixed-Integer Optimization**|Marco Zamponi et.al.|[2503.11388](http://arxiv.org/abs/2503.11388)|null|\n", "2503.11359": "|**2025-03-14**|**Learning-Based MPC for Efficient Control of Autonomous Vehicles**|Samuel Mallick et.al.|[2503.11359](http://arxiv.org/abs/2503.11359)|**[link](https://github.com/samuelmallick/mpcrl-vehicle-gears)**|\n", "2503.11352": "|**2025-03-14**|**Enhancing Hand Palm Motion Gesture Recognition by Eliminating Reference Frame Bias via Frame-Invariant Similarity Measures**|Arno Verduyn et.al.|[2503.11352](http://arxiv.org/abs/2503.11352)|null|\n", "2503.11332": "|**2025-03-14**|**Advancements in Real-Time Oncology Diagnosis: Harnessing AI and Image Fusion Techniques**|Leila Bagheriye et.al.|[2503.11332](http://arxiv.org/abs/2503.11332)|null|\n", "2503.11328": "|**2025-03-14**|**TransiT: Transient Transformer for Non-line-of-sight Videography**|Ruiqian Li et.al.|[2503.11328](http://arxiv.org/abs/2503.11328)|null|\n", "2503.11315": "|**2025-03-14**|**MMS-LLaMA: Efficient LLM-based Audio-Visual Speech Recognition with Minimal Multimodal Speech Tokens**|Jeong Hun Yeo et.al.|[2503.11315](http://arxiv.org/abs/2503.11315)|**[link](https://github.com/JeongHun0716/MMS-LLaMA)**|\n", "2503.11247": "|**2025-03-14**|**Breaking Shallow Limits: Task-Driven Pixel Fusion for Gap-free RGBT Tracking**|Andong Lu et.al.|[2503.11247](http://arxiv.org/abs/2503.11247)|null|\n", "2503.11181": "|**2025-03-14**|**Multi-Stage Generative Upscaler: Reconstructing Football Broadcast Images via Diffusion Models**|Luca Martini et.al.|[2503.11181](http://arxiv.org/abs/2503.11181)|null|\n", "2503.11162": "|**2025-03-14**|**Reliable and Cost-Efficient IoT Connectivity for Smart Agriculture: A Comparative Study of LPWAN, 5G, and Hybrid Connectivity Models**|Mohamed Shabeer Mohamed Rafi et.al.|[2503.11162](http://arxiv.org/abs/2503.11162)|null|\n", "2503.11145": "|**2025-03-14**|**Leveraging Semantic Graphs for Efficient and Robust LiDAR SLAM**|Neng Wang et.al.|[2503.11145](http://arxiv.org/abs/2503.11145)|**[link](https://github.com/nubot-nudt/sg-slam)**|\n", "2503.11115": "|**2025-03-14**|**Solution for 8th Competition on Affective & Behavior Analysis in-the-wild**|Jun Yu et.al.|[2503.11115](http://arxiv.org/abs/2503.11115)|null|\n", "2503.13430": "|**2025-03-17**|**AugMapNet: Improving Spatial Latent Structure via BEV Grid Augmentation for Enhanced Vectorized Online HD Map Construction**|Thomas Monninger et.al.|[2503.13430](http://arxiv.org/abs/2503.13430)|null|\n", "2503.13349": "|**2025-03-17**|**A 1.8 m class pathfinder Raman LIDAR for the Northern Site of the Cherenkov Telescope Array Observatory -- Technical Design**|Otger Ballester et.al.|[2503.13349](http://arxiv.org/abs/2503.13349)|null|\n", "2503.13340": "|**2025-03-17**|**LearnMate: Enhancing Online Education with LLM-Powered Personalized Learning Plans and Support**|Xinyu Jessica Wang et.al.|[2503.13340](http://arxiv.org/abs/2503.13340)|null|\n", "2503.13203": "|**2025-03-17**|**Clustering is back: Reaching state-of-the-art LiDAR instance segmentation without training**|Corentin Sautier et.al.|[2503.13203](http://arxiv.org/abs/2503.13203)|null|\n", "2503.13200": "|**2025-03-17**|**Timing the Match: A Deep Reinforcement Learning Approach for Ride-Hailing and Ride-Pooling Services**|Yiman Bao et.al.|[2503.13200](http://arxiv.org/abs/2503.13200)|null|\n", "2503.13123": "|**2025-03-17**|**MIXPINN: Mixed-Material Simulations by Physics-Informed Neural Network**|Xintian Yuan et.al.|[2503.13123](http://arxiv.org/abs/2503.13123)|null|\n", "2503.13098": "|**2025-03-17**|**LIVEPOINT: Fully Decentralized, Safe, Deadlock-Free Multi-Robot Control in Cluttered Environments with High-Dimensional Inputs**|Jeffrey Chen et.al.|[2503.13098](http://arxiv.org/abs/2503.13098)|null|\n", "2503.13092": "|**2025-03-17**|**A Downstream and vertexing algorithm for Long Lived Particles (LLP) selection at the first High-level trigger (HLT1) of LHCb**|V. Kholoimov et.al.|[2503.13092](http://arxiv.org/abs/2503.13092)|null|\n", "2503.13086": "|**2025-03-17**|**Gaussian On-the-Fly Splatting: A Progressive Framework for Robust Near Real-Time 3DGS Optimization**|Yiwei Xu et.al.|[2503.13086](http://arxiv.org/abs/2503.13086)|null|\n", "2503.13068": "|**2025-03-17**|**Crab: A Unified Audio-Visual Scene Understanding Model with Explicit Cooperation**|Henghui Du et.al.|[2503.13068](http://arxiv.org/abs/2503.13068)|null|\n", "2503.13053": "|**2025-03-17**|**Uncertainty-Aware Knowledge Distillation for Compact and Efficient 6DoF Pose Estimation**|Nassim Ali Ousalah et.al.|[2503.13053](http://arxiv.org/abs/2503.13053)|null|\n", "2503.13048": "|**2025-03-17**|**Robot Skin with Touch and Bend Sensing using Electrical Impedance Tomography**|Haofeng Chen et.al.|[2503.13048](http://arxiv.org/abs/2503.13048)|null|\n", "2503.13023": "|**2025-03-17**|**Real-Time Multi-Object Tracking using YOLOv8 and SORT on a SoC FPGA**|Michal Danilowicz et.al.|[2503.13023](http://arxiv.org/abs/2503.13023)|null|\n", "2503.12988": "|**2025-03-17**|**ROMA: a Read-Only-Memory-based Accelerator for QLoRA-based On-Device LLM**|Wenqiang Wang et.al.|[2503.12988](http://arxiv.org/abs/2503.12988)|null|\n", "2503.12976": "|**2025-03-17**|**Practical Abstractions for Model Checking Continuous-Time Multi-Agent Systems**|Yan Kim et.al.|[2503.12976](http://arxiv.org/abs/2503.12976)|null|\n", "2503.12962": "|**2025-03-17**|**Goal-Oriented Remote Tracking Through Correlated Observations in Pull-based Communications**|Abolfazl Zakeri et.al.|[2503.12962](http://arxiv.org/abs/2503.12962)|null|\n", "2503.12891": "|**2025-03-17**|**PD-Skygroundhook Controller for Semi-Active Suspension System Using Magnetorheological Fluid Dampers**|Hansol Lim et.al.|[2503.12891](http://arxiv.org/abs/2503.12891)|null|\n", "2503.12886": "|**2025-03-17**|**RGBAvatar: Reduced Gaussian Blendshapes for Online Modeling of Head Avatars**|Linzhou Li et.al.|[2503.12886](http://arxiv.org/abs/2503.12886)|null|\n", "2503.12848": "|**2025-03-17**|**Introducing GPGPUs to smartphone-based digital holographic microscope for 3D imaging**|Yuki Nagahama et.al.|[2503.12848](http://arxiv.org/abs/2503.12848)|null|\n", "2503.12847": "|**2025-03-17**|**Robust Audio-Visual Segmentation via Audio-Guided Visual Convergent Alignment**|Chen Liu et.al.|[2503.12847](http://arxiv.org/abs/2503.12847)|null|\n", "2503.14492": "|**2025-03-18**|**Cosmos-Transfer1: Conditional World Generation with Adaptive Multimodal Control**|NVIDIA et.al.|[2503.14492](http://arxiv.org/abs/2503.14492)|**[link](https://github.com/nvidia-cosmos/cosmos-transfer1)**|\n", "2503.14478": "|**2025-03-18**|**Creation-MMBench: Assessing Context-Aware Creative Intelligence in MLLM**|Xinyu Fang et.al.|[2503.14478](http://arxiv.org/abs/2503.14478)|**[link](https://github.com/open-compass/creation-mmbench)**|\n", "2503.14475": "|**2025-03-18**|**Optimized 3D Gaussian Splatting using Coarse-to-Fine Image Frequency Modulation**|Umar Farooq et.al.|[2503.14475](http://arxiv.org/abs/2503.14475)|null|\n", "2503.14395": "|**2025-03-18**|**Weakly Supervised Spatial Implicit Neural Representation Learning for 3D MRI-Ultrasound Deformable Image Registration in HDR Prostate Brachytherapy**|Jing Wang et.al.|[2503.14395](http://arxiv.org/abs/2503.14395)|null|\n", "2503.14327": "|**2025-03-18**|**Multi-Parameter Analysis of Li-ion Battery Degradation: Integrating Optical Fiber Sensing with Differential State of Health Metrics**|Idris Temitope Bello et.al.|[2503.14327](http://arxiv.org/abs/2503.14327)|null|\n", "2503.14308": "|**2025-03-18**|**A novel method for quantifying enzyme immobilization in porous carriers using simple NMR relaxometry**|M. Raquel Serial et.al.|[2503.14308](http://arxiv.org/abs/2503.14308)|null|\n", "2503.14266": "|**2025-03-18**|**EmotionCarrier: A Multimodality 'Mindfulness-Training' Tool for Positive Emotional Value**|Yi Wang et.al.|[2503.14266](http://arxiv.org/abs/2503.14266)|null|\n", "2503.14250": "|**2025-03-18**|**A Parallel Hybrid Action Space Reinforcement Learning Model for Real-world Adaptive Traffic Signal Control**|Yuxuan Wang et.al.|[2503.14250](http://arxiv.org/abs/2503.14250)|**[link](https://github.com/cjwyx/ph-ddpg-model)**|\n", "2503.14227": "|**2025-03-18**|**Benchmarking Failures in Tool-Augmented Language Models**|Eduardo Trevi\u00f1o et.al.|[2503.14227](http://arxiv.org/abs/2503.14227)|null|\n", "2503.14220": "|**2025-03-18**|**musicolors: Bridging Sound and Visuals For Synesthetic Creative Musical Experience**|ChungHa Lee et.al.|[2503.14220](http://arxiv.org/abs/2503.14220)|null|\n", "2503.14188": "|**2025-03-18**|**Optimal Moment-based Characterization of a Gaussian State**|Niels Tripier-Mondancin et.al.|[2503.14188](http://arxiv.org/abs/2503.14188)|null|\n", "2503.14102": "|**2025-03-18**|**Sensory-driven microinterventions for improved health and wellbeing**|Youssef Abdalla et.al.|[2503.14102](http://arxiv.org/abs/2503.14102)|null|\n", "2503.14049": "|**2025-03-18**|**A Modular Edge Device Network for Surgery Digitalization**|Vincent Schorp et.al.|[2503.14049](http://arxiv.org/abs/2503.14049)|null|\n", "2503.14031": "|**2025-03-18**|**Balanced Opto-electronic Joint Transform Correlator for Enhanced Real-Time Pattern Recognition**|Julian Gamboa et.al.|[2503.14031](http://arxiv.org/abs/2503.14031)|null|\n", "2503.14009": "|**2025-03-18**|**Developing cholera outbreak forecasting through qualitative dynamics: Insights into Malawi case study**|Adrita Ghosh et.al.|[2503.14009](http://arxiv.org/abs/2503.14009)|**[link](https://github.com/ctanujit/EIML)**|\n", "2503.13957": "|**2025-03-18**|**DIFFVSGG: Diffusion-Driven Online Video Scene Graph Generation**|Mu Chen et.al.|[2503.13957](http://arxiv.org/abs/2503.13957)|**[link](https://github.com/kagawa588/diffvsgg)**|\n", "2503.13951": "|**2025-03-18**|**FrustumFusionNets: A Three-Dimensional Object Detection Network Based on Tractor Road Scene**|Lili Yang et.al.|[2503.13951](http://arxiv.org/abs/2503.13951)|null|\n", "2503.13918": "|**2025-03-18**|**Impact of Cooperativity on the Spatial and Temporal Evolution of the Light-induced Spin-State Switching of the Fe(phen)$_2$(SCN)$_2$ Spin-Crossover Complex**|Chetana Badala Viswanatha et.al.|[2503.13918](http://arxiv.org/abs/2503.13918)|null|\n", "2503.13883": "|**2025-03-18**|**YOLO-LLTS: Real-Time Low-Light Traffic Sign Detection via Prior-Guided Enhancement and Multi-Branch Feature Interaction**|Ziyu Lin et.al.|[2503.13883](http://arxiv.org/abs/2503.13883)|null|\n", "2503.13848": "|**2025-03-18**|**FlexStep: Enabling Flexible Error Detection in Multi/Many-core Real-time Systems**|Tinglue Wang et.al.|[2503.13848](http://arxiv.org/abs/2503.13848)|null|\n", "2503.15456": "|**2025-03-19**|**Temporal Encoding Strategies for Energy Time Series Prediction**|Aayam Bansal et.al.|[2503.15456](http://arxiv.org/abs/2503.15456)|null|\n", "2503.15447": "|**2025-03-19**|**Friction-Scaled Vibrotactile Feedback for Real-Time Slip Detection in Manipulation using Robotic Sixth Finger**|Naqash Afzal et.al.|[2503.15447](http://arxiv.org/abs/2503.15447)|null|\n", "2503.15399": "|**2025-03-19**|**Online Matching under KIID: Enhanced Competitive Analysis through Ordinary Differential Equation Systems**|Pan Xu et.al.|[2503.15399](http://arxiv.org/abs/2503.15399)|null|\n", "2503.15394": "|**2025-03-19**|**Advancing MG Energy Management: A Rolling Horizon Optimization Framework for Three-Phase Unbalanced Networks Integrating Convex Formulations**|Pablo Cort\u00e9s et.al.|[2503.15394](http://arxiv.org/abs/2503.15394)|null|\n", "2503.15373": "|**2025-03-19**|**Priority-driven Constraints Softening in Safe MPC for Perturbed Systems**|Ying Shuai Quan et.al.|[2503.15373](http://arxiv.org/abs/2503.15373)|null|\n", "2503.15339": "|**2025-03-19**|**Data-driven Azimuthal RHEED construction for in-situ crystal growth characterization**|Abdourahman Khaireh-Walieh et.al.|[2503.15339](http://arxiv.org/abs/2503.15339)|null|\n", "2503.15288": "|**2025-03-19**|**Beacon2Science: Enhancing STEREO/HI beacon data1 with machine learning for efficient CME tracking**|Justin Le Lou\u00ebdec et.al.|[2503.15288](http://arxiv.org/abs/2503.15288)|null|\n", "2503.15285": "|**2025-03-19**|**PAPI-Reg: Patch-to-Pixel Solution for Efficient Cross-Modal Registration between LiDAR Point Cloud and Camera Image**|Yuanchao Yue et.al.|[2503.15285](http://arxiv.org/abs/2503.15285)|null|\n", "2503.15273": "|**2025-03-19**|**Perception-aware Planning for Quadrotor Flight in Unknown and Feature-limited Environments**|Chenxin Yu et.al.|[2503.15273](http://arxiv.org/abs/2503.15273)|null|\n", "2503.15202": "|**2025-03-19**|**A Unified Framework for Real-Time Failure Handling in Robotics Using Vision-Language Models, Reactive Planner and Behavior Trees**|Faseeh Ahmad et.al.|[2503.15202](http://arxiv.org/abs/2503.15202)|null|\n", "2503.15185": "|**2025-03-19**|**3D Occupancy Prediction with Low-Resolution Queries via Prototype-aware View Transformation**|Gyeongrok Oh et.al.|[2503.15185](http://arxiv.org/abs/2503.15185)|null|\n", "2503.15177": "|**2025-03-19**|**Food Delivery Time Prediction in Indian Cities Using Machine Learning Models**|Ananya Garg et.al.|[2503.15177](http://arxiv.org/abs/2503.15177)|null|\n", "2503.15120": "|**2025-03-19**|**Communication Access Real-Time Translation Through Collaborative Correction of Automatic Speech Recognition**|Korbinian Kuhn et.al.|[2503.15120](http://arxiv.org/abs/2503.15120)|null|\n", "2503.15106": "|**2025-03-20**|**Distilling 3D distinctive local descriptors for 6D pose estimation**|Amir Hamza et.al.|[2503.15106](http://arxiv.org/abs/2503.15106)|null|\n", "2503.15100": "|**2025-03-19**|**Exploring the Perspectives of Social VR-Aware Non-Parent Adults and Parents on Children's Use of Social Virtual Reality**|Cristina Fiani et.al.|[2503.15100](http://arxiv.org/abs/2503.15100)|null|\n", "2503.15098": "|**2025-03-19**|**Virtual Voyages: Evaluating the Role of Real-Time and Narrated Virtual Tours in Shaping User Experience and Memories**|Lillian Maria Eagan et.al.|[2503.15098](http://arxiv.org/abs/2503.15098)|null|\n", "2503.15094": "|**2025-03-20**|**A method of Extracting Flat Field from Real Time Solar Observation Data**|YaHui Jin et.al.|[2503.15094](http://arxiv.org/abs/2503.15094)|null|\n", "2503.15078": "|**2025-03-19**|**Fast But Accurate: A Real-Time Hyperelastic Simulator with Robust Frictional Contact**|Ziqiu Zeng et.al.|[2503.15078](http://arxiv.org/abs/2503.15078)|null|\n", "2503.15009": "|**2025-03-19**|**Modeling, Embedded Control and Design of Soft Robots using a Learned Condensed FEM Model**|Etienne M\u00e9nager et.al.|[2503.15009](http://arxiv.org/abs/2503.15009)|null|\n", "2503.15001": "|**2025-03-19**|**Low-Complexity Patch-based No-Reference Point Cloud Quality Metric exploiting Weighted Structure and Texture Features**|Michael Neri et.al.|[2503.15001](http://arxiv.org/abs/2503.15001)|null|\n", "2503.16411": "|**2025-03-20**|**Parallel Domain-Decomposition Algorithms for Complexity Certification of Branch-and-Bound Algorithms for Mixed-Integer Linear and Quadratic Programming**|Shamisa Shoja et.al.|[2503.16411](http://arxiv.org/abs/2503.16411)|null|\n", "2503.16399": "|**2025-03-20**|**SA-Occ: Satellite-Assisted 3D Occupancy Prediction in Real World**|Chen Chen et.al.|[2503.16399](http://arxiv.org/abs/2503.16399)|null|\n", "2503.16357": "|**2025-03-20**|**UniSync: A Unified Framework for Audio-Visual Synchronization**|Tao Feng et.al.|[2503.16357](http://arxiv.org/abs/2503.16357)|null|\n", "2503.16329": "|**2025-03-20**|**Real-time simulations of laser-induced electron excitations in crystalline ZnO**|Xiao Chen et.al.|[2503.16329](http://arxiv.org/abs/2503.16329)|null|\n", "2503.16287": "|**2025-03-20**|**Securing Satellite Communications: Real-Time Video Encryption Scheme on Satellite Payloads**|Hanshuo Qiu et.al.|[2503.16287](http://arxiv.org/abs/2503.16287)|null|\n", "2503.16275": "|**2025-03-20**|**Loop Closure from Two Views: Revisiting PGO for Scalable Trajectory Estimation through Monocular Priors**|Tian Yi Lim et.al.|[2503.16275](http://arxiv.org/abs/2503.16275)|null|\n", "2503.16235": "|**2025-03-20**|**A Unifying Complexity-Certification Framework for Branch-and-Bound Algorithms for Mixed-Integer Linear and Quadratic Programming**|Shamisa Shoja et.al.|[2503.16235](http://arxiv.org/abs/2503.16235)|null|\n", "2503.16128": "|**2025-03-20**|**Coupling deep and handcrafted features to assess smile genuineness**|Benedykt Pawlus et.al.|[2503.16128](http://arxiv.org/abs/2503.16128)|null|\n", "2503.16112": "|**2025-03-20**|**PromptMobile: Efficient Promptus for Low Bandwidth Mobile Video Streaming**|Liming Liu et.al.|[2503.16112](http://arxiv.org/abs/2503.16112)|null|\n", "2503.16107": "|**2025-03-20**|**Learn to Bid as a Price-Maker Wind Power Producer**|Shobhit Singhal et.al.|[2503.16107](http://arxiv.org/abs/2503.16107)|null|\n", "2503.16086": "|**2025-03-20**|**Hyperspectral Imaging for Identifying Foreign Objects on Pork Belly**|Gabriela Ghimpeteanu et.al.|[2503.16086](http://arxiv.org/abs/2503.16086)|null|\n", "2503.16081": "|**2025-03-20**|**OThink-MR1: Stimulating multimodal generalized reasoning capabilities through dynamic reinforcement learning**|Zhiyuan Liu et.al.|[2503.16081](http://arxiv.org/abs/2503.16081)|null|\n", "2503.16061": "|**2025-03-20**|**Efficient Service Differentiation and Energy Management in Hybrid WiFi/LiFi Networks**|Asim Ihsan et.al.|[2503.16061](http://arxiv.org/abs/2503.16061)|null|\n", "2503.16047": "|**2025-03-20**|**Temporal-Spatial Attention Network (TSAN) for DoS Attack Detection in Network Traffic**|Bisola Faith Kayode et.al.|[2503.16047](http://arxiv.org/abs/2503.16047)|null|\n", "2503.16041": "|**2025-03-20**|**GreenIQ: A Deep Search Platform for Comprehensive Carbon Market Analysis and Automated Report Generation**|Bisola Faith Kayode et.al.|[2503.16041](http://arxiv.org/abs/2503.16041)|null|\n", "2503.16035": "|**2025-03-20**|**Representation of Global Viscosity Solutions for Tonelli Hamiltonians**|Skander Charfi et.al.|[2503.16035](http://arxiv.org/abs/2503.16035)|null|\n", "2503.15968": "|**2025-03-20**|**Digital Asset Data Lakehouse. The concept based on a blockchain research center**|Raul Cristian Bag et.al.|[2503.15968](http://arxiv.org/abs/2503.15968)|null|\n", "2503.15937": "|**2025-03-21**|**Advancing Mobile GUI Agents: A Verifier-Driven Approach to Practical Deployment**|Gaole Dai et.al.|[2503.15937](http://arxiv.org/abs/2503.15937)|null|\n", "2503.15901": "|**2025-03-20**|**A multi-model approach using XAI and anomaly detection to predict asteroid hazards**|Amit Kumar Mondal et.al.|[2503.15901](http://arxiv.org/abs/2503.15901)|null|\n", "2503.15887": "|**2025-03-20**|**DocVideoQA: Towards Comprehensive Understanding of Document-Centric Videos through Question Answering**|Haochen Wang et.al.|[2503.15887](http://arxiv.org/abs/2503.15887)|null|\n", "2503.17302": "|**2025-03-21**|**Bugdar: AI-Augmented Secure Code Review for GitHub Pull Requests**|John Naulty et.al.|[2503.17302](http://arxiv.org/abs/2503.17302)|null|\n", "2503.17293": "|**2025-03-21**|**Leveraging statistical models to improve pre-season forecasting and in-season management of a recreational fishery**|A. Challen Hyman et.al.|[2503.17293](http://arxiv.org/abs/2503.17293)|null|\n", "2503.17213": "|**2025-03-21**|**PP-DocLayout: A Unified Document Layout Detection Model to Accelerate Large-Scale Data Construction**|Ting Sun et.al.|[2503.17213](http://arxiv.org/abs/2503.17213)|null|\n", "2503.17175": "|**2025-03-21**|**Which2comm: An Efficient Collaborative Perception Framework for 3D Object Detection**|Duanrui Yu et.al.|[2503.17175](http://arxiv.org/abs/2503.17175)|null|\n", "2503.17059": "|**2025-03-21**|**DIDiffGes: Decoupled Semi-Implicit Diffusion Models for Real-time Gesture Generation from Speech**|Yongkang Cheng et.al.|[2503.17059](http://arxiv.org/abs/2503.17059)|null|\n", "2503.17038": "|**2025-03-21**|**Arm DynamIQ Shared Unit and Real-Time: An Empirical Evaluation**|Ashutosh Pradhan et.al.|[2503.17038](http://arxiv.org/abs/2503.17038)|null|\n", "2503.17033": "|**2025-03-21**|**Probing Peptide Adsorption Kinetics and Regioselectivity via Multipolar Plasmonic Modes of Gold Resonators**|Mathieu Nicolas et.al.|[2503.17033](http://arxiv.org/abs/2503.17033)|null|\n", "2503.17032": "|**2025-03-21**|**TaoAvatar: Real-Time Lifelike Full-Body Talking Avatars for Augmented Reality via 3D Gaussian Splatting**|Jianchuan Chen et.al.|[2503.17032](http://arxiv.org/abs/2503.17032)|null|\n", "2503.16984": "|**2025-03-21**|**EVSOAR: Security Orchestration, Automation and Response via EV Charging Stations**|Tadeu Freitas et.al.|[2503.16984](http://arxiv.org/abs/2503.16984)|null|\n", "2503.16978": "|**2025-03-21**|**Real-Time Diffusion Policies for Games: Enhancing Consistency Policies with Q-Ensembles**|Ruoqi Zhang et.al.|[2503.16978](http://arxiv.org/abs/2503.16978)|null|\n", "2503.16977": "|**2025-03-21**|**Parallel splitting method for large-scale quadratic programs**|Matteo Vandelli et.al.|[2503.16977](http://arxiv.org/abs/2503.16977)|null|\n", "2503.16949": "|**2025-03-21**|**Multiple Ultrasound Image Generation based on Tuned Alignment of Amplitude Hologram over Spatially non-Uniform Ultrasound Source**|Keisuke Hasegawa et.al.|[2503.16949](http://arxiv.org/abs/2503.16949)|null|\n", "2503.16924": "|**2025-03-21**|**Optimized Minimal 3D Gaussian Splatting**|Joo Chan Lee et.al.|[2503.16924](http://arxiv.org/abs/2503.16924)|null|\n", "2503.16904": "|**2025-03-21**|**Deep Learning for Human Locomotion Analysis in Lower-Limb Exoskeletons: A Comparative Study**|Omar Coser et.al.|[2503.16904](http://arxiv.org/abs/2503.16904)|null|\n", "2503.16850": "|**2025-03-21**|**Physics-Informed Neural Network Surrogate Models for River Stage Prediction**|Maximilian Zoch et.al.|[2503.16850](http://arxiv.org/abs/2503.16850)|null|\n", "2503.16847": "|**2025-03-21**|**Early-MFC: Enhanced Flow Correlation Attacks on Tor via Multi-view Triplet Networks with Early Network Traffic**|Yali Yuan et.al.|[2503.16847](http://arxiv.org/abs/2503.16847)|null|\n", "2503.16798": "|**2025-03-21**|**A Pathway to Near Tissue Computing through Processing-in-CTIA Pixels for Biomedical Applications**|Zihan Yin et.al.|[2503.16798](http://arxiv.org/abs/2503.16798)|null|\n", "2503.16794": "|**2025-03-21**|**Local Ratio based Real-time Job Offloading and Resource Allocation in Mobile Edge Computing**|Chuanchao Gao et.al.|[2503.16794](http://arxiv.org/abs/2503.16794)|null|\n", "2503.16769": "|**2025-03-21**|**Shear and bulk viscous coefficients of a hot and chirally imbalanced quark matter using NJL model**|Snigdha Ghosh et.al.|[2503.16769](http://arxiv.org/abs/2503.16769)|null|\n", "2503.16768": "|**2025-03-21**|**Dynamic Attention Mechanism in Spatiotemporal Memory Networks for Object Tracking**|Meng Zhou et.al.|[2503.16768](http://arxiv.org/abs/2503.16768)|null|\n", "2503.18880": "|**2025-03-24**|**Seeing Speech and Sound: Distinguishing and Locating Audios in Visual Scenes**|Hyeonggon Ryu et.al.|[2503.18880](http://arxiv.org/abs/2503.18880)|null|\n", "2503.18857": "|**2025-03-24**|**Secure Edge Computing Reference Architecture for Data-driven Structural Health Monitoring: Lessons Learned from Implementation and Benchmarking**|Sheikh Muhammad Farjad et.al.|[2503.18857](http://arxiv.org/abs/2503.18857)|null|\n", "2503.18846": "|**2025-03-24**|**Convolutional neural network approach to ion Coulomb crystal image analysis**|James Allsopp et.al.|[2503.18846](http://arxiv.org/abs/2503.18846)|null|\n", "2503.18841": "|**2025-03-24**|**Unsupervised Detection of Fraudulent Transactions in E-commerce Using Contrastive Learning**|Xuan Li et.al.|[2503.18841](http://arxiv.org/abs/2503.18841)|null|\n", "2503.18732": "|**2025-03-24**|**Embedding computational neurorehabilitation in clinical practice using a modular intelligent health system**|Thomas Weikert et.al.|[2503.18732](http://arxiv.org/abs/2503.18732)|null|\n", "2503.18698": "|**2025-03-24**|**Wireless Hearables With Programmable Speech AI Accelerators**|Malek Itani et.al.|[2503.18698](http://arxiv.org/abs/2503.18698)|null|\n", "2503.18688": "|**2025-03-24**|**SynchroStore: A Cost-Based Fine-Grained Incremental Compaction for Hybrid Workloads**|Yinan Zhang et.al.|[2503.18688](http://arxiv.org/abs/2503.18688)|null|\n", "2503.18670": "|**2025-03-24**|**Deep learning-based identification of precipitation clouds from all-sky camera data for observatory safety**|Mohammad H. Zhoolideh Haghighi et.al.|[2503.18670](http://arxiv.org/abs/2503.18670)|null|\n", "2503.18610": "|**2025-03-24**|**RIS-Assisted Localization: A Novel Conditional Sample Mean Approach without CSI**|Jiawei Yao et.al.|[2503.18610](http://arxiv.org/abs/2503.18610)|null|\n", "2503.18584": "|**2025-03-25**|**A Universal Model Combining Differential Equations and Neural Networks for Ball Trajectory Prediction**|Zhiwei Shi et.al.|[2503.18584](http://arxiv.org/abs/2503.18584)|null|\n", "2503.18537": "|**2025-03-24**|**In-vivo real-time 13C-MRSI without polarizer on site: across cities transportable hyperpolarization using UV-induced labile radicals**|Andrea Capozzi et.al.|[2503.18537](http://arxiv.org/abs/2503.18537)|null|\n", "2503.18495": "|**2025-03-24**|**Real-Time Streaming Telemetry Based Detection and Mitigation of OOK and Power Interference in Multi-User OSaaS Networks**|Agastya Raj et.al.|[2503.18495](http://arxiv.org/abs/2503.18495)|null|\n", "2503.18470": "|**2025-03-24**|**MetaSpatial: Reinforcing 3D Spatial Reasoning in VLMs for the Metaverse**|Zhenyu Pan et.al.|[2503.18470](http://arxiv.org/abs/2503.18470)|null|\n", "2503.18437": "|**2025-03-24**|**Similarity-Informed Transfer Learning for Multivariate Functional Censored Quantile Regression**|Hua Liu et.al.|[2503.18437](http://arxiv.org/abs/2503.18437)|null|\n", "2503.18429": "|**2025-03-24**|**Teller: Real-Time Streaming Audio-Driven Portrait Animation with Autoregressive Motion Generation**|Dingcheng Zhen et.al.|[2503.18429](http://arxiv.org/abs/2503.18429)|null|\n", "2503.18422": "|**2025-03-24**|**Breaking the Encoder Barrier for Seamless Video-Language Understanding**|Handong Li et.al.|[2503.18422](http://arxiv.org/abs/2503.18422)|null|\n", "2503.18408": "|**2025-03-24**|**Fast and Physically-based Neural Explicit Surface for Relightable Human Avatars**|Jiacheng Wu et.al.|[2503.18408](http://arxiv.org/abs/2503.18408)|null|\n", "2503.18405": "|**2025-03-24**|**Offline Meteorology-Pollution Coupling Global Air Pollution Forecasting Model with Bilinear Pooling**|Xu Fan et.al.|[2503.18405](http://arxiv.org/abs/2503.18405)|null|\n", "2503.18308": "|**2025-03-24**|**Vision-Guided Loco-Manipulation with a Snake Robot**|Adarsh Salagame et.al.|[2503.18308](http://arxiv.org/abs/2503.18308)|null|\n", "2503.18301": "|**2025-03-24**|**Ground Penetrating Radar-Assisted Multimodal Robot Odometry Using Subsurface Feature Matrix**|Haifeng Li et.al.|[2503.18301](http://arxiv.org/abs/2503.18301)|null|\n", "2503.19911": "|**2025-03-25**|**Real-time all-optical signal equalisation with silicon photonic recurrent neural networks**|Ruben Van Assche et.al.|[2503.19911](http://arxiv.org/abs/2503.19911)|null|\n", "2503.19900": "|**2025-03-25**|**CAFe: Unifying Representation and Generation with Contrastive-Autoregressive Finetuning**|Hao Yu et.al.|[2503.19900](http://arxiv.org/abs/2503.19900)|null|\n", "2503.19876": "|**2025-03-25**|**SLA-Awareness for AI-assisted coding**|Kishanthan Thangarajah et.al.|[2503.19876](http://arxiv.org/abs/2503.19876)|null|\n", "2503.19861": "|**2025-03-25**|**Programmable on-chip nonlinear photonics**|Ryotatsu Yanagimoto et.al.|[2503.19861](http://arxiv.org/abs/2503.19861)|null|\n", "2503.19851": "|**2025-03-25**|**Towards Online Multi-Modal Social Interaction Understanding**|Xinpeng Li et.al.|[2503.19851](http://arxiv.org/abs/2503.19851)|null|\n", "2503.19794": "|**2025-03-25**|**PAVE: Patching and Adapting Video Large Language Models**|Zhuoming Liu et.al.|[2503.19794](http://arxiv.org/abs/2503.19794)|null|\n", "2503.19736": "|**2025-03-25**|**GRN+: A Simplified Generative Reinforcement Network for Tissue Layer Analysis in 3D Ultrasound Images for Chronic Low-back Pain**|Zixue Zeng et.al.|[2503.19736](http://arxiv.org/abs/2503.19736)|null|\n", "2503.19659": "|**2025-03-25**|**Real-Time Electro-Optic Dual Comb Detection of Ultrasound Waves**|Debanuj Chatterjee et.al.|[2503.19659](http://arxiv.org/abs/2503.19659)|null|\n", "2503.19627": "|**2025-03-25**|**femtoPro: Real-time linear and nonlinear optics simulations**|Tobias Brixner et.al.|[2503.19627](http://arxiv.org/abs/2503.19627)|null|\n", "2503.19613": "|**2025-03-25**|**Energy-aware Joint Orchestration of 5G and Robots: Experimental Testbed and Field Validation**|Milan Groshev et.al.|[2503.19613](http://arxiv.org/abs/2503.19613)|null|\n", "2503.19607": "|**2025-03-25**|**Enabling Rapid Shared Human-AI Mental Model Alignment via the After-Action Review**|Edward Gu et.al.|[2503.19607](http://arxiv.org/abs/2503.19607)|null|\n", "2503.19535": "|**2025-03-25**|**Optimizing train dispatching for the Union Pacific Railroad**|Maurizio Boccia et.al.|[2503.19535](http://arxiv.org/abs/2503.19535)|null|\n", "2503.19512": "|**2025-03-25**|**Conditional Autoencoder for Generating BNS Waveforms with Tidal and Precession Effects**|Mengfei Sun et.al.|[2503.19512](http://arxiv.org/abs/2503.19512)|null|\n", "2503.19505": "|**2025-03-25**|**Single-Step Latent Consistency Model for Remote Sensing Image Super-Resolution**|Xiaohui Sun et.al.|[2503.19505](http://arxiv.org/abs/2503.19505)|null|\n", "2503.19501": "|**2025-03-25**|**Pose-Based Fall Detection System: Efficient Monitoring on Standard CPUs**|Vinayak Mali et.al.|[2503.19501](http://arxiv.org/abs/2503.19501)|null|\n", "2503.19467": "|**2025-03-25**|**EFIT-mini: An Embedded, Multi-task Neural Network-driven Equilibrium Inversion Algorithm**|Guohui Zheng et.al.|[2503.19467](http://arxiv.org/abs/2503.19467)|null|\n", "2503.19398": "|**2025-03-25**|**CyanKitten: AI-Driven Markerless Motion Capture for Improved Elderly Well-Being**|Mengyao Guo et.al.|[2503.19398](http://arxiv.org/abs/2503.19398)|null|\n", "2503.19397": "|**2025-03-25**|**Quality-focused Active Adversarial Policy for Safe Grasping in Human-Robot Interaction**|Chenghao Li et.al.|[2503.19397](http://arxiv.org/abs/2503.19397)|**[link](https://github.com/clee-jaist/QFAAP)**|\n", "2503.19391": "|**2025-03-25**|**TraF-Align: Trajectory-aware Feature Alignment for Asynchronous Multi-agent Perception**|Zhiying Song et.al.|[2503.19391](http://arxiv.org/abs/2503.19391)|null|\n", "2503.19381": "|**2025-03-25**|**Towards Build Optimization Using Digital Twins**|Henri A\u00efdasso et.al.|[2503.19381](http://arxiv.org/abs/2503.19381)|null|\n", "2503.20785": "|**2025-03-26**|**Free4D: Tuning-free 4D Scene Generation with Spatial-Temporal Consistency**|Tianqi Liu et.al.|[2503.20785](http://arxiv.org/abs/2503.20785)|null|\n", "2503.20782": "|**2025-03-26**|**Zero-Shot Audio-Visual Editing via Cross-Modal Delta Denoising**|Yan-Bo Lin et.al.|[2503.20782](http://arxiv.org/abs/2503.20782)|null|\n", "2503.20739": "|**2025-03-26**|**Emotion Detection and Music Recommendation System**|Swetha Kambham et.al.|[2503.20739](http://arxiv.org/abs/2503.20739)|null|\n", "2503.20705": "|**2025-03-26**|**Model-free Vehicle Rollover Prevention: A Data-driven Predictive Control Approach**|Mohammad R. Hajidavalloo et.al.|[2503.20705](http://arxiv.org/abs/2503.20705)|null|\n", "2503.20699": "|**2025-03-26**|**Quantum decoherence in the Caldeira-Leggett model by the real-time path integral on a computer**|Jun Nishimura et.al.|[2503.20699](http://arxiv.org/abs/2503.20699)|null|\n", "2503.20694": "|**2025-03-26**|**A Low-complexity Structured Neural Network Approach to Intelligently Realize Wideband Multi-beam Beamformers**|Hansaka Aluvihare et.al.|[2503.20694](http://arxiv.org/abs/2503.20694)|null|\n", "2503.20693": "|**2025-03-26**|**Toward Dynamic Control of Tendon-Driven Continuum Robots using Clarke Transform**|Christian Muhmann et.al.|[2503.20693](http://arxiv.org/abs/2503.20693)|null|\n", "2503.20681": "|**2025-03-26**|**Benchmarking Machine Learning Methods for Distributed Acoustic Sensing**|Shuaikai Shi et.al.|[2503.20681](http://arxiv.org/abs/2503.20681)|null|\n", "2503.20665": "|**2025-03-26**|**Agent-Based Analysis of the Impact of Near Real-Time Data and Smart Balancing on the Frequency Stability of Power Systems**|Johannes Lips et.al.|[2503.20665](http://arxiv.org/abs/2503.20665)|null|\n", "2503.20639": "|**2025-03-27**|**PVLens: Enhancing Pharmacovigilance Through Automated Label Extraction**|Jeffery L Painter et.al.|[2503.20639](http://arxiv.org/abs/2503.20639)|**[link](https://github.com/jlpainter/AMIA2025/tree/main/pvlens)**|\n", "2503.20584": "|**2025-03-26**|**A Deep Learning Pipeline for Large Earthquake Analysis using High-Rate Global Navigation Satellite System Data**|Claudia Quinteros-Cartaya et.al.|[2503.20584](http://arxiv.org/abs/2503.20584)|null|\n", "2503.20516": "|**2025-03-26**|**Small Object Detection: A Comprehensive Survey on Challenges, Techniques and Real-World Applications**|Mahya Nikouei et.al.|[2503.20516](http://arxiv.org/abs/2503.20516)|null|\n", "2503.20499": "|**2025-03-26**|**FireRedTTS-1S: An Upgraded Streamable Foundation Text-to-Speech System**|Hao-Han Guo et.al.|[2503.20499](http://arxiv.org/abs/2503.20499)|null|\n", "2503.20479": "|**2025-03-26**|**A multi-agentic framework for real-time, autonomous freeform metasurface design**|Robert Lupoiu et.al.|[2503.20479](http://arxiv.org/abs/2503.20479)|null|\n", "2503.20410": "|**2025-03-26**|**Learning Data-Driven Uncertainty Set Partitions for Robust and Adaptive Energy Forecasting with Missing Data**|Akylas Stratigakos et.al.|[2503.20410](http://arxiv.org/abs/2503.20410)|null|\n", "2503.20365": "|**2025-03-26**|**Power Networks SCADA Communication Cybersecurity, A Qiskit Implementation**|Hillol Biswas et.al.|[2503.20365](http://arxiv.org/abs/2503.20365)|null|\n", "2503.20364": "|**2025-03-26**|**UnReference: analysis of the effect of spoofing on RTK reference stations for connected rovers**|Marco Spanghero et.al.|[2503.20364](http://arxiv.org/abs/2503.20364)|null|\n", "2503.20325": "|**2025-03-26**|**Theory of two-electrons optics experiments with smooth potentials: Flying electron molecules**|P. G. Silvestrov et.al.|[2503.20325](http://arxiv.org/abs/2503.20325)|null|\n", "2503.20323": "|**2025-03-26**|**Derivation and analysis of power offset in fiber-longitudinal power profile estimation using pre-FEC hard-decision data**|Du Tang et.al.|[2503.20323](http://arxiv.org/abs/2503.20323)|null|\n", "2503.20306": "|**2025-03-26**|**3D Convolutional Neural Networks for Improved Detection of Intracranial bleeding in CT Imaging**|Bargava Subramanian et.al.|[2503.20306](http://arxiv.org/abs/2503.20306)|null|\n", "2503.21782": "|**2025-03-27**|**Mobile-VideoGPT: Fast and Accurate Video Understanding Language Model**|Abdelrahman Shaker et.al.|[2503.21782](http://arxiv.org/abs/2503.21782)|**[link](https://github.com/amshaker/mobile-videogpt)**|\n", "2503.21746": "|**2025-03-27**|**Effects of dissipation on phase diagram and bosonic excitations in the quark-meson model**|Johannes V. Roth et.al.|[2503.21746](http://arxiv.org/abs/2503.21746)|null|\n", "2503.21699": "|**2025-03-27**|**MAVERIX: Multimodal Audio-Visual Evaluation Reasoning IndeX**|Liuyue Xie et.al.|[2503.21699](http://arxiv.org/abs/2503.21699)|null|\n", "2503.21674": "|**2025-03-27**|**Intelligent IoT Attack Detection Design via ODLLM with Feature Ranking-based Knowledge Base**|Satvik Verma et.al.|[2503.21674](http://arxiv.org/abs/2503.21674)|**[link](https://github.com/claudwq/Intelligent-IoT-Attack-Detection-Design-via-LLM-with-Feature-Ranking-Based-Knowledge-Base-Design)**|\n", "2503.21645": "|**2025-03-27**|**Mapping the Digital Diplomatic Infrastructure: A Comparative Evaluation of Global Online Directories for Diplomatic Missions**|Sinisa Grgic et.al.|[2503.21645](http://arxiv.org/abs/2503.21645)|null|\n", "2503.21614": "|**2025-03-27**|**A Survey of Efficient Reasoning for Large Reasoning Models: Language, Multimodality, and Beyond**|Xiaoye Qu et.al.|[2503.21614](http://arxiv.org/abs/2503.21614)|null|\n", "2503.21552": "|**2025-03-27**|**Real-time Tracking System with partially coupled sources**|Saeid Sadeghi Vilni et.al.|[2503.21552](http://arxiv.org/abs/2503.21552)|null|\n", "2503.21548": "|**2025-03-27**|**Combining Graph Attention Networks and Distributed Optimization for Multi-Robot Mixed-Integer Convex Programming**|Viet-Anh Le et.al.|[2503.21548](http://arxiv.org/abs/2503.21548)|null|\n", "2503.21491": "|**2025-03-27**|**Data-Driven Contact-Aware Control Method for Real-Time Deformable Tool Manipulation: A Case Study in the Environmental Swabbing**|Siavash Mahmoudi et.al.|[2503.21491](http://arxiv.org/abs/2503.21491)|null|\n", "2503.21476": "|**2025-03-27**|**Robust DNN Partitioning and Resource Allocation Under Uncertain Inference Time**|Zhaojun Nan et.al.|[2503.21476](http://arxiv.org/abs/2503.21476)|null|\n", "2503.21470": "|**2025-03-27**|**Penetration depth and effective sample size characterization of UV/Vis radiation into pharmaceutical tablets**|R. Brands et.al.|[2503.21470](http://arxiv.org/abs/2503.21470)|null|\n", "2503.21453": "|**2025-03-27**|**OCEP: An Ontology-Based Complex Event Processing Framework for Healthcare Decision Support in Big Data Analytics**|Ritesh Chandra et.al.|[2503.21453](http://arxiv.org/abs/2503.21453)|null|\n", "2503.21443": "|**2025-03-27**|**Sparse Bayesian Learning for Label Efficiency in Cardiac Real-Time MRI**|Felix Terhag et.al.|[2503.21443](http://arxiv.org/abs/2503.21443)|null|\n", "2503.21433": "|**2025-03-27**|**On Learning-Based Traffic Monitoring With a Swarm of Drones**|Marko Maljkovic et.al.|[2503.21433](http://arxiv.org/abs/2503.21433)|null|\n", "2503.21417": "|**2025-03-27**|**Improving the Detection of Gravitational-Wave Signals in Real Time**|Arthur Tolley et.al.|[2503.21417](http://arxiv.org/abs/2503.21417)|null|\n", "2503.21374": "|**2025-03-27**|**Generative Decoding for Quantum Error-correcting Codes**|Hanyan Cao et.al.|[2503.21374](http://arxiv.org/abs/2503.21374)|null|\n", "2503.21337": "|**2025-03-27**|**A 71.2-$\u03bc$W Speech Recognition Accelerator with Recurrent Spiking Neural Network**|Chih-Chyau Yang et.al.|[2503.21337](http://arxiv.org/abs/2503.21337)|null|\n", "2503.21335": "|**2025-03-27**|**A Low-Power Streaming Speech Enhancement Accelerator For Edge Devices**|Ci-Hao Wu et.al.|[2503.21335](http://arxiv.org/abs/2503.21335)|null|\n", "2503.21274": "|**2025-03-27**|**Interactive Databases for the Life Sciences**|Rosalia Moreddu et.al.|[2503.21274](http://arxiv.org/abs/2503.21274)|null|\n", "2503.21263": "|**2025-03-27**|**Cultivating Game Sense for Yourself: Making VLMs Gaming Experts**|Wenxuan Lu et.al.|[2503.21263](http://arxiv.org/abs/2503.21263)|null|\n"}, "Music2Dance and Co-speech": {"2502.12546": "|**2025-02-18**|**Spatiotemporal Multi-Camera Calibration using Freely Moving People**|Sang-Eun Lee et.al.|[2502.12546](http://arxiv.org/abs/2502.12546)|null|\n", "2502.11752": "|**2025-02-17**|**Early Detection of Human Handover Intentions in Human-Robot Collaboration: Comparing EEG, Gaze, and Hand Motion**|Parag Khanna et.al.|[2502.11752](http://arxiv.org/abs/2502.11752)|null|\n", "2502.11644": "|**2025-02-17**|**InTec: integrated things-edge computing: a framework for distributing machine learning pipelines in edge AI systems**|Habib Larian et.al.|[2502.11644](http://arxiv.org/abs/2502.11644)|**[link](https://github.com/idaslab/intec_framework)**|\n", "2502.11149": "|**2025-02-19**|**Large Language-Geometry Model: When LLM meets Equivariance**|Zongzhao Li et.al.|[2502.11149](http://arxiv.org/abs/2502.11149)|null|\n", "2502.10585": "|**2025-02-14**|**Prediction uncertainty-aware planning using deep ensembles and trajectory optimisation**|Anshul Nayak et.al.|[2502.10585](http://arxiv.org/abs/2502.10585)|null|\n", "2502.07869": "|**2025-02-11**|**EventEgo3D++: 3D Human Motion Capture from a Head-Mounted Event Camera**|Christen Millerdurai et.al.|[2502.07869](http://arxiv.org/abs/2502.07869)|null|\n", "2502.06221": "|**2025-02-10**|**Interaction-aware Conformal Prediction for Crowd Navigation**|Zhe Huang et.al.|[2502.06221](http://arxiv.org/abs/2502.06221)|**[link](https://github.com/tedhuang96/icp)**|\n", "2502.05857": "|**2025-02-09**|**Acquisition through My Eyes and Steps: A Joint Predictive Agent Model in Egocentric Worlds**|Lu Chen et.al.|[2502.05857](http://arxiv.org/abs/2502.05857)|null|\n", "2502.05792": "|**2025-02-12**|**AToM: Adaptive Theory-of-Mind-Based Human Motion Prediction in Long-Term Human-Robot Interactions**|Yuwen Liao et.al.|[2502.05792](http://arxiv.org/abs/2502.05792)|**[link](https://github.com/centilinda/atom-human-prediction)**|\n", "2502.05641": "|**2025-02-08**|**Generating Physically Realistic and Directable Human Motions from Multi-Modal Inputs**|Aayam Shrestha et.al.|[2502.05641](http://arxiv.org/abs/2502.05641)|null|\n", "2502.05534": "|**2025-02-08**|**Fg-T2M++: LLMs-Augmented Fine-Grained Text Driven Human Motion Generation**|Yin Wang et.al.|[2502.05534](http://arxiv.org/abs/2502.05534)|null|\n", "2502.05432": "|**2025-02-08**|**MoFM: A Large-Scale Human Motion Foundation Model**|Mohammadreza Baharani et.al.|[2502.05432](http://arxiv.org/abs/2502.05432)|null|\n", "2502.04847": "|**2025-02-10**|**HumanDiT: Pose-Guided Diffusion Transformer for Long-form Human Motion Video Generation**|Qijun Gan et.al.|[2502.04847](http://arxiv.org/abs/2502.04847)|null|\n", "2502.03449": "|**2025-02-05**|**Dress-1-to-3: Single Image to Simulation-Ready 3D Outfit with Diffusion Prior and Differentiable Physics**|Xuan Li et.al.|[2502.03449](http://arxiv.org/abs/2502.03449)|null|\n", "2502.02936": "|**2025-02-05**|**Every Angle Is Worth A Second Glance: Mining Kinematic Skeletal Structures from Multi-view Joint Cloud**|Junkun Jiang et.al.|[2502.02936](http://arxiv.org/abs/2502.02936)|null|\n", "2502.02817": "|**2025-02-05**|**A Decade of Action Quality Assessment: Largest Systematic Survey of Trends, Challenges, and Future Directions**|Hao Yin et.al.|[2502.02817](http://arxiv.org/abs/2502.02817)|null|\n", "2502.02358": "|**2025-02-06**|**MotionLab: Unified Human Motion Generation and Editing via the Motion-Condition-Motion Paradigm**|Ziyan Guo et.al.|[2502.02358](http://arxiv.org/abs/2502.02358)|null|\n", "2502.02063": "|**2025-02-04**|**CASIM: Composite Aware Semantic Injection for Text to Motion Generation**|Che-Jui Chang et.al.|[2502.02063](http://arxiv.org/abs/2502.02063)|null|\n", "2502.01143": "|**2025-02-08**|**ASAP: Aligning Simulation and Real-World Physics for Learning Agile Humanoid Whole-Body Skills**|Tairan He et.al.|[2502.01143](http://arxiv.org/abs/2502.01143)|**[link](https://github.com/lecar-lab/asap)**|\n", "2502.00665": "|**2025-02-02**|**Cross-Modal Synergies: Unveiling the Potential of Motion-Aware Fusion Networks in Handling Dynamic and Static ReID Scenarios**|Fuxi Ling et.al.|[2502.00665](http://arxiv.org/abs/2502.00665)|null|\n", "2502.14795": "|**2025-02-21**|**Humanoid-VLA: Towards Universal Humanoid Control with Visual Integration**|Pengxiang Ding et.al.|[2502.14795](http://arxiv.org/abs/2502.14795)|null|\n", "2502.14140": "|**2025-02-19**|**ModSkill: Physical Character Skill Modularization**|Yiming Huang et.al.|[2502.14140](http://arxiv.org/abs/2502.14140)|null|\n", "2502.17414": "|**2025-02-24**|**X-Dancer: Expressive Music to Human Dance Video Generation**|Zeyuan Chen et.al.|[2502.17414](http://arxiv.org/abs/2502.17414)|null|\n", "2502.16913": "|**2025-02-24**|**HVIS: A Human-like Vision and Inference System for Human Motion Prediction**|Kedi Lyu et.al.|[2502.16913](http://arxiv.org/abs/2502.16913)|null|\n", "2502.16908": "|**2025-02-24**|**Design of a low-cost and lightweight 6 DoF bimanual arm for dynamic and contact-rich manipulation**|Jaehyung Kim et.al.|[2502.16908](http://arxiv.org/abs/2502.16908)|null|\n", "2502.16175": "|**2025-02-22**|**Mojito: LLM-Aided Motion Instructor with Jitter-Reduced Inertial Tokens**|Ziwei Shan et.al.|[2502.16175](http://arxiv.org/abs/2502.16175)|null|\n", "2502.15956": "|**2025-02-21**|**Human Motion Prediction, Reconstruction, and Generation**|Canxuan Gang et.al.|[2502.15956](http://arxiv.org/abs/2502.15956)|null|\n", "2502.18373": "|**2025-02-25**|**EgoSim: An Egocentric Multi-view Simulator and Real Dataset for Body-worn Cameras during Motion and Activity**|Dominik Hollidt et.al.|[2502.18373](http://arxiv.org/abs/2502.18373)|null|\n", "2502.18180": "|**2025-02-27**|**ChatMotion: A Multimodal Multi-Agent for Human Motion Analysis**|Lei Li et.al.|[2502.18180](http://arxiv.org/abs/2502.18180)|null|\n", "2502.17834": "|**2025-03-04**|**Impact of Object Weight in Handovers: Inspiring Robotic Grip Release and Motion from Human Handovers**|Parag Khanna et.al.|[2502.17834](http://arxiv.org/abs/2502.17834)|null|\n", "2502.19364": "|**2025-02-26**|**Deep Learning For Time Series Analysis With Application On Human Motion**|Ali Ismail-Fawaz et.al.|[2502.19364](http://arxiv.org/abs/2502.19364)|null|\n", "2502.19056": "|**2025-02-26**|**Fatigue-PINN: Physics-Informed Fatigue-Driven Motion Modulation and Synthesis**|Iliana Loi et.al.|[2502.19056](http://arxiv.org/abs/2502.19056)|null|\n", "2502.19049": "|**2025-02-26**|**Foundation Inference Models for Stochastic Differential Equations: A Transformer-based Approach for Zero-shot Function Estimation**|Patrick Seifner et.al.|[2502.19049](http://arxiv.org/abs/2502.19049)|null|\n", "2503.02577": "|**2025-03-04**|**SPG: Improving Motion Diffusion by Smooth Perturbation Guidance**|Boseong Jeon et.al.|[2503.02577](http://arxiv.org/abs/2503.02577)|null|\n", "2503.01610": "|**2025-03-03**|**Vid2Avatar-Pro: Authentic Avatar from Videos in the Wild via Universal Prior**|Chen Guo et.al.|[2503.01610](http://arxiv.org/abs/2503.01610)|null|\n", "2503.01291": "|**2025-03-03**|**SemGeoMo: Dynamic Contextual Human Motion Generation with Semantic and Geometric Guidance**|Peishan Cong et.al.|[2503.01291](http://arxiv.org/abs/2503.01291)|null|\n", "2503.00602": "|**2025-03-01**|**Zero-Power Backscatter Sensing and Communication Proof-of-Concept**|Yu Zhang et.al.|[2503.00602](http://arxiv.org/abs/2503.00602)|null|\n", "2503.00576": "|**2025-03-01**|**Enhancing Context-Aware Human Motion Prediction for Efficient Robot Handovers**|Gerard G\u00f3mez-Izquierdo et.al.|[2503.00576](http://arxiv.org/abs/2503.00576)|null|\n", "2503.00389": "|**2025-03-01**|**BGM2Pose: Active 3D Human Pose Estimation with Non-Stationary Sounds**|Yuto Shibata et.al.|[2503.00389](http://arxiv.org/abs/2503.00389)|null|\n", "2503.00371": "|**2025-03-07**|**Jointly Understand Your Command and Intention:Reciprocal Co-Evolution between Scene-Aware 3D Human Motion Synthesis and Analysis**|Xuehao Gao et.al.|[2503.00371](http://arxiv.org/abs/2503.00371)|null|\n", "2503.03474": "|**2025-03-05**|**Enhancing Spoken Discourse Modeling in Language Models Using Gestural Cues**|Varsha Suresh et.al.|[2503.03474](http://arxiv.org/abs/2503.03474)|null|\n", "2503.03222": "|**2025-03-06**|**Mocap-2-to-3: Lifting 2D Diffusion-Based Pretrained Models for 3D Motion Capture**|Zhumei Wang et.al.|[2503.03222](http://arxiv.org/abs/2503.03222)|null|\n", "2503.04879": "|**2025-03-06**|**Modeling Dynamic Hand-Object Interactions with Applications to Human-Robot Handovers**|Sammy Christen et.al.|[2503.04879](http://arxiv.org/abs/2503.04879)|null|\n", "2503.04829": "|**2025-03-05**|**StickMotion: Generating 3D Human Motions by Drawing a Stickman**|Tao Wang et.al.|[2503.04829](http://arxiv.org/abs/2503.04829)|null|\n", "2503.06499": "|**2025-03-15**|**ExGes: Expressive Human Motion Retrieval and Modulation for Audio-Driven Gesture Synthesis**|Xukun Zhou et.al.|[2503.06499](http://arxiv.org/abs/2503.06499)|null|\n", "2503.06151": "|**2025-03-08**|**BioMoDiffuse: Physics-Guided Biomechanical Diffusion for Controllable and Authentic Human Motion Synthesis**|Zixi Kang et.al.|[2503.06151](http://arxiv.org/abs/2503.06151)|null|\n", "2503.08664": "|**2025-03-11**|**MEAT: Multiview Diffusion Model for Human Generation on Megapixels with Mesh Attention**|Yuhan Wang et.al.|[2503.08664](http://arxiv.org/abs/2503.08664)|**[link](https://github.com/johannwyh/meat)**|\n", "2503.08270": "|**2025-03-11**|**HERO: Human Reaction Generation from Videos**|Chengjun Yu et.al.|[2503.08270](http://arxiv.org/abs/2503.08270)|null|\n", "2503.07597": "|**2025-03-10**|**HumanMM: Global Human Motion Recovery from Multi-shot Videos**|Yuhong Zhang et.al.|[2503.07597](http://arxiv.org/abs/2503.07597)|null|\n", "2503.09015": "|**2025-03-12**|**Natural Humanoid Robot Locomotion with Generative Motion Prior**|Haodong Zhang et.al.|[2503.09015](http://arxiv.org/abs/2503.09015)|null|\n", "2503.06955": "|**2025-03-12**|**Motion Anything: Any to Motion Generation**|Zeyu Zhang et.al.|[2503.06955](http://arxiv.org/abs/2503.06955)|**[link](https://github.com/steve-zeyu-zhang/MotionAnything)**|\n", "2503.13300": "|**2025-03-17**|**Progressive Human Motion Generation Based on Text and Few Motion Frames**|Ling-An Zeng et.al.|[2503.13300](http://arxiv.org/abs/2503.13300)|null|\n", "2503.13229": "|**2025-03-17**|**HoloGest: Decoupled Diffusion and Motion Priors for Generating Holisticly Expressive Co-speech Gestures**|Yongkang Cheng et.al.|[2503.13229](http://arxiv.org/abs/2503.13229)|null|\n", "2503.13120": "|**2025-03-17**|**3D Human Interaction Generation: A Survey**|Siyuan Fan et.al.|[2503.13120](http://arxiv.org/abs/2503.13120)|null|\n", "2503.12955": "|**2025-03-17**|**HIS-GPT: Towards 3D Human-In-Scene Multimodal Understanding**|Jiahe Zhao et.al.|[2503.12955](http://arxiv.org/abs/2503.12955)|null|\n", "2503.12628": "|**2025-03-16**|**texTENG: Fabricating Wearable Textile-Based Triboelectric Nanogenerators**|Ritik Batra et.al.|[2503.12628](http://arxiv.org/abs/2503.12628)|null|\n", "2503.14505": "|**2025-03-18**|**MusicInfuser: Making Video Diffusion Listen and Dance**|Susung Hong et.al.|[2503.14505](http://arxiv.org/abs/2503.14505)|null|\n", "2503.14229": "|**2025-03-18**|**HA-VLN: A Benchmark for Human-Aware Navigation in Discrete-Continuous Environments with Dynamic Multi-Human Interactions, Real-World Validation, and an Open Leaderboard**|Yifei Dong et.al.|[2503.14229](http://arxiv.org/abs/2503.14229)|null|\n", "2503.14040": "|**2025-03-18**|**MAG: Multi-Modal Aligned Autoregressive Co-Speech Gesture Generation without Vector Quantization**|Binjie Liu et.al.|[2503.14040](http://arxiv.org/abs/2503.14040)|null|\n", "2503.15225": "|**2025-03-19**|**A Personalized Data-Driven Generative Model of Human Motion**|Angelo Di Porzio et.al.|[2503.15225](http://arxiv.org/abs/2503.15225)|null|\n", "2503.15127": "|**2025-03-19**|**A Comparative Study of Human Motion Models in Reinforcement Learning Algorithms for Social Robot Navigation**|Tommaso Van Der Meer et.al.|[2503.15127](http://arxiv.org/abs/2503.15127)|**[link](https://github.com/TommasoVandermeer/Social-Navigation-PyEnvs)**|\n", "2503.15082": "|**2025-03-19**|**StyleLoco: Generative Adversarial Distillation for Natural Humanoid Robot Locomotion**|Le Ma et.al.|[2503.15082](http://arxiv.org/abs/2503.15082)|null|\n", "2503.14919": "|**2025-03-19**|**GenM$^3$: Generative Pretrained Multi-path Motion Model for Text Conditional Human Motion Generation**|Junyu Shi et.al.|[2503.14919](http://arxiv.org/abs/2503.14919)|null|\n", "2503.14637": "|**2025-03-18**|**Reinforcement learning-based motion imitation for physiologically plausible musculoskeletal motor control**|Merkourios Simos et.al.|[2503.14637](http://arxiv.org/abs/2503.14637)|**[link](https://github.com/amathislab/kinesis)**|\n", "2503.15996": "|**2025-03-20**|**Animating the Uncaptured: Humanoid Mesh Animation with Video Diffusion Models**|Marc Bened\u00ed San Mill\u00e1n et.al.|[2503.15996](http://arxiv.org/abs/2503.15996)|null|\n", "2503.16973": "|**2025-03-26**|**ARFlow: Human Action-Reaction Flow Matching with Physical Guidance**|Wentao Jiang et.al.|[2503.16973](http://arxiv.org/abs/2503.16973)|null|\n", "2503.18674": "|**2025-03-24**|**Human Motion Unlearning**|Edoardo De Matteis et.al.|[2503.18674](http://arxiv.org/abs/2503.18674)|null|\n", "2503.18211": "|**2025-03-25**|**SimMotionEdit: Text-Based Human Motion Editing with Motion Similarity Prediction**|Zhengyuan Li et.al.|[2503.18211](http://arxiv.org/abs/2503.18211)|**[link](https://github.com/lzhyu/simmotionedit)**|\n", "2503.17978": "|**2025-03-23**|**PIM: Physics-Informed Multi-task Pre-training for Improving Inertial Sensor-Based Human Activity Recognition**|Dominique Nshimyimana et.al.|[2503.17978](http://arxiv.org/abs/2503.17978)|null|\n", "2503.19557": "|**2025-03-25**|**Dance Like a Chicken: Low-Rank Stylization for Human Motion Diffusion**|Haim Sawdayee et.al.|[2503.19557](http://arxiv.org/abs/2503.19557)|null|\n", "2503.20237": "|**2025-03-26**|**A Virtual Fencing Framework for Safe and Efficient Collaborative Robotics**|Vineela Reddy Pippera Badguna et.al.|[2503.20237](http://arxiv.org/abs/2503.20237)|null|\n", "2503.20218": "|**2025-03-26**|**Video Motion Graphs**|Haiyang Liu et.al.|[2503.20218](http://arxiv.org/abs/2503.20218)|null|\n", "2503.21268": "|**2025-03-27**|**ClimbingCap: Multi-Modal Dataset and Method for Rock Climbing in World Coordinate**|Ming Yan et.al.|[2503.21268](http://arxiv.org/abs/2503.21268)|null|\n"}, "Speech and Interaction": {"2502.13133": "|**2025-02-18**|**AV-Flow: Transforming Text to Audio-Visual Human-like Interactions**|Aggelina Chatziagapi et.al.|[2502.13133](http://arxiv.org/abs/2502.13133)|null|\n", "2502.12759": "|**2025-02-18**|**High-Fidelity Music Vocoder using Neural Audio Codecs**|Luca A. Lanzend\u00f6rfer et.al.|[2502.12759](http://arxiv.org/abs/2502.12759)|null|\n", "2502.12572": "|**2025-02-18**|**TechSinger: Technique Controllable Multilingual Singing Voice Synthesis via Flow Matching**|Wenxiang Guo et.al.|[2502.12572](http://arxiv.org/abs/2502.12572)|**[link](https://github.com/gwx314/techsinger)**|\n", "2502.12048": "|**2025-02-18**|**A Survey on Bridging EEG Signals and Generative AI: From Image and Text to Beyond**|Shreya Shukla et.al.|[2502.12048](http://arxiv.org/abs/2502.12048)|null|\n", "2502.12002": "|**2025-02-17**|**NaturalL2S: End-to-End High-quality Multispeaker Lip-to-Speech Synthesis with Differential Digital Signal Processing**|Yifan Liang et.al.|[2502.12002](http://arxiv.org/abs/2502.12002)|null|\n", "2502.11128": "|**2025-02-16**|**FELLE: Autoregressive Speech Synthesis with Token-Wise Coarse-to-Fine Flow Matching**|Hui Wang et.al.|[2502.11128](http://arxiv.org/abs/2502.11128)|null|\n", "2502.11094": "|**2025-02-16**|**SyncSpeech: Low-Latency and Efficient Dual-Stream Text-to-Speech based on Temporal Masked Transformer**|Zhengyan Sheng et.al.|[2502.11094](http://arxiv.org/abs/2502.11094)|null|\n", "2502.10329": "|**2025-02-14**|**VocalCrypt: Novel Active Defense Against Deepfake Voice Based on Masking Effect**|Qingyuan Fei et.al.|[2502.10329](http://arxiv.org/abs/2502.10329)|null|\n", "2502.08939": "|**2025-02-13**|**TokenSynth: A Token-based Neural Synthesizer for Instrument Cloning and Text-to-Instrument**|Kyungsu Kim et.al.|[2502.08939](http://arxiv.org/abs/2502.08939)|**[link](https://github.com/kyungsukim42/tokensynth)**|\n", "2502.08857": "|**2025-02-14**|**ASVspoof 5: Design, Collection and Validation of Resources for Spoofing, Deepfake, and Adversarial Attack Detection Using Crowdsourced Speech**|Xin Wang et.al.|[2502.08857](http://arxiv.org/abs/2502.08857)|null|\n", "2502.07562": "|**2025-02-11**|**LoRP-TTS: Low-Rank Personalized Text-To-Speech**|\u0141ukasz Bondaruk et.al.|[2502.07562](http://arxiv.org/abs/2502.07562)|null|\n", "2502.07345": "|**2025-02-11**|**Advanced Zero-Shot Text-to-Speech for Background Removal and Preservation with Controllable Masked Speech Prediction**|Leying Zhang et.al.|[2502.07345](http://arxiv.org/abs/2502.07345)|null|\n", "2502.07243": "|**2025-02-11**|**Vevo: Controllable Zero-Shot Voice Imitation with Self-Supervised Disentanglement**|Xueyao Zhang et.al.|[2502.07243](http://arxiv.org/abs/2502.07243)|null|\n", "2502.06710": "|**2025-02-10**|**Learning Musical Representations for Music Performance Question Answering**|Xingjian Diao et.al.|[2502.06710](http://arxiv.org/abs/2502.06710)|null|\n", "2502.06922": "|**2025-02-10**|**Synthetic Audio Helps for Cognitive State Tasks**|Adil Soubki et.al.|[2502.06922](http://arxiv.org/abs/2502.06922)|**[link](https://github.com/adil-soubki/sad-training)**|\n", "2502.06490": "|**2025-02-16**|**Recent Advances in Discrete Speech Tokens: A Review**|Yiwei Guo et.al.|[2502.06490](http://arxiv.org/abs/2502.06490)|null|\n", "2502.05980": "|**2025-02-19**|**Speech to Speech Translation with Translatotron: A State of the Art Review**|Jules R. Kala et.al.|[2502.05980](http://arxiv.org/abs/2502.05980)|null|\n", "2502.05762": "|**2025-02-09**|**Non-invasive electromyographic speech neuroprosthesis: a geometric perspective**|Harshavardhana T. Gowda et.al.|[2502.05762](http://arxiv.org/abs/2502.05762)|null|\n", "2502.05729": "|**2025-02-09**|**BnTTS: Few-Shot Speaker Adaptation in Low-Resource Setting**|Mohammad Jahid Ibna Basher et.al.|[2502.05729](http://arxiv.org/abs/2502.05729)|null|\n", "2502.05649": "|**2025-02-08**|**Gender Bias in Instruction-Guided Speech Synthesis Models**|Chun-Yi Kuan et.al.|[2502.05649](http://arxiv.org/abs/2502.05649)|null|\n", "2502.13508": "|**2025-02-21**|**VLAS: Vision-Language-Action Model With Speech Instructions For Customized Robot Manipulation**|Wei Zhao et.al.|[2502.13508](http://arxiv.org/abs/2502.13508)|**[link](https://github.com/whichwhichgone/VLAS)**|\n", "2502.14780": "|**2025-02-20**|**ReVision: A Dataset and Baseline VLM for Privacy-Preserving Task-Oriented Visual Instruction Rewriting**|Abhijit Mishra et.al.|[2502.14780](http://arxiv.org/abs/2502.14780)|null|\n", "2502.15367": "|**2025-02-21**|**Advancing User-Voice Interaction: Exploring Emotion-Aware Voice Assistants Through a Role-Swapping Approach**|Yong Ma et.al.|[2502.15367](http://arxiv.org/abs/2502.15367)|null|\n", "2502.17239": "|**2025-02-24**|**Baichuan-Audio: A Unified Framework for End-to-End Speech Interaction**|Tianpeng Li et.al.|[2502.17239](http://arxiv.org/abs/2502.17239)|**[link](https://github.com/baichuan-inc/baichuan-audio)**|\n", "2502.16897": "|**2025-02-24**|**Balancing Speech Understanding and Generation Using Continual Pre-training for Codec-based Speech LLM**|Jiatong Shi et.al.|[2502.16897](http://arxiv.org/abs/2502.16897)|null|\n", "2502.15919": "|**2025-02-21**|**Mind the Gap! Static and Interactive Evaluations of Large Audio Models**|Minzhi Li et.al.|[2502.15919](http://arxiv.org/abs/2502.15919)|null|\n", "2502.17971": "|**2025-02-25**|**Multimodal Interaction and Intention Communication for Industrial Robots**|Tim Schreiter et.al.|[2502.17971](http://arxiv.org/abs/2502.17971)|null|\n", "2502.18924": "|**2025-02-26**|**Sparse Alignment Enhanced Latent Diffusion Transformer for Zero-Shot Speech Synthesis**|Ziyue Jiang et.al.|[2502.18924](http://arxiv.org/abs/2502.18924)|null|\n", "2502.18889": "|**2025-03-08**|**Clip-TTS: Contrastive Text-content and Mel-spectrogram, A High-Quality Text-to-Speech Method based on Contextual Semantic Understanding**|Tianyun Liu et.al.|[2502.18889](http://arxiv.org/abs/2502.18889)|null|\n", "2502.20140": "|**2025-03-12**|**Telephone Surveys Meet Conversational AI: Evaluating a LLM-Based Telephone Survey System at Scale**|Max M. Lang et.al.|[2502.20140](http://arxiv.org/abs/2502.20140)|null|\n", "2502.19924": "|**2025-02-27**|**DiffCSS: Diverse and Expressive Conversational Speech Synthesis with Diffusion Models**|Weihao wu et.al.|[2502.19924](http://arxiv.org/abs/2502.19924)|null|\n", "2502.19759": "|**2025-02-27**|**Does Your Voice Assistant Remember? Analyzing Conversational Context Recall and Utilization in Voice Interaction Models**|Heeseung Kim et.al.|[2502.19759](http://arxiv.org/abs/2502.19759)|null|\n", "2502.19732": "|**2025-03-04**|**Speculative Decoding and Beyond: An In-Depth Survey of Techniques**|Yunhai Hu et.al.|[2502.19732](http://arxiv.org/abs/2502.19732)|null|\n", "2503.02769": "|**2025-03-04**|**InSerter: Speech Instruction Following with Unsupervised Interleaved Pre-training**|Dingdong Wang et.al.|[2503.02769](http://arxiv.org/abs/2503.02769)|null|\n", "2503.01710": "|**2025-03-03**|**Spark-TTS: An Efficient LLM-Based Text-to-Speech Model with Single-Stream Decoupled Speech Tokens**|Xinsheng Wang et.al.|[2503.01710](http://arxiv.org/abs/2503.01710)|**[link](https://github.com/sparkaudio/spark-tts)**|\n", "2503.01266": "|**2025-03-03**|**Voice Cloning for Dysarthric Speech Synthesis: Addressing Data Scarcity in Speech-Language Pathology**|Birger Moell et.al.|[2503.01266](http://arxiv.org/abs/2503.01266)|null|\n", "2503.01045": "|**2025-03-02**|**Language-agnostic, automated assessment of listeners' speech recall using large language models**|Bj\u00f6rn Herrmann et.al.|[2503.01045](http://arxiv.org/abs/2503.01045)|null|\n", "2503.00733": "|**2025-03-02**|**UniWav: Towards Unified Pre-training for Speech Representation Learning and Generation**|Alexander H. Liu et.al.|[2503.00733](http://arxiv.org/abs/2503.00733)|null|\n", "2503.00455": "|**2025-03-01**|**PodAgent: A Comprehensive Framework for Podcast Generation**|Yujia Xiao et.al.|[2503.00455](http://arxiv.org/abs/2503.00455)|**[link](https://github.com/yujxx/podagent)**|\n", "2503.03250": "|**2025-03-05**|**Good practices for evaluation of synthesized speech**|Erica Cooper et.al.|[2503.03250](http://arxiv.org/abs/2503.03250)|null|\n", "2503.04724": "|**2025-03-06**|**LLMVoX: Autoregressive Streaming Text-to-Speech Model for Any LLM**|Sambal Shikhar et.al.|[2503.04724](http://arxiv.org/abs/2503.04724)|null|\n", "2503.04713": "|**2025-03-06**|**Scaling Rich Style-Prompted Text-to-Speech Datasets**|Anuj Diwan et.al.|[2503.04713](http://arxiv.org/abs/2503.04713)|**[link](https://github.com/ajd12342/paraspeechcaps)**|\n", "2503.04110": "|**2025-03-06**|**InterChat: Enhancing Generative Visual Analytics using Multimodal Interactions**|Juntong Chen et.al.|[2503.04110](http://arxiv.org/abs/2503.04110)|null|\n", "2503.05223": "|**2025-03-07**|**DiVISe: Direct Visual-Input Speech Synthesis Preserving Speaker Characteristics And Intelligibility**|Yifan Liu et.al.|[2503.05223](http://arxiv.org/abs/2503.05223)|**[link](https://github.com/pussycat0700/divise)**|\n", "2503.04799": "|**2025-03-03**|**Direct Speech to Speech Translation: A Review**|Mohammad Sarim et.al.|[2503.04799](http://arxiv.org/abs/2503.04799)|null|\n", "2503.06375": "|**2025-03-09**|**ProSE: Diffusion Priors for Speech Enhancement**|Sonal Kumar et.al.|[2503.06375](http://arxiv.org/abs/2503.06375)|null|\n", "2503.08562": "|**2025-03-11**|**Exploring Socio-Cultural Challenges and Opportunities in Designing Mental Health Chatbots for Adolescents in India**|Neil K. R. Sehgal et.al.|[2503.08562](http://arxiv.org/abs/2503.08562)|null|\n", "2503.07919": "|**2025-03-10**|**BEARCUBS: A benchmark for computer-using web agents**|Yixiao Song et.al.|[2503.07919](http://arxiv.org/abs/2503.07919)|null|\n", "2503.08954": "|**2025-03-11**|**An Exhaustive Evaluation of TTS- and VC-based Data Augmentation for ASR**|Sewade Ogun et.al.|[2503.08954](http://arxiv.org/abs/2503.08954)|null|\n", "2503.10616": "|**2025-03-18**|**OVTR: End-to-End Open-Vocabulary Multiple Object Tracking with Transformer**|Jinyang Li et.al.|[2503.10616](http://arxiv.org/abs/2503.10616)|**[link](https://github.com/jinyanglii/ovtr)**|\n", "2503.10241": "|**2025-03-13**|**SCOOP: A Framework for Proactive Collaboration and Social Continual Learning through Natural Language Interaction andCausal Reasoning**|Dimitri Ognibene et.al.|[2503.10241](http://arxiv.org/abs/2503.10241)|null|\n", "2503.10298": "|**2025-03-14**|**Proceedings of the ISCA/ITG Workshop on Diversity in Large Speech and Language Models**|Sebastian M\u00f6ller et.al.|[2503.10298](http://arxiv.org/abs/2503.10298)|null|\n", "2503.11026": "|**2025-03-14**|**MAVFlow: Preserving Paralinguistic Elements with Conditional Flow Matching for Zero-Shot AV2AV Multilingual Translation**|Sungwoo Cho et.al.|[2503.11026](http://arxiv.org/abs/2503.11026)|null|\n", "2503.12115": "|**2025-03-15**|**Universal Speech Token Learning via Low-Bitrate Neural Codec and Pretrained Representations**|Xue Jiang et.al.|[2503.12115](http://arxiv.org/abs/2503.12115)|null|\n", "2503.14345": "|**2025-03-19**|**MoonCast: High-Quality Zero-Shot Podcast Generation**|Zeqian Ju et.al.|[2503.14345](http://arxiv.org/abs/2503.14345)|**[link](https://github.com/jzq2000/mooncast)**|\n", "2503.14257": "|**2025-03-26**|**InnerSelf: Designing Self-Deepfaked Voice for Emotional Well-being**|Guang Dai et.al.|[2503.14257](http://arxiv.org/abs/2503.14257)|null|\n", "2503.13693": "|**2025-03-21**|**Adapting to the Unknown: Training-Free Audio-Visual Event Perception with Dynamic Thresholds**|Eitan Shaar et.al.|[2503.13693](http://arxiv.org/abs/2503.13693)|**[link](https://github.com/eitan159/AV2A)**|\n", "2503.14928": "|**2025-03-19**|**Shushing! Let's Imagine an Authentic Speech from the Silent Video**|Jiaxin Ye et.al.|[2503.14928](http://arxiv.org/abs/2503.14928)|null|\n", "2503.16956": "|**2025-03-21**|**From Faces to Voices: Learning Hierarchical Representations for High-quality Video-to-Speech**|Ji-Hoon Kim et.al.|[2503.16956](http://arxiv.org/abs/2503.16956)|null|\n", "2503.16689": "|**2025-03-20**|**WaveFM: A High-Fidelity and Efficient Vocoder Based on Flow Matching**|Tianze Luo et.al.|[2503.16689](http://arxiv.org/abs/2503.16689)|**[link](https://github.com/luotianze666/wavefm)**|\n", "2503.16488": "|**2025-03-10**|**VocalEyes: Enhancing Environmental Perception for the Visually Impaired through Vision-Language Models and Distance-Aware Object Detection**|Kunal Chavan et.al.|[2503.16488](http://arxiv.org/abs/2503.16488)|null|\n", "2503.18422": "|**2025-03-24**|**Breaking the Encoder Barrier for Seamless Video-Language Understanding**|Handong Li et.al.|[2503.18422](http://arxiv.org/abs/2503.18422)|null|\n", "2503.17577": "|**2025-03-21**|**Measuring the Robustness of Audio Deepfake Detectors**|Xiang Li et.al.|[2503.17577](http://arxiv.org/abs/2503.17577)|**[link](https://github.com/Jessegator/Audio_robustness_evaluation)**|\n", "2503.17479": "|**2025-03-21**|**Your voice is your voice: Supporting Self-expression through Speech Generation and LLMs in Augmented and Alternative Communication**|Yiwen Xu et.al.|[2503.17479](http://arxiv.org/abs/2503.17479)|null|\n", "2503.19510": "|**2025-03-25**|**RoboFlamingo-Plus: Fusion of Depth and RGB Perception with Vision-Language Models for Enhanced Robotic Manipulation**|Sheng Wang et.al.|[2503.19510](http://arxiv.org/abs/2503.19510)|null|\n", "2503.19398": "|**2025-03-25**|**CyanKitten: AI-Driven Markerless Motion Capture for Improved Elderly Well-Being**|Mengyao Guo et.al.|[2503.19398](http://arxiv.org/abs/2503.19398)|null|\n", "2503.19334": "|**2025-03-25**|**Design of Seamless Multi-modal Interaction Framework for Intelligent Virtual Agents in Wearable Mixed Reality Environment**|Ghazanfar Ali et.al.|[2503.19334](http://arxiv.org/abs/2503.19334)|null|\n", "2503.20499": "|**2025-03-26**|**FireRedTTS-1S: An Upgraded Streamable Foundation Text-to-Speech System**|Hao-Han Guo et.al.|[2503.20499](http://arxiv.org/abs/2503.20499)|null|\n", "2503.20215": "|**2025-03-26**|**Qwen2.5-Omni Technical Report**|Jin Xu et.al.|[2503.20215](http://arxiv.org/abs/2503.20215)|null|\n", "2503.21094": "|**2025-03-27**|**GazeSwipe: Enhancing Mobile Touchscreen Reachability through Seamless Gaze and Finger-Swipe Integration**|Zhuojiang Cai et.al.|[2503.21094](http://arxiv.org/abs/2503.21094)|null|\n", "2503.20999": "|**2025-03-26**|**Text-Driven Voice Conversion via Latent State-Space Modeling**|Wen Li et.al.|[2503.20999](http://arxiv.org/abs/2503.20999)|null|\n"}}